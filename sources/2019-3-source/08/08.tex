
\noindent{\small УДК 004.738  \hfill {\footnotesize Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}\\
MSC 60K30, 90B25

}

\vskip1.5mm%2mm

\noindent{\bf Алгоритм планирования очередей передачи трафика\\
в~телекоммуникационных сетях для управления
доступностью$^{*}$%
 }

\vskip1.8mm%2.5mm

\noindent{\it Ю. М. Монахов, А. П. Кузнецова, М. Р. Исмаилова%$\,^1$%
%, И. О. Фамилия$\,^2$%

 }

\efootnote{
%%
\vspace{-3mm}\parindent=7mm
%%
\vskip 0.1mm $^{*}$ Работа выполнена при финансовой поддержке
Российского фонда фундаментальных исследований (гранты №
16-47-330055 и~18-07-01109).\par
%%
%%\vskip1.5mm%2mm
%%
\indent{\copyright} Санкт-Петербургский государственный
университет, \issueyear%
%%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum08 } }\hfill\thepage}%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum08}}}%
% для оформления нижнего колонтитула
\cfoot{} %

\vskip1.5mm%2mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

\noindent%
%$^2$~%
Владимирский государственный университет имени А. Г. и~Н. Г.
Столетовых,

\noindent%
%\hskip2.45mm%
Российская Федерация, 600026, Владимир, ул. Горького, 87

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vskip2mm%3mm

{\small \noindent \textbf{Для цитирования:} \textit{Монахов Ю. М.,
Кузнецова А. П., Исмаилова М. Р.} Алгоритм планирования очередей
передачи трафика в~телекоммуникационных сетях для управления
доступностью~// Вестник Санкт-Петербургского университета.
Прикладная математика. Информатика. Процессы управления.
\issueyear. Т.~15. Вып.~\issuenum.
С.~\pageref{p8}--\pageref{p8e}.\\
\doivyp/\enskip%
\!\!\!spbu10.\issueyear.\issuenum08

\vskip2mm%3mm

{\leftskip=7mm\noindentСовременное состояние телекоммуникаций
характеризуется все более возрастающей масштабностью сетей,
большими скоростями передачи данных и~постоянным появ\-ле\-нием
новых сервисов и~приложений, работающих на~различных протоколах
и~по-разному ис\-поль\-зую\-щих ресурсы сети. В~то же время
с~развитием сенсорных сетей все больше становится доля трафика,
чувствительного к~изменениям параметров среды. Поэтому для более
эффективного применения сетевых ресурсов актуальными являются
задачи приоритизации и~контроля трафика, позволяющие увеличивать
доступность как в~телекоммуникационной системе в~целом, так
и~приоритетных сервисов. В~данной статье предлагается алгоритм
планирования очередей передачи данных на~основе приоритизации,
который поз\-во\-ляет оптимизировать использование пропускной
способности и~обеспечивать минимально возможную задержку для
приоритетных классов. Этот алгоритм основан на~известном алгоритме
планирования <<маркерное ведро>> и~служит для минимизации времени
обработки пакетов на~маршрутизируемом устройстве. Тестирование
и~сравнение разработанного алгоритма с~существующими решениями
позволили сделать вывод, что предложенный алгоритм показывает
более низкие суммарные значения задержки для различных классов
трафика. Приведена концептуальная модель доступности, представлены
математическое описание алгоритма приоритизации,  методика оценки
качества обслуживания и~результаты
сравнительного тестирования и~его анализа.\\[1mm]
\textit{Ключевые слова}: доступность сети, управление потоком,
приоритизация трафика, алгоритм планирования, технология «Quality
of Service», алгоритм Hierarchical Token Bucket.

}

}

\vskip 3mm%4mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Введение.} Доступность сервиса является основополагающим
свойством безопасности системы, так как отсутствие доступа
к~требуемому ресурсу может повлечь за~собой простой элементов
IТ-инфраструктуры, который может привести к~отказу
работоспособности всей IТ-инфраструктуры и, как следствие,
к~серьезным экономическим убыткам [1].

К наиболее эффективным способам повышения доступности относится
внедрение известной технологии «Quality of Service» (QoS) [2]
в~телекоммуникационную сеть предприятия. Определений для такой
технологии множество, приведем данное компанией Cisco [3].

QoS определяет способность сети предоставлять наиболее
качественный сервис выбранному сетевому трафику в~заданных
технологических рамках. В~частности, функции QoS обеспечивают
улучшенный и~более предсказуемый сетевой сервис, реа\-ли\-зуя
сле\-дую\-щие службы:

--- поддержка гарантированной полосы пропускания;

--- уменьшение потерь;

--- управление перегрузками;

--- формирование (шейпинг) трафика;

--- настройка приоритетов трафика в~сети.

В корпоративных сетях выполняются сложные критически важные
приложения, при этом возрастает доля чувствительного к~задержкам
трафика. QoS служит для определения его приоритетности, чтобы
гарантировать, что каждое приложение получит требуемый уровень
сервиса~[4]. Здесь важной задачей является разработка механизмов,
благодаря которым в~периоды перегрузки пакеты с~информацией,
чувствительной к~задержкам, не будут простаивать в~очередях или
получат более высокий приоритет, чем пакеты с~не чувствительной
к~задержкам информацией~[4].

\textbf{Постановка проблемы.} Использование алгоритмов
приоритизации и~контроля трафика позволяет отделять трафик
функционирующих сервисов из~общего потока и~обеспечивать
гарантированную полосу пропускания для таких типов трафика.
В~настоящее время конфигурирование данных алгоритмов производится
на основании выделения части канала связи для различных типов
трафика.  Однако такое распределение не учитывает особенности
проходящего трафика и~не гарантирует обеспечение доступности
трафика, чувствительного к~задержкам канала. Тем самым доступность
сервиса понижается, что ведет к~потенциальной угрозе безопасности
системы~[5].

По нашему мнению, эту проблему возможно решить путем разработки
новых алгоритмов приоритизации и~контроля трафика, позволяющих
оптимально распределять трафик, проходящий через канал связи,
с~целью повышения доступности определенных типов трафика.


Объектом исследования является телекоммуникационная сеть передачи
данных, а~предметом~--- модели и~алгоритмы контроля задержек при
обслуживании. Цель работы заключается в~повышении доступности
сервисов в~телекоммуникационных сетях за~счет разработки
и~внедрения новых алгоритмов приоритизации и~управления качеством
обслуживания. Ввиду того, что глобальные сети содержат массу
гетерогенных устройств, и, как следствие, неконтролируемы,
а~локальные сети обладают недостаточным инструментарием для
имплементации собственных протоколов приоритизации, авторы видят
приложение своей работы скорее в~программно-определяемых сетях
(SDN), или маршрутизаторах, базирующихся на~свободном программном
обеспечении, либо в~рамках IaaS.

Под доступностью будем понимать время отклика сервиса, входящее
в~директивный интервал времени, в~течение которого этот сервис
доступен между определенными входной и~выходной точками
с~параметрами, оговоренными в~соглашении об уровне обслуживания
(SLA); под повышением доступности~--- гарантированное попадание
в~заданные SLA временные интервалы, которое обеспечивается
посредством уменьшения времени отклика сервиса посредством
минимизации времени обработки пакетов на~маршрутизирующем
устройстве~[6]. Стоит отметить, что исследование проводится
на~транспортном уровне (4 в~модели OSI), вследствие чего
коммутаторы не рас\-смат\-ри\-вают\-ся как низкоуровневые
устройства.

\textbf{Описание модели.} Концептуальная модель доступности
включает:

--- множество соглашений об уровне обслуживании $S$, где каждая
$s_i$ --- максимальное время отклика для каждого $i$-го сервиса:
$S=\left\{s_1,\ldots,s_n\right\}$;

--- множество приоритетов каждого сервиса $C$, в~котором каждая
$c_i$ является приоритетом $i$-го сервиса, где сервис с~наименьшим
значением $c$ имеет наивысший приоритет:
$C=\left\{c_1,\ldots,c_n\right\},~ c_i\in[0,i]$;

--- множество откликов сервисов $T$, где каждая $t_i$ --- время
отклика $i$-го сервиса: $T=\left\{t_1,\ldots,t_n\right\}$.

Время отклика зависит от различного рода задержек, выделяют
следующие~[7]: сетевые задержки маршрутизирующего оборудования,
$N$; задержки операционной системы по~обработке процессов, $O$;
задержки программного обеспечения сервиса, $P$. Следовательно,
каждая $t_i$ рассчитывается по~формуле
$$t_i=(N+O+P)c_i, \ ~ t_i\in[0,s_i].$$
Выделим ограничения, которые препятствуют бесконечному уменьшению
времени отклика сервиса: размер буферной памяти маршрутизируемого
оборудования, $B$; скорость передачи пакетов сетевым
оборудованием, $E$; требования по~обеспечению работы нескольких
сервисов в~равных приоритетах, $V$.

Обозначим $Y$ как множество ограничений для системы в~целом: $Y =
BEV$. Соот\-ветственно функция доступности определенного сервиса
выглядит следующим образом:
\begin{equation*}
\begin{gathered}
   t_i=\min_Y(N+O+P)c_i,\\
   B<B_{t_i}, \ ~ V<V_{t_i}.
\end{gathered}
\end{equation*}

\textbf{Выявление параметров оптимизации.} Исследования показывают
прямую зависимость отклика сервиса от используемого алгоритма
планирования очередей. Для обеспечения должных откликов применяют
метод приоритизации трафика посредством его классификации.
Наибольшей популярностью пользуется иерархический алгоритм
Hierarchical Token Bucket~(HTB), подразумевающий разделение полосы
пропускания для определенных типов потока в~отдельные классы,
каждый из~которых имеет собственную полосу пропускания. HTB
выстраивает классы в~виде дерева: они могут разделяться
на~дочерние классы, каждый из~которых делит между собой полосу
родительского класса. В~русскоязычной литературе Hierarchical
Token Bucket переводят как <<маркерное ведро>>, или
<<(иерархическая) корзина маркеров>>.

Для выявления узких мест в~функционировании алгоритма планирования
HTB на~экспериментальной установке было проведено изучение его
типовой конфигурации в~различных режимах нагрузки. Целью
эксперимента являлось определение ключевых аспектов, влияющих
на~обеспечение низкой задержки передачи пакетов при различной
интенсивности входящего потока пакетов. Анализ полученных данных
показал следующие закономерности и~ключевые места планировщиков
пакетов, оптимизация которых может привести к~уменьшению задержки
пакетов при высокой интенсивности потока: минимизация простоя
полосы пропускания при отсутствии пакетов в~том или ином классе,
динамическое изменение полосы пропускания относительно
интенсивности входящего потока пакетов, размер буфера.

Исходя из~результатов анализа~[8], были предложены направления
оптимизации основных параметров, влияющих на задержку передачи
пакетов: контроль интенсивности входящего потока пакетов,
динамическое изменение пропускной способности канала относительно
входящей интенсивности, оптимизация предоставления полосы для
классов трафика относительно входящей интенсивности.


\textbf{Входные данные алгоритма планирования очередей.} Алгоритм
под\-ра\-зу\-ме\-вает классификацию трафика по~определенным
признакам, таким как: IP-адрес назначения или источника, порт
назначения или источника, протокол передачи данных и~т.~д. Для
каждого класса трафика определяются приоритет в~соответствии с~SLA
и~директивное время задержки пакета в~очереди на~ожидание передачи
сетевым оборудованием. Каждый класс имеет свою очередь накопления
пакетов. Выпуск пакетов в~передающую очередь осуществляется
со~скоростью, рассчитанной на~основании директивного времени
и~алгоритма планирования использования пропускной способности.

Математически это можно описать через следующие множества:

---\,\,множество классов трафика: $C={c_0,...,c_n}$, где $n$ ---
количество классов тра\-фика;

---\,\,множество приоритетов класса: $Q={q_0,...,q_n}$;

---\,\,множество задержек для классов: $D={d_0,...,d_n}$;

---\,\,множество пороговых скоростей потока пакетов для каждого
класса: $S=\left\{s_0,...,s_n\right\}$, где $s_i$ рассчитывается
по формуле $$s_i=\frac{MTU\cdot8\cdot1000}{d_i}.$$ Также должно
соблюдаться условие $$\sum\limits_{i=0}^n s_i\leq
\textrm{max\_rate},$$ в~котором max\_rate ~--- максимальная
пропускная способность интерфейса;

---\,\,множество времени обработки пакетов для каждого класса:
$X=\left\{\chi_0,...,\chi_n\right\}$, где $\chi_i=d_i$;

---\,\,множество интенсивностей входящего трафика пакетов:
$\Lambda=\left\{\lambda_0,...,\lambda_n\right\}$;

---\,\,множество интенсивностей обслуживания пакетов:
$M=\left\{\mu_0,...,\mu_n\right\}$, где $\mu_i=1/\chi_i;$

---\,\,множество нагрузок на~очередь передачи пакетов класса:
$R=\left\{\rho_0,...,\rho_n\right\}$, где
$\rho_i=\lambda_i/\mu_i$.


Следовательно, для каждого класса устанавливаются параметры
интенсивности потока пакетов $\lambda$; время обработки пакета
$\chi$, в~начальный момент работы алгоритма равное
гарантированному времени для $i$-го класса;\, $\mu$~---
интенсивность обслуживания пакетов.

В современных телекоммуникационных сетях между отправителем
и~получателем находятся сетевые устройства, которые реализуют
другие алгоритмы обработки очередей, по~большей части
несовпадающие с~описанными в~данной работе, однако следует
отметить тот факт, что расстановка приоритетов в~этих очередях не
имеет для нас решающего значения по~следующим причинам:

---\,\,если устройств в~сети достаточно много, то, исходя
из~положений теории случайных процессов, задержки на~входе можно
моделировать с~помощью пуассоновского потока с~малой погрешностью;

---\,\,в~различных телекоммуникационных системах существуют разные
подходы к~приоритизации: если для одной системы важно
приоритизировать легковесный трафик, то для другой системы
тяжеловесный трафик может оказаться важнее, соответственно
необходимо изменять приоритеты в~трафике, поступающем на~вход.

Алгоритм определяет одну очередь передачи для пакетов различных
классов. Из~очередей классов пакеты выходят с~интенсивностью,
меньшей или равной $s_i$ для $i$-го~клас\-са. Пакеты попадают
в~очередь последовательно в~соответствии с~приоритетами~$P$.

Если интенсивность входного потока в~наиболее приоритетном классе
ниже выходной пороговой интенсивности~$s_i$, следующий
по~приоритету класс может произвести повышение пороговой выходной
интенсивности при сохранении приведeнного на стр.~388 условия.
Право повышения пороговой выходной интенсивности переходит
нижестоящим по~приоритету классам.

Если интенсивность потока пакетов больше пороговой интенсивности
потока $s_i$, то пакеты начинают отбрасываться для уравнивания
интенсивности потока до пороговой интенсивности потока. Повышение
или понижение интенсивности пакетов определяется в~результате
работы алгоритма планирования использования пропускной
способности. Авторы не включают в~рассмотрение механизмы
управления перегрузками, поскольку данные алгоритмы работают
на~оконечных устройствах (терминалах), не рассматриваемых в~данной
работе.

\textbf{Описание предлагаемого алгоритма.} Алгоритм производит
управление временем обработки пакетов в~очередях их передачи. Его
проход  производится на~временной основе, каждые 0,5 мс.\vskip 2mm

{\itshapeШаг 1.} Проверяем условие, превышает ли суммарная
интенсивность потока всех пакетов возможную скорость обработки
$\sum\limits_{i=0}^n \lambda_i<\textrm{max\_rate}$.

Если условие выполняется, переходим к~шагу 2, если нет~---
к~шагу~3.

{\itshapeШаг 2.} Устанавливаем значение времени обработки пакета
для каждого класса в~минимальное время обработки пакетов
$\textrm{min\_delay}: \chi=\textrm{min\_delay}$.

{\itshapeШаг 3.} Проверяем условие, что минимальное время
обработки пакета для приоритетного класса 0 меньше или равно
$\textrm{min\_delay}: \frac{1}{\lambda_i}\leq
\textrm{min\_delay}$.

Если условие выполняется, переходим к~шагу 4, если нет~--- то
к~шагу 8.

{\itshapeШаг 4.} Производится распределение полосы пропускания
выпускающей очереди таким образом, что наиболее приоритетный класс
забирает всегда 2/3 доступной ему полосы пропускания, каждый
следующий по~приоритету класс занимает 2/3 полосы, оставшейся
после первого класса, и~т.~д. до последнего класса, который
занимает оставшуюся полосу.

{\itshapeШаг 5.} Запускается цикл проверки необходимости
оптимальности использования полосы. Цикл отрабатывает по~всем
классам трафика~--- от~1 до~$n$. После прохождения происходит
переход к шагу~1.

{\itshapeШаг 6.} Проверка соответствия интенсивности обслуживания
интенсивности входящего потока пакетов по~условию
$\frac{\lambda_i}{\mu_1}<1$.

Если условие выполняется, то производится переход к~шагу~7, если
нет~--- то к~шагу~5.

{\itshapeШаг 7.} Производится предоставление неиспользуемой полосы
для класса, максимальное значение которого равно
$\frac{\lambda_i}{\mu_1}$, путем определения разницы интенсивности
обслуживания пакетов класса и~полученной оптимальной интенсивности
обслуживания. Оптимальное время обработки пакетов находится
по~формуле $\chi_i=\frac{1}{\lambda_i}$.

{\itshapeШаг 8.} Время обработки пакетов для класса с~приоритетом
0 выставляется в~половину гарантированной полосы пропускания минус
минимальное время обработки пакетов. Время обработки остальных
пакетов определяется по~принципу разделения полосы,
представленному согласно шагу 4.\vskip 2mm

Блок-схема работы алгоритма приведена на~рис.~1.


\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{08/fig1}

\vskip 2mm {\small{\it Рис. 1.} Блок-схема работы алгоритма} }
\end{figure}



%\begin{figure}[htbp]
%\centerline{\includegraphics[width=0.9\linewidth]{1}}
%\caption{Блок-схема работы алгоритма.} \label{1}
%\end{figure}

\textbf{Тестирование алгоритма.} Для проверки эффективности
разработанного алгоритма было произведено имитационное
моделирование его работы в~среде AnyLogic в~сравнении с~работой
алгоритма планирования очередей HTB в~типовой конфигурации.

\textit{Состав моделируемой системы.} Моделируемая система
состояла из следующих элементов:

--- очереди передачи пакетов с~приоритетом 0;

--- очереди передачи пакетов с~приоритетом 1;

--- очереди передачи пакетов в~среду передачи сигнала;

--- планировщика распределения использования очереди передачи
пакетов в~среду для очередей с~приоритетами.

Каждая моделируемая очередь обладала такими параметрами:

--- интенсивность потока пакетов, $\lambda_i$;

--- время обработки пакетов в~очереди, $\chi_i$;

--- гарантированная задержка для передачи пакетов очереди, $d_i$.


Для очередей задавались ограничения:

--- интенсивность пакетов в~очередь передачи пакетов в~среду
передачи не может превышать значение $\textrm{max\_rate}$;

--- время обработки пакетов в~очереди передачи пакетов в~среду
передачи всегда составляет $\textrm{min\_delay}$;

--- буфер очередей с~приоритетами ограничен значением, равным 100
пакетам.

На рис. 2 представлена схема имитационной модели в~AnyLogic.


\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{08/fig2}

\vskip 2mm {\small{\it Рис. 2.} Схема имитационной модели
в~AnyLogic} }
\end{figure}



%\begin{figure}[htbp]
%\centerline{\includegraphics[width=0.9\linewidth]{2}}
%\caption{Схема имитационной модели в~AnyLogic.} \label{2}
%\end{figure}

В рамках тестирования разработанного алгоритма было произведено
сравнение задержек передачи пакетов каждой очереди при одинаковых
нагрузках на~канал очереди классов. Исследование предполагало
проведение 5 тестовых съемов задержки передачи пакетов. Режимы
тестирования представлены в~таблице.


\begin{table}[h!]
\begin{center}
{\small

{\it Таблица.} {\bf Режимы тестирования алгоритма}%

}

\vskip 3mm

{\footnotesize

\begin{tabular}{@{}|c|c|c|c|@{}}

\hline
{\begin{tabular}[c]{@{}c@{}}Режим\\ тестирования\end{tabular}} & {\begin{tabular}[c]{@{}c@{}}Интенсивность \\ очереди 1, \\ пакет/мс \end{tabular}} & {\begin{tabular}[c]{@{}c@{}} Интенсивность \\ очереди 2, \\ пакет/мс \end{tabular}} & {\begin{tabular}[c]{@{}c@{}}Количество \\ замеров \end{tabular}} \\
\hline
1                                                               & 0.48                                                                                      & 0.857                                                                                     & 180                                                                    \\
\hline
2                                                               & 100                                                                                       & 0.857                                                                                     & 180                                                                    \\
\hline
3                                                               & 0.48                                                                                      & 100                                                                                       & 180                                                                    \\
\hline
4                                                               & 20.825                                                                                    & 62.4                                                                                      & 180                                                                    \\
\hline
5                                                               & 100                                                                                       & 100                                                                                       & 180                                                                    \\
\hline
\end{tabular}

}
\end{center}\vspace{-3mm}
\end{table}


Результаты эксперимента приведены на~рис.~3,~4. На рис.~3,\,{\it
а} изображен график работы алгоритмов в~режиме 1. Из~него видно,
что при низкой интенсивности входящего потока пакетов оба
алгоритма обеспечивают низкую задержку обработки пакетов. Однако
для низкоприоритетной очереди HTB задержка выше приоритетного
класса, что обусловлено последовательностью права передачи пакетов
на~основании приоритета.

\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{08/fig3}

\vskip 2mm {\small{\it Рис. 3.} Графики работы алгоритмов
в~режимах 1 ({\it а})
и~2 ({\it б}) } \\

\vskip 0mm {\footnotesize {\it 1} --- очередь с приоритетом 0
(модификация НТВ); %\\
{\it 2} --- очередь с приоритетом 1
(модификация НТВ); %\\
{\it 3} --- очередь с приоритетом 0 (НТВ); %\\
{\it 4} --- очередь с приоритетом 1 (НТВ).\\ } }
\end{figure}

\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{08/fig4}

\vskip 2mm {\small{\it Рис. 4.} Результаты тестирования моделей
в~режимах 3  ({\itа}), 4
({\itб}) и 5 ({\itв}) } \\

\vskip 0mm {\footnotesize {\it 1} --- очередь с приоритетом 0
(модификация НТВ); %\\
{\it 2} --- очередь с приоритетом 1
(модификация НТВ); %\\
{\it 3} --- очередь с приоритетом 0 (НТВ); %\\
{\it 4} --- очередь с приоритетом 1 (НТВ).\\ } }
\end{figure}



%\begin{figure}[htbp]
%\centerline{\includegraphics[width=0.9\linewidth]{3}}
%\caption{Графики работы алгоритмов в~режиме 1({\itа})
%и~2({\itб}).} \label{3}
%\end{figure}
%
%\begin{figure}
%\includegraphics[width=0.9\linewidth]{4}
%\caption{Результаты тестирования моделей в~режимах 3({\itа}), 4
%({\itб}), 5({\itв}).} \label{4}
%\end{figure}


На рис. 3,\,{\it б} представлен график работы алгоритмов в~режиме
2. Он показывает, что HTB произвел выделение полосы для
приоритетного класса и~тем самым занял б\'{о}льшую часть ресурсов
сети, поэтому задержка во~втором классе начала расти.
Разработанный алгоритм, в~свою очередь, определил, что
интенсивность потока низкоприоритетного класса невысокая, тем
самым можно обеспечивать низкую задержку для обоих классов,
оставаясь в~директивном времени.



График работы алгоритмов в~режиме 3 иллюстрирует рис. 4,\,{\it а}.
На нeм видно, что HTB определил низкую активность
высокоприоритетного класса и~позволяет низкоприоритетному классу
использовать больше полосы. В~свою очередь, с~помощью
разработанного алгоритма выявлена необходимая часть полосы для
высокоприоритетного класса, чтобы выдавать пакеты с~минимальной
задержкой, а~оставшаяся часть определена для класса
низкоприоритетного.

На рис. 4,\,{\it б} приведен график работы алгоритмов в~режиме 4.
Нагрузка на~систему равняется 1, это предел обработки пакетов без
потерь. Из~рисунка следует, что HTB сохраняет заданную полосу
пропускания для высокоприоритетного класса, не снижая его
задержки, притом, что задержка низкоприоритетного класса сильно
возросла.

Разработанный алгоритм производит расчет оптимального
распределения полосы в~пределах нагрузки на~систему таким образом,
чтобы обеспечить среднюю минимальную задержку для обоих классов.
Но поскольку классы имеют разные приоритеты, задержка для
высокоприоритетного класса определяется ниже. К~тому же
интенсивность потока заявок высокоприоритетного класса меньше, чем
у низкоприоритетного, и~согласно работе алгоритма приоритетный
класс получает б\'oльшую часть необходимой полосы,
а~низкоприоритетный только ту часть, которая осталась. Исходя
из~этого, мы наблюдаем возрастание задержки для низкоприоритетного
класса.



На рис. 4,\,{\it в} продемонстрирован график работы алгоритмов
в~режиме 5. Интенсивность входящего потока пакетов обоих классов
трафика сильно превышает значение, возможное для обработки.
Следовательно, происходит накопление пакетов в~буфере очереди, все
пакеты, что выходят за~границу буфера, начинают отбрасываться.

На графике получаем значения задержки пакетов, передача которых
была осуществлена. И данная ситуация аналогична режиму 4, когда
система способна обработать входящий поток заявок, но так как
интенсивность обоих классов равна, то для низкоприоритетного
класса остается меньше допустимой полосы и~его задержка начинает
возрастать. HTB производит обработку аналогичным образом,
и~распределение полосы пропускания происходит согласно
сконфигурированному значению, без возможности расширения полосы
для разных классов.


\textbf{Заключение.} Результат сравнительного тестирования
алгоритмов позволяет сделать вывод, что разработанный алгоритм
показывает более низкие суммарные значения задержки для различных
классов трафика, тем самым обеспечивая доступность сервисов
в~обоих классах. Соответственно предложенный алгоритм планирования
очередей передачи данных даeт возможность оптимизировать
использование пропускной способности и~приводит к~минимально
возможной задержке для приоритетных классов.

Использование и~внедрение предложенного алгоритма в~реальных
условиях является трудоемкой задачей, требующей добавления
специального модуля в~операционную систему маршрутизатора, поэтому
следующим этапом будет исследование возможностей внедрения данного
алгоритма для работы в~реальной телекоммуникационной сети в~целях
увеличения доступности сервисов в~условиях повышенной сетевой
активности. Также, отмечая определенное взаимовлияние между
алгоритмами приоритизации трафика и~алгоритмами контроля
перегрузок, авторы видят возможность продолжения своей работы
в~изучении данного влияния.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\input{08/lit-ra}

%\newpage
\input{08/ref-s}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

%\thispagestyle{empty}
%
\vskip 3mm
%
\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}}}%
% для оформления нижнего колонтитула
\cfoot{} %
%
}
