
%\begin{center}
%{\footnotesize
%\begin{tabular}{lcr}
%$\issueyear$   & ВЕСТНИК\,САНКТ-ПЕТЕРБУРГСКОГО\,УНИВЕРСИТЕТА  &  Том\,13.\,\,Вып.\,$\issuenum$ \\
%\multicolumn{3}{c}{ПРИКЛАДНАЯ МАТЕМАТИКА.
%ИНФОРМАТИКА. ПРОЦЕССЫ УПРАВЛЕНИЯ}\\
%\end{tabular}
%\end{center}
%}
{\footnotesize \noindent$\issueyear$\mbox{~~~~~~~~~~}
ВЕСТНИК\,САНКТ-ПЕТЕРБУРГСКОГО\,УНИВЕРСИТЕТА
Т.\,13.\,\,Вып.\,$\issuenum$\linebreak %
\mbox{~~~~~~~~~~}ПРИКЛАДНАЯ МАТЕМАТИКА. ИНФОРМАТИКА. ПРОЦЕССЫ
УПРАВЛЕНИЯ %
}

%\ \\ \vskip 0.8mm\hrule \\ \hrule \\ \ \\

\vskip 0.5mm

\hline\vskip .5mm

\hline

\vspace{1.2cm} \noindent {\large ИНФОРМАТИКА} \vspace{1.0cm}

\noindent{\footnotesize УДК 004.042}

\vskip2.5mm

\noindent{\it В. П. Потапов, М. А. Костылев, C. E. Попов}

\vskip2.5mm

\noindent{\bf ПОТОКОВАЯ ОБРАБОТКА РАДАРНЫХ ДАННЫХ \\
В~РАСПРЕДЕЛЕННОЙ СРЕДЕ APACHE SPARK}

\efootnote{

\vspace{-3mm}\parindent=7mm


%{\copyright} Н. А. Валиотти, 2014

{\it Потапов Вадим Петрович} --- доктор технических наук,
профессор;  potapov@ict.sbras.ru

{\it Костылев Михаил Александрович} --- аспирант; 5999ft@gmail.com


{\it Попов Семен Евгеньевич} --- кандидат технических наук;
popov@ict.sbras.ru


\vskip 2.0mm

\textit{Potapov Vadim Petrovich} --- doctor of engineering
sciences, professor;  potapov@ict.sbras.ru

\textit{Kostylev Mikhail Alexandrovich} --- postgraduate student;
5999ft@gmail.com


\textit{Popov Semen Evgen'evich} --- PhD in engineering sciences;
popov@ict.sbras.ru

\vskip 2.0mm

{\copyright} Санкт-Петербургский государственный университет,
\issueyear%\\
%$^{*}$ Работа выполнена при финансовой поддержке
%Санкт-Петербургского государственного университета (грант
%№~9.38.673.2013).
}

\vskip3mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
%\fancyfoot[LO]{{\footnotesize\emph{\doivyp09 } }\hfill\thepage}%
\fancyfoot[LO]{{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum04 } }\hfill\thepage}%
%\fancyfoot[RE]{\thepage\hfill{\footnotesize\emph{\doivyp09 } } }%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum04}}}%
%\fancyfoot[LO]{\hfill{\fontsize{10.5}{10.5}\selectfont \thepage}}%
%\fancyfoot[RE]{{\fontsize{10.5}{10.5}\selectfont \thepage}\hfill}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

\noindentИнститут вычислительных технологий СО РАН, Российская
Федерация, \\ 630090, Новосибирск, пр. Академика Лаврентьева, 6



\vskip3mm

\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}

\item В~статье описан современный подход к~созданию распределенного программного
комплекса на~базе массово-параллельной технологии для потоковой
пре- и~постоб\-ра\-бот\-ки радарных снимков. Отличительными
особенностями системы являются ее способность работы в~режиме
реального времени с~большими объемами потоковых данных, а~также
применение существующих алгоритмов, не~предназначенных для
распределенной обработки, на~множестве узлов без изменения
реализации последних. Проведено сравнение технологий
распределенных вычислений, на~основе которого делается выбор
в~пользу системы Apache Spark. Показано, что ее функциональность
позволяет организовать автоматическую обработку поступающих
радарных снимков в~виде последовательности операций (workflow),
которые необходимо выполнить над входными данными в~зависимости от
заданных ранее условий. Результаты обработки остаются доступными
в~системе в~виде устойчивых к~сбоям распределенных коллекций
данных (RDD-Resilient Distributed Data), что позволяет по~мере
поступления космических снимков и~их автоматической обработки,
согласно цепочке алгоритмов, на~каждом этапе получать/сохранять
промежуточный результат в~распределенную файловую систему HDFS.
Охарактеризованы особенности имплементации конкретных задач
процессинга радарных данных в~рамках предложенного подхода (расчет
фазы, корегистрация, формирование интерферограммы и~развертка фазы
методом роста регионов).  Представлена блок-схема алгоритма
развертки фазы с~возможностью его запуска на~платформах
с~использованием графических устройств, поддерживающих технологию
NVIDIA CUDA. Представлена адаптация ее к~системам
с~массово-параллельным исполнением заданий. Имплементация
алгоритма ориентирована на~вычисления для пары радарных
изображений на~одном вычислительном узле. Ускорение достигается
за~счет возможности одновременной обработки множества пар
изображений, равных количеству узлов кластера. Показан пример
реализаций методов работы с~потоками бинарных данных
(BinaryRecordsStream), осуществляющих мониторинг распределенной
файловой системы HDFS на~наличие поступающих радарных данных
и~чтение/запись их как бинарных файлов со~значением фиксированного
размера байт. В~качестве входных параметров используются каталог
и~размер одной записи в~байтах. В~заключении приведены результаты
тестирования разработанных алгоритмов на~демонстрационном
кластере. Показано, что при количестве узлов, равном восьми,
в~среднем возможно достижение 8-кратного прироста скорости работы
для такого же количества пар изображений по~сравнению с~их
последовательной обработкой на~отдельном вычислительном узле.
Результаты тестирования дают возможность повышения
производительности представленных алгоритмов при увеличении
количества узлов кластера без внесения изменений в~их реализацию,
что оправдывает применение распределенного подхода для решения
задач пре- и~постобработки радарных данных. Библиогр.~26 назв.
Ил.~4. Табл.~3.

{\it Ключевые слова}: Apache Spark, Apache Hadoop, распределенные
информационные системы, радарная интерферометрия, алгоритмы
обработки.

\end{list}

}

%\newpage
\vskip3.0mm

\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}

\noindent{\it  V. P. Potapov, M. A. Kostylev, S. E. Popov}

\vskip2mm\noindent{\bf THE STREAMING PROCESSING OF SAR DATA\\  IN
DISTRIBUTED ENVIRONMENT WITH APACHE SPARK}

\vskip1.5mm



{\footnotesize

\noindent Institute of Computational Technologies of the Siberian
Branch\\ of the Russian Academy of Sciences, 6, Academician M. A.
Lavrentiev pr., Novosibirsk,\\
630090, Russian Federation

\vskip2mm


\item This article presents a modern approach to creating a distributed program
complex based on mass-parallel technology for pre- and
postprocessing of SAR images. The unique features of the system is
the ability to work in real time mode with huge amounts of
streaming data and applying existing algorithms that are not used
for distributed processing on multiple nodes without changing the
algorithms' implementation. A comparison has been made of
distributed processing technologies based on which we have
selected Apache Spark. The ability to organise automatic
processing of input SAR images as a sequence of operations which
should be performed based on defined conditions is demonstrated.
The results of processing store in the system as fault tolerant
distributed collections of data (RDD-Resilient Distributed Data),
which allows getting and saving the intermediate results in the
distributed file system HDFS as and when new space images became
available and processed by the sequence of algorithms. This
article described the implementation for the specific tasks of SAR
data processing based on the suggested approach is described
(phase estimation, coregistration, interferogram creation and
phase unwrapping with region growing method). A scheme of the
phase unwrapping algorithm with the ability to use GPU and NVIDIA
CUDA technology is presented. An adaptation of the algorithm for
the mass-parallel systems is shown. The algorithm implementation
focused on processing pair of SAR images on one node. Performance
growth is achieved by simultaneous processing multiple images
whose number is equal to cluster nodes count. An example of
methods implementation for working with streaming binary data
(BinaryRecordStream) which perform monitoring of new SAR data in
distributed file system HDFS and reading\writing this data as
binary files with fixed bytes size is shown. A directory and size
of one record are used as the input parameters. The results of
testing developed algorithms on demonstration cluster is
presented. A possibility of getting up to eight times better
processing speed using eight nodes in a cluster for the same
images count in comparison with sequential processing on one node
is shown. Results of testing provide the ability to improve the
performance of presented algorithms without any changes in
implementation and this in turn justifies the utility of applying
distributed approach for SAR data processing. Refs~26. Figs~4.
Tables~3.

\textit{Keywords}: Apache Spark, Apache Hadoop, distributed
information systems, sar inter-\linebreak fometry, processing
algorithms.


}

\end{list}

\vskip 3mm



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\textbf{Введение.} Данные дистанционного зондирования Земли
получили широкое распространение практически во~всех отраслях как
науки, так и~промышленности и~используются для решения самых
разнообразных задач, число которых постоянно растет. Не
исключением стали и~радарные данные, получаемые с~космических
аппаратов радиолокационной съемки.

Основным аппаратом анализа радарных данных является метод радарной
дифференциальной интерферометрии (DInSAR), который занимается
построением цифровых моделей рельефа (ЦМР) на~основе расчета
разности фаз нескольких радарных снимков одной территории [1, 2].

В то~же время пре- и~постобработка радарных данных обусловлена
повышенными требованиями к~вычислительным ресурсам даже
на~современном аппаратном уровне. Тем не~менее математические
модели и~алгоритмизация, заложенные в~процедуры пре-
и~постобработки радарных данных, корректно могут быть перенесены
на~технологию параллельных вычислений. К~основным процедурам
обработки можно отнести, например, корегистрацию снимков [3],
расчет когерентности и~формирование интерферограммы [4], а~также
развертку фазы [5--8] и~последующий расчет ЦМР [6], которые можно
отнести к~наиболее ресурсоемким этапам.

Оптимизации и~ускорению работы, в~том числе и~за~счет
распараллеливания расчета математических алгоритмов в~процедурах
обработки радарных данных, посвящено большое количество научных
работ [6--14].

В статьях [6--11] авторы используют технологию CUDA для улучшения
производительности процедуры развертки фазы на~базе различных
математических моделей. В~частности, рассматриваются уравнение
Пуассона с~весовыми коэффициентами, метод сопряженных градиентов
[6, 7], метод роста регионов и~отсечения ветвей [8, 9],
компенсации фазового набега [10] и~совмещения (корегистрации)
радарных снимков [11]. В~работе [12] представлен алгоритм
генерации нативных (синтетических) радарных данных, симулирующих
различные ошибки/шумы принимающей/передающей части космических
аппаратов в~зависимости от наблюдаемой земной поверхности с~целью
выработки программных методов коррекции.

Наряду с~GPU имплементацией существуют программные реализации
алгоритмов на~базе параллельных вычислений на~CPU. В~работе [13]
предлагается интеграция технологии параллельных вычислений MPI
[15] c системой комплексной обработки радарных изображений Doris
(Delft object-oriented radar interferometric software) [16].
Рассмотрены основные этапы процессинга InSAR/PS-InSAR технологий,
включая наиболее ресурсоемкие (корегистрация, формирование
интерферограммы и~развертка фазы). Предложена стратегия
распараллеливания декомпозиции главного/подчиненного изображений
с~большим количеством сегментов и~частичным перекрытием границ,
обеспечивающая минимальное межпроцессорное взаи\-модействие.

Преимуществом подходов, показанных в~[6--14], является
алгоритмизация решений задач пре- и~постобработки, которые легко
переносятся на~параллельные вычисления, с~помощью уже широко
известных процедур, реализованных в~библиотеках для GPU и~CPU.
Так, в~работах [6, 10--15] за~основу взяты элементы пакетов CuFFT,
CuBLASS, CuSPARSE, PBLASS, FFTW, ScaLAPACK [17--19].

В последнее время в~структуре стандартного алгоритмического
аппарата DInSAR широкое распространение получил метод
интерферометрии малых базовых линий (SBaS), совместно использующий
длинные временные серии радарных изображений одной территории,
полученные за~счет повторяющейся геометрии съемки в~хронологически
упорядоченных промежутках времени [20]. SbaS относят к~одной
из~наиболее ресурсоемких технологий обработки радарных данных
[13]. Например, только на~начальном этапе производится
формирование интерферограмм на~базе комплексного перемножения всех
возможных пар главного/подчиненного изображений. Затем для каждой
парной интерферограммы проводится развертка фазы с~целью получения
полного смещения в~направлении на~спутник. При этом чаще всего
сначала применяют алгоритмы «минимальной стоимости», а~затем
алгоритм «роста регионов». Учитывая тот факт, что для выявления
динамики и~средней скорости изменения вертикальных смещений земной
поверхности с~погрешностью разности высот ЦМР не~более чем
$\pm$3~мм/пиксел необходимо как минимум 30 изображений,
на~отдельных стадиях расчетов возникает резкая деградация
производительности. Экспериментальные расчеты показывают время от
3 до~5~ч для 12~пар снимков небольшого разрешения в~$3000 \times
1000$ пикселей.

Учитывая, что в~настоящее время существует огромное количество
программно реализованных высокопроизводительных алгоритмов
технологических этапов обработки радарных данных, целесообразно
применять их совместно в~облачной инфраструктуре. Причем сама
облачная инфраструктура выступает как интегратор распределенного
исполнения программного кода на~данных, получаемых в~потоковом
режиме. Технологии распределенных вычислений в~облачной среде
широко распространены в~различных областях науки, однако нам
не~удалось найти применение последних в~сфере тематической
обработки именно радарных снимков. Поэтому задача разработки
интегрального программного комплекса для пре- и~постпроцессинга
радарных изображений в~распределенной среде
с~массово-параллельными механизмами (на примере Apache Spark)
является, на~наш взгляд, весьма актуальной для современной
радарной интерферометрии.

\textbf{Сравнение технологий распределенных вычислений.} При
выборе технологии распределенных вычислений были учтены
особенности пре- и~постпроцессинга радарных данных. Так,
популярные технологии параллельного программирования, построенные
по стандарту MPI (Message Passing Interface), например OpenMPI,
не~предлагают распределенного файлового хранилища, что вносит
ограничение на~возможные объемы обрабатываемой информации из-за
необходимости применения дорогостоящих систем хранения данных
и~отсутствия возможности их линейного масштабирования [21].

Сейчас все б\'{о}льшую популярность приобретают облачные системы
распределенной обработки данных на~базе технологии MapReduce.
Такие системы включают в~себя распределенную файловую систему,
обеспечивают отказоустойчивость при выходе из~строя отдельных
узлов кластера, повышают надежность хранения данных и~корректность
выполнения их обработки, а~также возможность использования
оборудования широкого назначения с~низкой стоимостью.

Для сравнения были взяты различные реализации технологии MapReduce
и рассмотрены применительно к~задачам обработки радарных данных
(табл. 1). Наиболее важным критерием при выборе вычислительной
платформы являлась возможность хранения промежуточных результатов
в оперативной памяти, что позволяло получить существенно
б\'{о}льшую производительность в~сравнении со~стандартным
подходом, например Hadoop MapReduce [22]. Такую функциональность
предоставляет платформа Apache Spark.

\vskip 2mm
\begin{center}
{\small

{\it Таблица 1.} {\bf Сравнение технологий распределенных
вычислений}

}

\vskip 3mm

{\footnotesize


\begin{tabular}{ | p{2.5cm} | p{2.2cm} | p{2.2cm} | p{2.7cm} | }
\hline  \multicolumn{1}{|c|}{Способ реализации} & \multicolumn{1}{|c|}{Apache Spark} &  \multicolumn{1}{|c|}{Tez} &  \multicolumn{1}{|c|}{Hadoop MapReduce} \\
\hline Интерактивный режим & Да & Да & Нет\\
\hline Языки програм- & Java, Scala, & Java & Java \\
мирования &  Python, R & & \\
\hline Работа в~потоко- & Да & Нет & Нет \\
вом режиме & & & \\
\hline Хранение проме- & RAM, HDD & RAM, HDD & HDD \\
жуточных результатов & & & \\
\hline
\end{tabular}


}
\end{center}





%\begin{table}[H]
%\caption{Сравнение технологий распределенных вычислений}
%\begin{tabular}{ | p{3cm} | p{3cm} | p{3cm} | p{3cm} | }
%\hline  \multicolumn{1}{|c|}{Способ реализации} & \multicolumn{1}{|c|}{Apache Spark} &  \multicolumn{1}{|c|}{Tez} &  \multicolumn{1}{|c|}{Hadoop MapReduce} \\
%\hline Интерактивный режим & Да & Да & Нет\\
%\hline Языки програм- & Java, Scala, & Java & Java \\
%мирования &  Python, R & & \\
%\hline Работа в~потоко- & Да & Нет & Нет \\
%вом режиме & & & \\
%\hline Хранение проме- & RAM, HDD & RAM, HDD & HDD \\
%жуточных результатов & & & \\
%\hline
%\end{tabular} \end{table}

Важное преимущество системы Apache Spark --- потоковая обработка
данных, которая упрощает разработку автоматической системы пре-
и~постпроцессинга из-за отсутствия необходимости создавать
собственную программную реализацию работы с~потоками [23]. Ее
применение позволяет организовать автоматическую обработку
поступающих снимков без непосредственного участия пользователя.
При таком подходе процесс пре- и~постобработки будет представлен
в~виде последовательности операций, которые необходимо выполнить
для входных данных в~зависимости от заданных ранее условий.
Результаты этой обработки будут доступны в~системе наряду
с~исходными данными. Таким образом, пользователю системы
достаточно указать источник входных данных, а~затем, по~мере
поступления снимков и~их автоматической обработки согласно цепочке
алгоритмов, на~каждом этапе получать/сохранять промежуточный
результат в~распределенную файловую систему.

На основании результатов сравнения нами была выбрана технология
массово-параллельных вычислений Apache Spark. Еe преимуществами
являются:

%\begin{itemize}%[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex,leftmargin=0pt,itemindent=3em]
%\item

$\bullet$\,\,высокая масштабируемость, достигаемая за~счет
добавления новых узлов в~вычислительный кластер, без необходимости
внесения
изменений в~применяемые алгоритмы; %\item

$\bullet$\,\,встроенная возможность работы в~режиме реального
времени, позволяющая построить алгоритмы потоковой обработки
радарных
данных; %\item

$\bullet$\,\,большое количество вспомогательных программных
решений, необходимых для организации системы, которая будет поддерживать полный цикл предметных задач. %\\
%\end{itemize}

\textbf{Постановка задачи.} Создадим распределенный программный
комплекс на~базе массово-параллельной технологии Apache Spark для
потоковой пре- и~постобработки радарных снимков со~следующими
функциональными особенностями:

%\begin{enumerate}%[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex,leftmargin=0pt,itemindent=3em,label={\arabic*)}]
%\item
$1)$\,\,возможность интеграции в~программный код существующих
высокопроизводительных решений для отдельных этапов (в частности,
расчет когерентности, формирование интерферограмм,
развертка фазы) обработки радарных ДДЗ;%
%\item

$2)$\,\,возможность автоматического выбора высокопроизводительной
параллельной технологии (например, CUDA, MPI и~пр.) в~расчетном
ядре
реализуемых алгоритмов;%
%\item

$3)$\,\,использование общего распределенного пространства для
хранения промежуточных результатов расчетов в~виде бинарных данных
стандартов BSQ с~возможностью доступа к~ним отдельных алгоритмов
последующих этапов обработки
с~разных узлов экосистемы Apache Spark.%\\
\end{enumerate}

\textbf{Программная реализация.} Для решения задач пре-
и~постобработки радарных снимков был разработан распределенный
программный комплекс на~базе технологий обработки больших данных
Apache BigData. Для этого были использованы языки программирования
Java и~Scala, методы работы с~распределенными наборами данных
(Spark RDD), операции над элементами которых могут выполняться
параллельно. На рис.~1 представлена архитектура программного
комплекса.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%fig1


\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{04/fig1}

\vskip 2mm {\small{\it Рис. 1.} Архитектура распределенного
программного комплекса} }
\end{figure}



%\begin{figure}[H]
%\centering
%\includegraphics[width=1\textwidth]{pic1}\\
%\caption{Архитектура распределенного программного комплекса}
%\label{fig.pic1}
%\end{figure}

Разработанное решение обладает такими функциональными
особенностями.

Распределенная отказоустойчивая файловая система на~базе
технологии HDFS позволяет хранить данные и~их производные на~всех
этапах обработки и~предоставлять доступ к~ним с~различных
вычислительных узлов кластера. Данный подход позволил отказаться
от применения дорогостоящих систем хранения и~привел к~увеличению
доступного пространства за~счет простого добавления новых узлов
в~кластер. Отвечает за~компонент <<Файловый менеджер>>,
представленный на~рис.~1. HDFS является базовым компонентом Apache
Hadoop и~имеет тесную интеграцию с~платформой Apache Spark.

Распределенная вычислительная платформа на~базе технологии Apache
Spark позволяет производить параллельную обработку потоковых
радарных данных на~множестве узлов с~максимально возможным объемом
обрабатываемых данных, ограниченным только количеством узлов
кластера. Масштабирование программного комплекса осуществляется
за~счет добавления новых узлов без изменения программной
реализации используемых алгоритмов. Отвечает за~компоненты
<<Вычислительный узел>> (см.~рис.~1).

Система планирования потоков работ на~базе технологии Apache Oozie
[24] дает возможность организовать процесс обработки потока
радарных данных в~виде последовательности действий, каждое
из~которых выполняется после успешного завершения предыдущего.
Такие последовательности могут запускаться автоматически при
поступлении новых данных, по~запросу пользователя либо
по~расписанию. Отвечает за~компонент <<Планировщик потоков
заданий>> (см. рис.~1). Данная системa была выбрана для
организации процесса пре- и~постобработки радарных данных в~виде
последовательности заданий, которые необходимо выполнить для
входных данных в~зависимости от различных условий.

Пользовательское веб-приложение на~базе технологии Apache Hue [25]
предоставляет возможность взаимодействия с~программным комплексом.
Приложение состоит из~файлового менеджера, позволяющего загружать
новые файлы, а~также просматривать и~редактировать уже
существующие файлы в~распределенной файловой системе. Вторым
важным компонентом системы является интегрированная среда
управления потоками работ с~возможностью их создания
и~редактирования, запуска и~мониторинга. Отвечает за~компонент
<<Пользовательское веб-приложение>>, представленное на~рис.~1.
Выбор данной технологии обусловлен интеграцией со~всеми
приведенными выше компонентами. Она позволяет пользователю
просматривать и~изменять операции, выполняемые над текущими
входными данными, осуществлять мониторинг состояния системы
(просмотр выполняемых и~выполненных работ), а~также получать
доступ к~исходным данным и~результатам их обработки через
встроенный файловый менеджер, интегрированный с~распределенной
файловой системой HDFS.

Для организации потоковой обработки используется метод Spark
Streaming API binaryRecordsStream(). С~его помощью можно создать
входной поток бинарных данных, который будет осуществлять
мониторинг распределенной файловой системы, совместимой с~HDFS
на~наличие новых файлов, и~считывать их как бинарный файл
со~значением фиксированного размера байт. В~качестве входных
параметров ис\-поль\-зуют\-ся каталог для мониторинга и~размер
одной записи в~файле в~байтах. Далее, на~полученном входном потоке
выполняется метод forEachRDD(). Входным параметром является
функция, которая реализуется для каждого нового изображения
из~входного потока в~виде RDD (Resilient Distributed Datasets),
состоящего из~значений, при\-ни\-мае\-мых конкретным пикселом
снимка.

Для загрузки исходных данных из~файловой системы HDFS запускается
метод Spark API binaryFiles(). Входным параметром служит путь
к~каталогу с~исходными данными (пакет). Результатом работы
является RDD, состоящий из~пар, каждая их которых содержит имя
файла и~соответствующий ему поток данных. С~помощью метода keyBy()
для каждого элемента пары определяется его ключ, как имя файла без
префикса. Получаемый таким образом RDD, содержащий бинарную
последовательность интерферограммы и~значений ее когерентности,
имеет уникальный ключ. Текущие значения RDD группируются по~ключу
методом API groupByKey(). Передача бинарной последовательности
и~запуск программного кода алгоритма развертки фазы производятся
с~помощью функции map(). Программный код функции map() проверяет
аппаратную доступность технологии CUDA на~каждом узле,
в~зависимости от этого выбирается имплементация алгоритма
с~использованием CPU или GPU. Разработанному алгоритму передаются
два массива байт (интерферограмма и~значения ее когерентности),
содержащиеся в~RDD, полученный результат сохраняется
в~распределенную файловую систему HDFS напрямую.

В зависимости от реализации конкретного алгоритма деление входных
данных осуществляется такими способами:
%\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex,leftmargin=0pt,itemindent=3em,label={\arabic*)}]
%\item

$1)$\,\,отдельные файлы радарных данных, предназначенные для
обработки, делятся на~области; результат для каждой области
вычисляется на~отдельном узле, полученные данные объединяются
и~сохраняются в~готовое изображение;
%\item

$2)$\,\,отдельное изображение обрабатывается целиком
на~вычислительном узле без деления на~области; параллелизация
достигается за~счет обработки большого количества изображений
на~множестве узлов.
%\end{enumerate}

Рассмотрим реализацию представленной выше обобщенной диаграммы
потоков данных на~примере алгоритма расчета фазы [26]. Блок-схему
предложенного алгоритма иллюстрирует рис.~2.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%fig2


\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{04/fig2}

\vskip 2mm {\small{\it Рис. 2.} Алгоритм развертки
интерферометрической фазы} }
\end{figure}




%\begin{figure}[H]
%\centering
%\includegraphics[width=1\textwidth]{pic2.png}\\
%\caption{Алгоритм развертки интерферометрической фазы}
%\label{fig.pic2}
%\end{figure}

Как показано выше на~диаграмме, в~процессе работы алгоритма
проводится параллельная развертка интерферометрической фазы,
а~количество одновременно выполняемых расчетов определяется
количеством узлов в~кластере. Входными данными являются массив
значений интерферограммы в~каждой точке изображения и~массив
величин когерентности каждого значения интерферограммы. В~общем
виде этап развертки фазы состоит из~следующих шагов:

% \begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex,leftmargin=0pt,itemindent=3em,label={\arabic*)}]
%\item

$1.$\,\,Выбираются начальные точки с~наибольшей когерентностью,
они объявляются развернутыми и~образуют регионы. Региону
с~наибольшей когерентностью начальной точки присваивается номер 1
и~так далее, при уменьшении значения когерентности начальной точки
увеличивается номер региона.
%\item

$2.$\,\,Для каждой развернутой точки ищутся соседние неразвернутые
(целевые) точки, образующие кольца роста регионов. Назовем этот
процесс итерацией роста.
%\item

$3.$\,\,Для каждой целевой точки кольца роста вычисляется
предсказываемое значение по~формуле
\begin{equation*}
\phi^\rho =
\frac{\sum^{N_\upsilon}_{\kappa=1}\omega^\kappa\phi^\rho_\kappa}{\sum^{N_\upsilon}_{\kappa=1}\omega^\kappa},
\end{equation*}
где $N_u>1$ (за исключением области начальных точек), $N_u$~---
количество соседних пикселей  с~развернутой фазой;
$\phi_k^p=2\phi[k]-\phi[k']$, $\omega^k=1.0$, если на~пути
предсказания к~точкe лежат два развернутых пиксела;
$\phi_k^p=\phi[k]$, $\omega^k=0.5$~--- если один развернутый
пиксел; $\phi[k]$ и~$\phi[k']$~--- значения развернутых фаз
на~пути предсказания соответственно.
%\item

$4.$\,\,Рассчитывается число неоднозначности $m$
\begin{equation*}
m={\rm nint}((\phi^p-\varphi_\omega)/2\pi),
\end{equation*}
в которой $\varphi_\omega$ --- значение свернутой (относительной)
фазы целевого пиксела, nint~--- оператор взятия ближайшего целого.
%\item

$5.$\,\,Рассчитывается величина развернутой (абсолютной) фазы
$\phi_u= \varphi_\omega+2\pim$.
%\item

$6.$\,\,Значение развернутой фазы в~целевой точке принимается,
если выполняются условия надежности $d^p< T_p$, $d_u< T_u$
и~когерентность в~целевой точке больше $T_c$, где
$d^p=\frac{\sum_{k=1}^{N_u}\omega^k
|\phi_k^p-\phi^p|}{\sum_{k=1}^{N_u}\omega^k }$,
$d_u=|\phi_u-\phi^p|$, $T_p=T_u=\pi/2$, $T_p=T_u=\pi/2$,
$T_c=0.9…0.2$, $T_c$~--- параметр релаксации. Если два региона
имеют точки пересечения, запускается процедура их объединения.\\
%\item
\indent$7.$\,\,Определяется количество общих точек $(N_ov)$.

%\item

$8.$\,\,Для каждой общей точки вычисляется разность их чисел
неоднозначности $(D_md=m_R1-m_R2)$, $m_R1$, $m_R2$~--- числа
неоднозначности общей точки в~регионах с~номерами R1 и~R2
соответственно.
%\item

$9.$\,\,Находятся мода значений разностей $D_md$ и~количество
точек, образующих ее $(N_c)$.
%\item

$10.$\,\,Если $\frac{N_c}{N_{ov}} \geq T_rr$ и~$N_ov \geq T_rn$,
где $T_rr=0.75$, $T_rn=3$,  то~регионы объединяются. В~точках
склейки величина абсолютной фазы берется для региона с~наименьшим
номером, остальные точки исключаются из~алгоритма. Если условия
не~выполнены, исключаются все общие точки.
%\end{enumerate}

В табл. 2 дано описание объектов (массивов), используемых
в~программной реализации усовершенствованного алгоритма роста
регионов.


\vskip 2mm
\begin{center}
{\small

{\it Таблица 2.} {\bf Основные объекты (массивы) алгоритма}

}

\vskip 3mm

{\footnotesize

%\begin{table}[H]
%\caption{Основные объекты (массивы) алгоритма}
\begin{tabular}{ | p{4.1cm} | p{8.9cm} |}
\hline \multicolumn{1}{|c|}{Название объекта, массива} &
\multicolumn{1}{|c|}{Описание} \\ \hline isUnwrapped & Флаг
остановки процедуры итераций роста\\ \hline isShared & Флаг
запуска процедуры объединения регионов \\ \hline Nu & Счетчик
количества развернутых соседних точек \\ \hline
D={$-$N$-$1,$-$N,$-$N+1,$-$1,1,N$-$1, N,N+1}
и~D1={$-$2N$-$2,$-$2N, $-$2N+2,$-$2,2,2N$-$2,2N,2N+2} & Массивы
констант для получения значений индексов соседних точек к~целевой
 \\ \hline
sum(arg, index) и~\hfill \break round\_int(arg)  & Функции
нахождения суммы аргументов с~указанными индексами и~округление
до~ближайшего целого соответственно
 \\ \hline
C\_idx\_gpu & Массив индексов целевых точек W\_gpu,
удовлетворяющих текущим параметрам надежности (когерентность
больше T\_c) \\ \hline U\_gpu & Массив значений развернутых фаз \\
\hline RM\_gpu & Массив номеров регионов \\ \hline
S\_pin  & Массив общих точек \\
\hline
\end{tabular}
%\end{table}

}
\end{center}

%Ниже представлена блок-схема этапа развертки интерферометрической
%фазы.



В табл. 3 приведены реализованные алгоритмы обработки радарных
данных с~указанием особенностей их распараллеливания.

\vskip 2mm
\begin{center}
{\small

{\it Таблица 3.} {\bf Особенности реализации различных алгоритмов}

}

\vskip 3mm

{\footnotesize
%\begin{table}[H]
%\centering \caption{Особенности реализации различных алгоритмов}

\begin{tabular}{ | p{3cm} | p{4.2cm} | p{5cm} |}
\hline \multicolumn{1}{|c|}{Алгоритм} &
\multicolumn{1}{|c|}{Входные данные} &
\multicolumn{1}{|c|}{Особенности реализации}
\\ \hline
Расчет фазы & \multirow{4}{*}{}{Бинарные представления ра- дарных
данных аппарата Cos- mo-SkyMed уровня L1A в~фор- мате (.hdr +
SLCBinary) на примере Exelis ENVI} & Изображение делится
на~отдельные значения (точки) последовательно, каждое изображение
рассчитывается на~множестве узлов по~частям
\\ \cline{1-1} \cline{3-3}
Формирование интерферограммы & & Изображение делится на~регионы
заданного размера ($7 \times 7$ точек), каждое изображение
рассчитывается на множестве узлов по~частям \\ \cline{1-1}
Расчет %& &  \\
когерентности & & \\
\cline{1-1} \cline{3-3}
Развертка фазы & & Изображение обрабатывается целиком на~отдельном вычислительном узле, производится параллельная обработка множества изображений \\
\hline
\end{tabular}
%\end{table}

}
\end{center}

Расчетная часть представленных алгоритмов реализована
в~соответствии с~аналогичными схемами в~основных системах
обработки радарных данных. Так, расчет фазы и~формирование
интерферограммы производятся согласно выражениям

\begin{equation*}
Phase_{i,j}={\rm arctan}
\left(\frac{(float)I_{i,j}}{(float)(I_{i,j}\gg 32)}\right),
\end{equation*}

\begin{equation*}
\begin{array}{c}%split}
I_{i,j}= (float)(SLC_{i,j}^M * SLC_{i,j}^S)+(float)(SLC_{i,j}^M \gg 8)*(SLC_{i,j}^S \gg 8),\\[0.3cm]
I_{i,j} \ll 32=(float)(-(SLC_{i,j}^M*(SLC_{i,j}^S \gg 8))+(float)((SLC_{i,j}^M \gg 8)*SLC_{i,j}^S)),\\[0.3cm]
I_{i,j}=(I_{i,j} ) |((I_{i,j} ) \ll 32),
\end{array}%{c}split}
\end{equation*}
а расчет когерентности --- по~формуле

\begin{equation*}
C_{i,j}=\frac{\frac{1}{49}\sum_{i=0}^7\sum_{j=0}^7|I_{i,j} |
}{(\frac{1}{49} \sum_{i=0}^7\sum_{j=0}^7|SLC_{i,j}^M |^2 )*(1/49
\sum_{i=0}^7\sum_{j=0}^7|SLC_{i,j}^s |^2 )}.
\end{equation*}

Для развертки интерферометрической фазы применяется алгоритм роста
ре\-гио\-нов. Особенностью этого способа обработки радарных данных
является использование распределенных технологий (HDFS и~Apache
Spark), что позволяет применять  алгоритмы для потоков данных.
На рис.~3 показан графический интерфейс разработанного алгоритма в~виде workflow-задания развертки интерферометрической фазы. \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%fig3

\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{04/fig3}

\vskip 2mm {\small{\it Рис. 3.} Графический интерфейс
workflow-задания\\ развертки интерферометрической фазы} }
\end{figure}

%\begin{figure}
%\centering
%\includegraphics[width=1\textwidth]{pic3.png}\\
%\caption{Графический интерфейс workflow-задания развертки
%интерферометрической фазы} \label{fig.pic3}
%\end{figure}


\textbf{Результаты тестирования.} Разработанные алгоритмы были
протестированы на~кластере из~четырех и~восьми узлов, созданном
с~использованием CDH5-дистрибутива среды Hadoop. Также вычисления
были произведены на~отдельном узле без применения распределенного
подхода.

При создании кластера была выбрана версия среды CDH 5.7.0, которая
включает следующие компоненты: Apache HDFS 2.6, Apache Spark
1.6.0, Apache Hue 3.9, Apache Oozie 1.7. Компоненты хранения
и~обработки данных были установлены на~каждом узле кластера
(slave-узлы), в~то время как система управления потоками работ
и~пользовательское веб-приложение были установлены только на~одном
узле (master-узел). Все узлы кластера были подключены к~локальной
вычислительной сети с~пропускной способностью 1 ГБит/c. При
проведении расчетов на~отдельном компьютере был использован только
вычислительный компонент представленного программного комплекса
(Apache Spark), так как остальные компоненты целесообразно
применять только для кластера.

В качестве тестовых данных были выбраны радарные изображения
размера 16~384 $\times$ 16~384 точек, с~объемом одного файла 2~Гб.
Для расчета относительной фазы было взято одно изображение, а~для
формирования интерферограммы, расчета когерентности и~развертки
фазы~--- пара изображений, что обусловлено особенностями работы
таких алгоритмов.

Результаты тестирования приведены на~рис.~4. Каждый узел кластера
соответствует следующей конфигурации: Ubuntu 16.04; Oracle JDK
1.8; Intel Xeon E5-2620 v2 @ 2.10GHz; 6GB RAM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fig4

\begin{figure}[h!]
\centering{
\includegraphics[scale=1]{04/fig4}

\vskip 2mm {\small{\it Рис. 4.} Результаты тестирования} }
\end{figure}



%\begin{figure}[H] \centering \includegraphics[width=1\textwidth]{pic4.png}\\
%\caption{Результаты тестирования} \label{fig.pic4}
%\end{figure}


Важно отметить, что для алгоритмов расчета фазы, формирования
интерферограммы и~определения когерентности применяется разделение
на уровне изображения, за~счет чего и~достигается ускорение при
обработке отдельного снимка относительно локального подхода.
Алгоритм развертки фазы предполагает проведение всех необходимых
расчетов для одной пары изображений на~одном вычислительном узле,
а~ускорение достигается за~счет возможности одновременной
обработки изображений, количество которых равно количеству узлов
кластера. Так, при количестве узлов кластера, равном 8, в~среднем
возможно достижение 8-кратного прироста скорости работы для восьми
пар изображений по~сравнению с~их последовательной обработкой
на~отдельном вычислительном узле.

Результаты тестирования показывают возможность повышения
производительности представленных алгоритмов при увеличении
количества узлов кластера без внесения изменений в~их реализацию,
что оправдывает применение распределенного подхода для решения
данной задачи.


%Каждый узел кластера соответствует следующей конфигурации: Ubuntu
%16.04; Oracle JDK 1.8; Intel Xeon E5-2620 v2 @ 2.10GHz; 6GB
%RAM. %\\


\textbf{Заключение.} В~результате анализа различных подходов,
применяемых при обработке радарных данных, а~также обзора
технологий распределенных вычислений был предложен и~реализован
распределенный программный комплекс на~базе массово-параллельной
технологии Apache Spark для потоковой пре- и~постобработки
снимков. По сравнению с~традиционными подходами к~обработке
радарных изображений, в~которых параллельные вычисления либо
не~используются, либо применяются только для повышения
производительности расчетов, предложенное решение ориентировано
на~обработку большого количества потоковых данных. Программная
реализация комплекса содержит веб-интерфейс, позволяющий
пользователю взаимодействовать с~кластером, получая доступ
к~распределенной файловой системе, а~также создавать и~исполнять
существующие потоки работ, существенно уменьшая вычислительные
затраты и~увеличивая эргономику работы с~системой.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{04/lit-ra}

%%%%%N DOI в~ссылке!!!!!!!!!!

\input{04/ref-s}

%%%%%N DOI в~ссылке!!!!!!!!!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\footnotesize



\vskip 3mm

%\thispagestyle{empty}



\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~13.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~13.~Вып.~\issuenum}}}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %


\noindent Статья рекомендована к~печати проф. В. Ю. Добрыниным.

\vskip 1mm

\noindent Статья поступила в~редакцию 15 сентября 2016~г.

\vskip 1mm

\noindent Статья принята к~печати 11 апреля 2017~г.


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vskip 5mm

%{\footnotesize

%\noindent К\,о\,н\,т\,а\,к\,т\,н\,а\,я\,
%и\,н\,ф\,о\,р\,м\,а\,ц\,и\,я \nopagebreak \vskip 3mm

%{\it Балонин Николай Алексеевич}~-- доктор технических наук,
%профессор; e-mail: korbendfs@mail.ru

%{\it Сергеев Михаил Борисович}~-- доктор технических наук,
%профессор,  директор; e-mail: mbse@mail.ru

%\vskip 2mm

%\emph{Balonin Nikolaj Alekseevich}~-- doctor of technical
%sciences, professor; e-mail: korbendfs@mail.ru


%\emph{Sergeev Mikhail Borisovich}~-- doctor of technical sciences,
%director; e-mail: mbse@mail.ru


%}


%\thispagestyle{empty}
