


\zagol{519.688}{Е.~А.~Малютин, Д.~Ю.~Бугайченко, А.~Н.~Мишенин}{ВЫДЕЛЕНИЕ ТЕКСТОВЫХ ТРЕНДОВ В~СОЦИАЛЬНОЙ СЕТИ OK%$^{*}$
}{



\vspace{-3mm}\parindent=7mm



%{\copyright} А.~В.~Буре, 2014

\emph{Малютин Евгений Алексеевич}  --- магистр;
eugeny.malyutin@gmail.com


\emph{Бугайченко Дмитрий Юрьевич}  --- кандидат
физико-математических наук;\\ dmitrybugaychenko@gmail.com


\emph{Мишенин Алексей Николаевич}  --- старший преподаватель;
alexey.mishenin@gmail.com






\vskip 4.0mm


\emph{Malyutin Evgeniy Alekseevich}  --- magister;
eugeny.malyutin@gmail.com


\emph{Bugaichenko Dmitriy Yurievich}  --- PhD of physical and
mathematical science;\\ dmitrybugaychenko@gmail.com


\emph{Mishenin Alexey Nikolayevich}  --- senior teacher;
alexey.mishenin@gmail.com


\vskip 4.0mm



%$^{*}$ Работа выполнена при финансовой поддержке
%Санкт-Петербургского государственного университета (грант
%№~9.38.205.2014).

{\copyright} Санкт-Петербургский государственный университет,
\issueyear%

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
%\fancyfoot[LO]{{\footnotesize\emph{\doivyp07 } }\hfill\thepage}%
\fancyfoot[LO]{{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum08 } }\hfill\thepage}%
%\fancyfoot[RE]{\thepage\hfill{\footnotesize\emph{\doivyp07 } } }%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum08}}}%
%\fancyfoot[LO]{\hfill{\fontsize{10.5}{10.5}\selectfont \thepage}}%
%\fancyfoot[RE]{{\fontsize{10.5}{10.5}\selectfont \thepage}\hfill}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

\noindentСанкт-Петербургский государственный университет,
Российская Федерация, \\ 199034, Санкт-Петербург, Университетская
наб., 7--9




\vskip4.0mm


\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}


\item Социальные сети все чаще выступают не только как средство
досуга или развлечения, но и~как канал распространения информации,
заменяя собой традиционные СМИ. В~данной статье представлена
модель масштабируемой системы выделения текстовых трендов,
реализованная в~социальной сети~ОК. Акторы (пользователи
и~коммьюнити) совместно конструируют широкую новостную повестку,
которая обладает определенной спецификой:

\vspace{-.5mm}$\bullet$~~{текст написан пользователями, а~не
профессиональными журналистами, что усложняет его обработку;}

\vspace{-.5mm}$\bullet$~~{пользователи социальной сети генерируют
текст на разных языках, что в~классическом подходе к анализу
медиапространства требует привлечения большого количества
высокооплачиваемых специалистов;}

\vspace{-.5mm}$\bullet$~~{учитывая характер современного
информационного пространства и~время отклика социальной сети,
необходима система, способная работать в~режиме реального
времени;}

\vspace{-.5mm}$\bullet$~~социальные сети зачастую используются
спамерами как площадка для продвижения и~навязчивой рекламы, что
требует привлечения дополнительных средств для фильтрации
подобного контента.

\vspace{.5mm}\noindentИспользование традиционных средств
медиаанализа представляется крайне затруднительным, что
естественным образом формирует запрос на разработку и внедрение
программных средств детектирования и~анализа текстовых трендов.
В~научной литературе при решении подобных задач предлагается
использование одного из двух подходов: тематического моделирования
с~последующим анализом эволюции выделенных тем или построения
дистрибутивных моделей, основанных на отслеживании частотных
характеристик термов в корпусе. В~статье приведен анализ
существующих научных работ, основанных на обоих подходах с~учетом
специфики, предполагающей применение данной модели в рамках
социальной сети. В~результате было принято решение использовать
дистрибутивную модель в~качестве основы дальнейшей системы. OK~---
одна из крупнейших социальных сетей на территории России и стран
СНГ, акторы которой генерируют более 100M символов текста в день.
Даже базовая обработка подобного потока информации является
тяжелой технической задачей, так что при разработке необходимо
прибегать к методам анализа <<больших данных>>. Система
детектирования трендов состоит из трех компонент:

\vspace{-.5mm}$\bullet$}~~{пакетный компонент, реализованный на
основе фреймворка Apache Spark;}

\vspace{-.5mm}$\bullet$~~{потоковый компонент, реализованный на
основе Apache Samza;}

\vspace{-.5mm}$\bullet$~~{mini-batch-компонент, реализованный на
основе Spark Streaming.}

\vspace{.5mm}\noindentВ статье подробно описаны архитектура
и~технические особенности каждого из компонентов, приведены
результаты работы системы, а~также направления для дальнейшего
исследования и~развития. Библиогр. 13~назв. Ил.~7. Табл.~1.

{\it Ключевые слова}: анализ естественного языка, выделение
трендов, большие данные.

\end{list}

}

%\vskip3mm
\newpage

\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}

\noindent{\it E.~A.~Malyutin, D.~Y.~Bugaichenko, A.~N.~Mishenin}

\vskip2mm \noindent{\bf TEXTUAL TRENDS DETECTION AT OK}

\vskip3mm


{\footnotesize


\noindent St.~Petersburg State University, 7--9, Universitetskaya
nab., St.~Petersburg,\\ 199034, Russian Federation



\vskip3.0mm


\item Social networks now serve not as a mere medium for entertainment,
but as an information distribution channel that is replacing
classical mass media. In this article we describe a scalable trend
detection system implemented with the social network OK. Actors
(users and communities) of social networks form a broad agenda.
The content of social networks is specific:

$\bullet$\,\,UGC (user generated content) is difficult to process;

$\bullet$\,\,actors generate a multilingual text. This requires
attracting a large number of highly paid professionals in the case
of classical media analysis;

$\bullet$\,\,modern social networks comprise a highly-connected
society with high ``response time''.  Therefore, the system must
work in real time;

$\bullet$\,\,social networks are used by spammers as a platform
for promotion and obtrusive advertising, therefore the system
should contain the ability to filter spam content.

\vspace{2mm}\noindent Applying standard methods of media analysis
to this seems impossible. It creates a natural demand for
developing and implementing textual trend detection and analysis
software. There are two main approaches of trend detection in
academic papers: topic modeling (and further topics evolutionary
analysis) and distributive models based on frequency-like
properties of distinct terms. We conducted an analysis of
scientific papers using both approaches taking into account the
specific features of social networks. As a result of research, it
was decided to use distributive models as a base for the system
development. OK is one of the largest social networks in Russia
and the CIS countries. Actors generate over 100M symbols of text
every day. Even basic processing is a serious technical problem.
So we are forced to use Big Data approaches through the
development. We introduce lambda-architecture based on three main
components:

$\bullet$\,\,daily-batch processing component, based on Apache
Spark;

$\bullet$\,\,streaming processing component, based on Apache
Samza;

$\bullet$\,\,mini-batch processing component, based on Spark
Streaming.

\noindent The article describes in detail the architecture and
technical features of each component. In conclusion we present the
results of operating the system as well as discuss areas for
further research and development. Refs~13. Figs~7. Table~1.

\textit{Keywords}: natural language processing, trend detection,
big data.


}

\end{list}


\vskip5mm

\textbf{Введение.} В~условиях современного информационного
общества социальные сети, выступая как источник и~канал
информации, заменяют собой традиционные СМИ. Пользователи
и~сообщества совместно конструируют широкую новостную повестку
крайне разнообразной тематики. Наличие подобного открытого
источника фор\-ми\-рует широкий спектр задач для специалистов
в~области анализа данных.

Одна из~этих задач~--- детектирование и~анализ текстовых трендов:
явлений или событий, набирающих популярность и~обсуждаемых
пользователями. Методы медиаанализа и~выделения трендов,
применимые к традиционным СМИ, почти невозможно адаптировать
к~контенту, генерируемому акторами социальной сети по~следующим
причинам:
\begin{itemize}\begin{itemize}%[topsep=0pt, noitemsep]
\item текст написан пользователями, а~не профессиональными журналистами, что усложняет обработку и~извлечение информации;
\item пользователи социальной сети генерируют текст на~разных языках, что в~классическом подходе к~анализу медиапространства требует привлечения большого количества высокооплачиваемых специалистов;
\item учитывая характер современного информационного пространства и~время отклика социальной сети, необходима система, способная работать в~режиме реального времени;
\end{itemize}\end{itemize}%
\newpage%

\begin{itemize}\begin{itemize}
\item социальные сети зачастую используются спамерами как площадка для продвижения и~навязчивой рекламы. Для стабильной и~надежной работы системы следует использовать механизмы текстовой дедупликации.
\end{itemize}\end{itemize}

Стоит отметить, что даже базовая агрегация подобного новостного
потока~--- сложная техническая задача. В~данной работе
представлена система обнаружения и~анализа текстовых трендов
в~рамках социальной сети OK.  Кроме того, описаны средства
и~технологии, позволившие реализовать эту систему.

\textbf{Обзор литературы.} Несмотря на~то, что имеется большое
количество исследований, посвященных задачам обработки
естественного языка (в том числе и~для русского), работ по~задаче
детектирования и~анализа текстовых трендов на~русском не~имеется.
Однако на~английском языке они есть. Их можно разделить на группы,
предполагающие: $1$) системы, базирующиеся на~тематическом
моделировании [1,\ 2] и~дальнейшем анализе изменения выделенных
тематик (тематические); $2)$ следующие модели, основывающиеся
на~различного рода статистических характеристиках отдельных термов
(дистрибутивные) [3,\ 4].

Тематические модели не~подходят для дальнейшего исследования по
целому ряду причин:
\begin{itemize}\begin{itemize}%[topsep=0pt,noitemsep]
\item большая часть моделей предполагает априорное знание количества тем в~корпусе;
\item в~исходном виде тематическое моделирование осуществляется без учета временного фактора, внедрение времени производится путем итеративного пе\-ре\-строе\-ния моделей и~отслеживания <<изменений>> выделенных тем, однако рассматриваемые способы изучения эволюции тем не~позволяют как-либо оценить ее <<популярность>>;
\item подобные модели так или иначе предполагают некоторую дискретизацию по~времени, не~позволяя проводить анализ в~режиме реального времени;
\item сомнительные возможности для масштабирования.
\end{itemize}\end{itemize}

Дистрибутивные модели, в~отличиe от~тематических, лишены этих
проблем. Они базируются на~выделении <<ключевых>> слов
из~пространства словарей, основываясь на~их <<популярности>>,
отличаясь лишь способами формализации <<популярности>>
(<<трендовости>>) и~еe расчeта. Но и~при таком подходе появляются
некоторые проблемы:
\begin{itemize}\begin{itemize}%[topsep=0pt,noitemsep]
\item в~рассмотренных работах используются усеченные наборы данных, не~соотносимые с~реальными объемами;
\item нет работ, прямо указывающих на~возможность реализации подобной системы в~реальном окружении;
\item зачастую обнаруженные тренды сложно интерпретировать напрямую.
\end{itemize}\end{itemize}

\textbf{Постановка задачи.} Обычно, когда говорят о~<<трендовых>>
явлениях, имеются в~виду самые популярные. Однако подобный
<<наивный>> подход не~совсем верен. Если смотреть на~явления
с~точки зрения пользователя, его больше интересует не~популярность
явления, а~актуальность, новизна. Таким образом,
<<трендовость>>~--- это рост популярности некоторой темы,
взвешенная в~ее историческом контексте. Хорошим примером тренда
являются профессиональные праздники (<<День сотрудника Полиции>>)
или новостные события (например, взрывы в~аэропорту в~Брюсселе).

ОК~--- одна из~крупнейших социальных сетей России и~стран СНГ.
Ежедневно в~нее заходят около 40 млн пользователей, которые
совместно с~миллионом активных сообществ генерируют около 100M
символов текста в~день более чем на~15~языках\ (использовались
тексты и~описания медиаконтента (фото и~видео) с~открытых страниц
пользователей и~сообществ). Необходимость обработки такого объема
информации на~постоянной основе в~пакетном или потоковом режиме
заставляет применять инструменты и~технологии <<больших данных>>
(Big Data).

Следовательно, необходима система детектирования и~анализа
текстовых трендов, функционирующая в~режиме реального времени
и~способная обрабатывать объе\-мы новостного потока OK. Имеет
смысл выделить такие требования:
\begin{itemize}\begin{itemize}%[topsep=0pt,noitemsep]
\item возможность предобработки большого корпуса текста;
\item горизонтальная масштабируемость системы;
\item работа в~режиме реального времени;
\item детектирование трендовых термов;
\item агрегирование и~сопоставление выделенных термов с~существующими тек\-стами.
\end{itemize}\end{itemize}

\textbf{Теоретическая часть.} Когда речь заходит о~трендах,
<<наивный подход>> предполагает рассматривать самые популярные
термы. Однако это не~совсем правильно. Не учитывая семантической
значимости выделенных термов, можно отметить, что конечный
пользователь предпочитает увидеть не~только популярные, значимые
события, но~и~обладающие <<новизной>>. Таким образом, для детекта
трендов недостаточно рассматривать только популярные слова,
но~следует учитывать их популярность в~некоторой исторической
перспективе. Стоит также учитывать, что абсолютная
популярность~--- характеристика, обладающая достаточно сильной
<<сезонной>> составляющей: средняя популярность слова,
не~участвующего в~тренде, может значительно меняться в~зависимости
от~дня недели, времени суток и~т.~д. Для первичной оценки
встречаемости терма более целесообразно использовать относительную
частоту, абсолютное количество упоминаний терма, нормированное
на~общее количество слов в~корпусе за~обследуемый период, более
формально:
%\begin{enumerate}
%\item

1.\,\,\,Из~постановки задачи предполагается, что с~каждым
документом, содержащимся в~коллекции, ассоциировано время его
создания. Разобьем коллекцию на~эпохи, и~будем в~дальнейшем
оценивать дистрибутивные характеристики терма в~рамках конкретной
эпохи. Пусть $N_{i}^{j}$~--- количество упоминания терма $i$
в~корпусе текста за~эпоху $j$. Рассмотрим величину
\begin{align*}
f_{i}^{j} = \frac{N_{i}^{j}}{\displaystyle \sum_{i}(N_{i}^{j})},
\end{align*}
где $\displaystyle {\sum_{i}(N_{i}^{j})} $~--- общая длина
корпуса. Величину $f_{i}^{j}$ будем называть {\it относительной
частотой терма} $i$ в~корпусе $j$.
%\item

2.\,\,\,Для каждого терма $i$ введем экспоненциально-взвешенное
скользящее среднее ($EWMA$) и~экспоненциально-взвешенную
скользящую дисперсию ($EWMVar$). Для расчета воспользуемся
рекуррентными формулами, представленными в~[5]:
\begin{equation}
\begin{gathered}
\Delta_{i}^{j} \triangleq f_{i}^{j} - EWMA_{i}^{(j-1)}, \\
EWMA_{i}^{j} = EWMA_{i}^{(j-1)} + \alpha \cdot \Delta_{i}^{j},\\
EWMVar_{i}^{j} = (1 - \alpha) \cdot (EWMVar_{i}^{j-1} + \alpha
\cdot (\Delta_{i}^{j})^{2}).
\end{gathered}
\end{equation}


\newpage
Параметр $\alpha$ можно задать, используя время полураспада:

\begin{equation*}
\alpha = 1 - e^{\frac{\ln(\frac{1}{2})}{t_{half}}},
\end{equation*}

\vskip2mm\noindent где $t_{half}$~--- временной интервал
в~единицах измерения, соответствующих единицам агрегации потока
текста в~эпохи. В~рамках работы реальной системы для инициализации
<<0-й>> эпохи предполагалось $EWMA_{i}^{0}=EWMVar_{i}^{0}=0\quad
(\forall i)$.

%\item
3.\,\,\,Для оценки <<важности>> (далее $sig$~--- от~significance)
конкретного терма воспользуемся методом $z$-$score$ (который даже
при отсутствии нормальности распределения может быть полезной
эвристикой) в~введeнных ранее определениях:

\begin{equation*}
sig_{i}^{j} = \frac{f_{i}^{j} -
EWMA_{i}^{(j-1)}}{\sqrt{EWMVar_{i}^{(j-1)}}}.
\end{equation*}
%\item

\vskip2mm 4.\,\,\,Однако при применении таких вычислений
с~реальными данными часто появляются сложности. С~одной стороны,
редко встречающийся терм, увиденный впервые и~употребленный всего
лишь несколько раз за~день, приобретает достаточно высокое
значение $sig$; с~другой~--- достаточно часто возникает ситуация,
когда $EWMVar$ оказывается достаточно близким к~нулю, что может
приводить к~серьезным погрешностям при вычислении. Для решения
этих проблем модифицируем приведенную выше формулу следующим
образом:

\begin{align}
sig_{i}^{j} = \frac{f_{i}^{j} - {\rm max}(EWMA_{i}^{(j-1)},
\beta)}{\sqrt{EWMVar_{i}^{(j-1)}} + \beta}.
\end{align}
\end{enumerate}

\vskip2mm\noindentПараметр $\beta$ используется как смещение, для
того чтобы избежать нулевого знаменателя или погрешности
вычисления, а~также в качестве шумового фильтра.
В~действительности при случайных флуктуациях редко встречающегося
терма, для которого $ EWMA < \beta $, нельзя статистически
достоверно гарантировать его <<трендовость>>.

Формулы (1) напрямую не~подходят для потоковой оценки $EWMA$
и~подразумевают некоторую агрегацию для $X$. Рекомендуется брать
достаточно крупный временной интервал для агрегации (выделения
эпохи), для уменьшения <<разброса>> $X$. Стоит заметить, что такие
источники данных как социальные сети имеют весьма явный суточный
цикл, и~в~этом случае более осмысленным выглядит использование
суточной агрегации новостного потока. Стоит также отметить, что
в~выражениях (1) применяется <<предыдущее>> значение $EWMA$, т. е.
текущее значение относительной встречаемости сравнивается
с~историческими знаниями об общей популярности\linebreak терма.

Несмотря на~то, что выражениe (2) позволяeт выделить значимые,
<<трендовые>> термы (как продемонстрировано на~рис.~1), опираясь
на известную статистику предыдущего дня, их прямая интерпретация,
как видно из~таблицы, остается достаточно трудоемкой.%\newpage

Для конструирования набора <<трендов>> (в данном случае набора
слов, характеризующего некоторое событие или явлениe) из~набора
термов применяется\linebreak\newpage

\begin{figure}[h!]
\centering
\includegraphics[scale=1.1]{08/fig1}
\vskip 2mm \caption{Сравнительный график характеристик термов,
имеющих отношение }\label{fig:dylan} \centering \vspace{0.5mm}
\small{к~присуждению Бобу Дилану Нобелевской премии}\\ \centering
\vspace{1mm} \footnotesize{{\it а} --- относительные частоты
термов; {\it б} --- $EWMA$; \\ \vskip 1mm  {\it в} --- $EWMVar$;
{\it г} --- обозначения на~графиках.}
\end{figure}

\noindent кластеризация на~основе совстречаемости термов.
В~качестве меры похожести использовалась величина $npmi$
(нормированная взаимная информация):

\begin{equation*}
npmi = \frac{{\rm log}(p(x,y) / p(x)\cdot p(y))}{-{\rm
log}(p(x,y)},
\end{equation*}
где $p(x)$~--- вероятность встретить терм $x$ в~корпусе;
$p(x,y)$~--- вероятность встретить в~одном документе термы $x$
и~$y$.

%\newpage
\vskip 2mm
\begin{center}
{\small

{\bf TOP-20 значимых термов за~12 октября 2016~г.\\ (слова
и~биграммы представлены в~<<сыром>> виде, после стемминга)}

}

\vskip 3mm

{\footnotesize


\begin{tabular}{|l|c|r|}
\hline
\multicolumn{2}{|c|}{Значимые термы}\\

\hline
наин ельцин & жертв ошибочн\\
\hline
вдов перв & михалков лжи \\
\hline
медведев установ & обвин михалков\\
\hline
тайн моисе & фигуристк медведев\\
\hline
моисе смотрет & мосул стал\\
\hline
пулеметчик всу & росс наин\\
\hline
ельцин обвин & фигуристк евген\\
\hline
успоко авак & повоня немн\\
\hline
авак останет & штаб иракск\\
\hline
серг микаэля & шкиряк украинц\\
\hline
\end{tabular}


}
\end{center}




Для кластеризации использовался алгоритм DBSCAN [6] (рис. 2).


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{08/fig2}
\vskip 4mm \caption{Визуализация результатов кластеризации за~4
июня 2016~г. }%\label{метка}
\centering \vspace{0.5mm} \footnotesize{Разными формами вершин
обозначены различные кластеры.
 Размер вершины\\ \vspace{0.8mm}
зависит от~популярности терма. На осях приведены значения
координат.}
\end{figure}




Изложенная выше модель хорошо подходит для пакетной обработки
данных. Однако применение ее при потоковой обработке сопряжено с
определенными трудностями. Одна из~них~--- расчет относительной
частоты в~потоковом режиме. Действительно, представленная модель,
основанная на~частотных характеристиках, предполагает наличие
какого-либо временного промежутка, в~рамках которого производится
агрегация. В~связи с~этим в~потоковом режиме при расчете $sig(x)$
для каждого терма использовалось экспоненциально-взвешенное
среднее абсолютного числа встречаемости терма, нормированное
на~экспоненциально-взвешенное среднее объема корпуса.

Кроме того, результат работы потоковой части системы~--- отдельные
слова и~биграммы. И их всe также сложно интерпретировать
по~отдельности. Подход, применяемый для пакетной обработки,
в~данном случае не~подходит. С~одной стороны, нет технической
возможности держать весь объем текста в~памяти и~постоянно
подсчитывать совстречаемость <<трендовых>> термов, с~другой~---
методы потоковой кластеризации достаточно слабо развиты,
а~качество их работы находится на~достаточно низком уровне. Для
визуализации и~агрегирования результатов работы потокового
компонента следует обратиться к~набирающей в~последнее время
популярность технике~--- mini-batch-анализу. В~рамках
mini-batch-системы поток данных дискретизируется по~времени, путем
объединения сообщений, пришедших за~определенный (небольшой)
интервал времени в~массивы (пакеты, батчи), а~расчеты и~обработка
происходят в~рамках каждого доступного батча.

Таким образом, общая система детектирования трендов состоит
из~трех модулей: пакетного, отвечающего за~точные ежедневные,
но~недостаточно актуальные расчеты, потокового, выполняющего роль
актуальной, но~упрощенной оценки, и~mini-batch-модуля,
необходимого для визуализации и~агрегирования результатов работы
потокового компонента и, фактически, отвечает за~сервисный
уровень.

Такое строение систем <<big-data аналитики>>, состоящей из~трех уровней: пакетного, потокового и~сервисного, называется <<lambda-архитектура>>.   \\
\indent
\textbf{Практическая часть.}

\emph{\textbf{Пакетная обработка.}} С~практической точки зрения
построение описанной системы~--- сложная техническая задача.
В~качестве основной платформы для реа\-лизации пакетных
компонентов был выбран Apache Spark~--- программный каркас
с~открытым исходным кодом для реализации распределенной обработки
структури\-рованных и~неструктурированных данных, интегрированный
в~экосистему Hadoop. В~отличие от~классической схемы Hadoop Spark
использует специализированные примитивы для рекурентной обработки
в~оперативной памяти без применения дисковых хранилищ, что
позволяет получить значительный выигрыш в~скорости работы для
некоторого класса задач.

Архитектура компонента представлена на~рис.~3.


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{08/fig3}
\vskip 3mm \caption{Архитектура пакетного компонента }%\label{метка}
\end{figure}



Кратко опишем каждый этап:

%\begin{itemize}\begin{itemize}%[topsep=0pt,noitemsep]
%\item \indent

$\bullet$\,\,\,Text Extraction: в~качестве системы для
транспортировки логов используется Apache Kafka. Данные поступают
в~Spark в~виде <<сырых>> JSON-логов. Извлечение данных происходит
с~помощью средств Apache Spark. Применяется начальная фильтрация
по~длине текста, типу объекта (пост, видео, фото, комментарии)
и~количеству лайков на~момент экстракции.
%\item

$\bullet$\,\,\,Language Detection: производится на~основе
open-source-библиотеки [7]. Детектирование языка основано на~<<top
trigram distribution>>. Добавлены дополнительные модули [8] для
детектирования языков стран СНГ (азербайджанский, армянский,
грузинский, казахский и~т. д.). Стоит отметить, что знание об
априорном распределении языков достаточно сильно влияет
на~качество работы алгоритма.
%\item

$\bullet$\,\,\,Tokenization and canonization: разделение текста
на~токены-термы и~их стемминг производятся на~основе Apache
Lucene. В~составе Lucene имеются готовые профили для 23 языков
(включая, например, русский, английский, армянский, латвийский),
однако нет профилей для многих языков стран СНГ.
%\item

$\bullet$\,\,\,Dictionary Extraction: извлечение словаря
средствами Apache Spark. Средний словарь на~эпоху (день) содержит
1М термов. Сохраняeтся индекс слов предыдущего дня.
%\item

$\bullet$\,\,\,Vectorization: преобразование текстов в~модель
Bag-Of-Words.
%\item

$\bullet$\,\,\,Deduplication: удаление дубликатов. Основано
на~методе случайных бинарных проекций [9]. Используется случайный
базис~--- 18-битный хэш, 50\% разреженности, в~качестве меры
похожести для документов~--- косинусное расстояние.
%\item

$\bullet$\,\,\,Current Day Statistics: подсчет относительных
частот токенов и~биграмм. Фильтрация по~частоте (шумовой порог).
Стоит отметить, что следует применять разные пороги для термов
и~биграмм.
%\item

$\bullet$\,\,\,Accumulated State Aggregation: подсчет $EWMA$
и~$EWMVar$ для термов.
%\item

$\bullet$\,\,\,Trending Term Identification: расчет значимости для
термов. Вводится дополнительный шумовой фильтр.
%\item

$\bullet$\,\,\,Trending Term Clustering: кластеризация термов
на~основе $npmi$, используются DBSCAN, имплементация ELKI [10].
%\item

$\bullet$\,\,\,Finding Relevant Document: для каждого документа
находятся релевантные документы на~основе процента термов
из~кластера в~составе документа. Для %\linebreak\newpage\noindent
каждого кластера-тренда выбирается список наиболее рейтинговых
(лайки) документов. Производится подсчет уникальных
авторов/групп/IP для спам-фильтрации.
%\item

$\bullet$\,\,\,Results Visualization: визуализация результатов
на~основе геолокации, текстов и~трендов-кластеров с~возможностью
навигации по~датам  (пример см. на~рис.~4).
%\end{itemize}\end{itemize}





\emph{\textbf{Потоковая обработка.}} Для потоковой обработки
такого объемного массива информации в~качестве транспортной
системы использовалась Apache Kafka, в~качестве фреймворка для
вычислений~--- Apache Samza. Apache Kafka~--- распределенный
программный брокер сообщений, который обладает высокой пропускной
способностью, легко горизонтально масштабируется, имеется
возможность временного хранения данных в~HDFS для пакетной
обработки [11].

Apache Samza~--- фреймворк для распределенной обработки потоков
данных, интегрированный в~экосистему Hadoop. Обладает встроенными
механизмами сохранения состояния и~восстановления в~случае падения
системы [12]. Системой для транспорта сообщений служит Apache
Kafka.

Схема работы потокового компонента приведена на~рис.~5.\newpage


\begin{figure}[h!]
\centering \vskip 3mm\includegraphics[scale=1]{08/fig4}
\vskip 2mm \caption{Визуализация результатов батчевой обработки }%\label{метка}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{08/fig5}
\vskip 2mm \caption{Схема работы потокового компонента }%\label{метка}
\end{figure}


\textbf{Mini-batch-компонент.} Для реализации mini-batсh-обработки
был использован Spark Streaming~--- компонент Apache Spark,
в~качестве средства для визуализации~--- Apache Zeppelin [13].

Apache Zeppelin~--- проект с~открытым исходным кодом для быстрого
прототипирования big-data-компонент, реализованный в~виде
интегрированной среды с~возможностью применения Apache Spark,
Spark Sql, HTML/CSS/Javascript/Angular и~многих других
интерпретеров для обработки и~визуализации данных. Схема
и~результат работы компонента представлены на~рис.~6 и~7.


\begin{figure}[h!]
\centering \vskip 1mm\includegraphics[scale=1]{08/fig6}
\vskip 1mm \caption{Схема работы mini-batch-компонента }%\label{метка}
\end{figure}
\begin{figure}[h!]
\centering \vskip 1mm\includegraphics[scale=1]{08/fig7}
\vskip 1mm \caption{Результат работы mini-batch-компонента }%\label{метка}
\end{figure}


\newpage
\textbf{Заключение.} В~рамках проделанной работы была предложена
дистрибутивная модель детектирования трендов. Кроме того, был
реализован стек препроцессинга и~анализа текста на~основе
распространенного фреймворка Spark. Модель показала\linebreak свою
работоспособность в~рамках OK. На~ее основе была реализована
big-data-систе-\linebreak ма анализа данных с~использованием
современных фреймворков, включенных в~общую lambda-архитектуру,
которая была интегрирована в~общую инфраструктуру~OK.

Результаты работы показывают успешность дистрибутивных моделей для
задачи детектирования и~анализа трендов. В~действительности эти
модели отличаются простотой математического аппарата и~легкостью
для горизонтального масштабирования, что позволило без особых
трудностей как переложить изначально пакетный алгоритм
на~потоковый способ обработки данных, так и~реализовать данную
систему на~стандартных и~общепринятых фреймворках.

Описанная система имеет большой потенциал и~возможности для
приложений: таргетирование новостных событий с~учетом интересов
пользователя, улучшение ранжирования контента с~учетом его
актуальности, формирование выборок и~дайджестов медиасообществ
портала и~т. д. В~будущем планируется работа над развитием
и~расширением такой системы.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\input{08/lit-ra}

%%%%%N DOI в~ссылке!!!!!!!!!!

\input{08/ref-s}

%%%%%N DOI в~ссылке!!!!!!!!!!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\footnotesize




%\thispagestyle{empty}

\vskip 3mm

%\thispagestyle{empty}


\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~13.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~13.~Вып.~\issuenum}}}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %


\noindent Статья рекомендована к~печати проф. В. Д. Добрыниным.

\vskip 1mm

\noindent Статья поступила в~редакцию 5 марта 2017~г.

\vskip 1mm

\noindent Статья принята к~печати 8 июня  2017~г.

}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\vskip 5mm


%{\footnotesize

%\noindent К\,о\,н\,т\,а\,к\,т\,н\,а\,я\,
%и\,н\,ф\,о\,р\,м\,а\,ц\,и\,я \nopagebreak

%\vskip 3mm

%\textit{Буре Артем Владимирович}~--- аспирант; e-mail:
%bure.artem@gmail.com

%\vskip 2mm

%\emph{Bure Artem Vladimirovich}~--- post-graduate student; e-mail:
%bure.artem@gmail.com

%}
