%
{\footnotesize \noindent$\issueyear$\mbox{~~~~~~~~~~}
ВЕСТНИК\,САНКТ-ПЕТЕРБУРГСКОГО\,УНИВЕРСИТЕТА
Т.\,17.\,\,Вып.\,$\issuenum$\linebreak %
\mbox{~~~~~~~~~~}ПРИКЛАДНАЯ МАТЕМАТИКА. ИНФОРМАТИКА. ПРОЦЕССЫ
УПРАВЛЕНИЯ %
}

%\ \\ \vskip 0.8mm\hrule \\ \hrule \\ \ \\

\vskip 0.5mm

\hline\vskip .5mm

\hline

\vspace{1.8cm} \noindent {\large ПРИКЛАДНАЯ МАТЕМАТИКА} \vspace{1.5cm}%1.8cm}

\noindent{\small УДК 519.25, 537.533.2\\ %  \hfill {\footnotesize Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~17.~Вып.~\issuenum}\\ %
MSC 62J05

}

\vskip2.5mm%3mm

\noindent{\bf Метод случайного поиска при оценке параметров сигнала\\эмиссионной системы$^{*}$%
 }

\vskip2.0%2.5
mm

\noindent{\it М. И. Вараюнь,~Е. М. Виноградова,~А. Ю. Антонов %$^1$%
%, И.~О. Фамилия%$\,^2$%

}

\efootnote{
%%
\vspace{-3mm}\parindent=7mm
%%
\vskip 0.1mm $^{*}$ Работа выполнена при финансовой поддержке Российского фонда фундаментальных исследований (грант № 20-07-01086).\par
%%
%%\vskip 2.0mm
%%
\indent{\copyright} Санкт-Петербургский государственный
университет, \issueyear%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum01 } }\hfill\thepage}%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum01}}}%
% для оформления нижнего колонтитула
\cfoot{} %

\vskip2mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize


\noindent%
%$^1$~%
Санкт-Петербургский государственный университет, Российская Федерация,

\noindent%
%\hskip2.45mm%
199034, Санкт-Петербург, Университетская~наб., 7--9



}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vskip2.5%3
mm

{\small \noindent \textbf{Для цитирования:} \textit{Вараюнь М. И., Виноградова~Е. М., Антонов ~А. Ю.} Метод случайного поиска при оценке параметров сигнала эмиссионной системы~// Вестник
Санкт-Пе\-тер\-бург\-ско\-го университета. Прикладная математика.
Информатика. Процессы управления. \issueyear. Т.~17.
Вып.~\issuenum.
С.~\pageref{p1}--\pageref{p1e}. %\\
\doivyp/\enskip%
\!\!\!spbu10.\issueyear.\issuenum01

\vskip2.5%3
mm

{\leftskip=7mm\noindentВ рамках компьютерного статистического эксперимента описана тестовая задача идентификации параметров сигнала полевой электронной эмиссии с~помощью регрессионной модели, основанной на законе Фаулера\,---\,Нордгейма. Были применены два подхода к~определению оценок параметров --- метод наименьших квадратов и~случайный поиск с~обучением. Показано, что погрешностью случайного поиска можно пренебречь, если при рассматриваемых соотношениях уровня шума к~мощности сигнала количество статистических испытаний составит величину порядка $10^3$. Полученный результат позволяет расширить класс используемых для идентификации отклика функционалов, не меняя при этом метод. Отмечены преимущества метода случайного поиска для предложенной задачи и~перспективы его применимости для задач в~более общей постановке.\\[1mm]
\textit{Ключевые слова}: полевая электронная эмиссия, вольт-амперная характеристика, регрессионная модель, метод наименьших квадратов, метод случайного поиска.

}

}

\vskip 3%4
mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{1. Введение.} Источники заряженных частиц, работающие в~режиме полевой электронной эмиссии (ПЭЭ), давно используются в~различных областях науки и~техники. Это касается как вакуумных приборов и~устройств [1--3], так и~материаловедения в~целом [4].

Запишем связь силы эмиссионного тока $I$ с~напряжением $V$ между катодом и~анодом в~виде $p$-параметрической ($p = 2$) зависимости [5]
\begin{equation}\label{eq_I_V}
	I(V; \mathbf{q}) = I_0 q_1 \left( \frac{V}{V_0} \right)^2 \exp\left[ -q_2 \frac{V_0}{V} \right].
\end{equation}
Это представление является следствием теории Фаулера\,---\,Нордгейма (ФН) [6]. Здесь компоненты вектора $\mathbf{q}$ в~нулевом приближении --- постоянные величины, опреде\-ляе\-мые материалом катода и~геометрическими параметрами системы. Калибровочные значения $V_0$ и~$I_0$ призваны сделать характеристики $q_1$ и~$q_2$ безразмерными. В~ходе эксперимента $\mathbf{q}$ оценивается по результатам наблюдений. Область значений параметров обозначим как $Q = \left\{ (q_1,q_2): q_1>0, q_2>0 \right\}$. В~данной работе не будем касаться имею\-щих\-ся в~литературе отклонений от теории ФН и, как следствие, моделей с~б\'ольшим ($p > 2$) числом параметров [7, 8]. Тем не менее рассматриваемый подход может быть легко распространен на общий случай.

Осуществим следующее преобразование, которое называется \textit{координатами ФН}:
\begin{equation}\label{eq_I_V_subs}
	X = \frac{V_0}{V}, \quad
	Y = \lg \left[ \frac{I}{V^2} \frac{V_0^2}{I_0} \right], \quad
	\vartheta_1 = \lg q_1, \quad
	\vartheta_2 = -\frac{q_2}{\ln 10}.
\end{equation}
Оно позволяет записать \eqref{eq_I_V} в~линейном виде как по параметрам $\bm{\upvartheta}=(\vartheta_1,\vartheta_2)^T \in \Theta$, так и~по фактору $X$:
\begin{equation}\label{eq_Y_X}
	Y = \vartheta_1 + \vartheta_2 X,
\end{equation}
где $\Theta = \left\{ (\vartheta_1,\vartheta_2): \vartheta_1 \in \mathds{R}, \vartheta_2<0 \right\}$ --- отображение $Q$ с~помощью \eqref{eq_I_V_subs}. Для систем одинаковой конфигурации наклон вольт-амперной характеристики (ВАХ) зависит от работы выхода электрона --- крайне важной для эмиссионной электроники величины. Методика определения работы выхода по наклону ВАХ настолько отточена, что служит отправной точкой для дальнейших исследований в~данной области~[9].

Преобразование \eqref{eq_I_V_subs} дает простую регрессионную модель~\eqref{eq_Y_X}. Рассмотрим ее. Измерения силы тока, как и~соответствующего напряжения, неизбежно содержат шум. Несложно показать, что ошибки измерения $V$ можно до некоторой степени игнорировать, рассматривая их как составляющую аддитивной погрешности для силы тока: \mbox{$\tilde{I} = I + I_0 \varepsilon$}~[10]. Понятно, что переход к~ координатам ФН затрагивает и~шум.

Применим метод наименьших квадратов (МНК) для поиска оптимальных оценок~$\hat{\bm{\upvartheta}}$. В~этом случае минимизируемый функционал имеет вид
\begin{equation}\label{eq_J}
	J = J(\bm{\upvartheta}; \mathbf{X}, \tilde{\mathbf{Y}}) =
	\sum\limits_{i=1}^N \left( \tilde{Y}_i - \vartheta_1 - \vartheta_2 X_i \right)^2,
\end{equation}
а соответствующее решение представим следующим образом:
\begin{equation*}
	\hat{\bm{\upvartheta}} = \mathbf{M}^{-1} \mathbf{b}, \quad
	\mathbf{M} =
	\begin{pmatrix}
		N & \sum\limits_{i=1}^N X_i \\
		\sum\limits_{i=1}^N X_i & \sum\limits_{i=1}^N X_i^2
	\end{pmatrix}\!, \quad
	\mathbf{b} =
	\begin{pmatrix}
		\sum\limits_{i=1}^N \tilde{Y}_i \\
		\sum\limits_{i=1}^N X_i \tilde{Y}_i
	\end{pmatrix}\!,
\end{equation*}
\begin{equation*}
	\hat{q}_2 = 10^{\hat{\vartheta}_1}, \quad
	\hat{q}_2 = - \hat{\vartheta}_1 \ln 10.
\end{equation*}

Очевидно, что $\hat{\bm{\upvartheta}}$ естественным образом оказывается также случайной величиной. Оценивание влечет за собой появление понятия остатков регрессионной модели:
\begin{equation}\label{eq_ehat}
	\hat{e}_i = \tilde{Y}_i - \hat{\vartheta}_1 - \hat{\vartheta}_2 X_i.
\end{equation}
Известно [11], что $\hat{\bm{\upvartheta}}$ будет оценкой максимального правдоподобия, если $\left\{\hat{e}_i\right\}$ удовлетворяют следующим условиям. Так, остатки должны быть независимы и~одинаково нормально распределены. Если в~выборке $\left\{\hat{e}_i\right\}$ наблюдается автокорреляция, гетеро\-скедастичность или отклонение от нормальности в~пользу альтернативных гипотез, то, пожалуй, единственным преимуществом функционала \eqref{eq_J} остается его простота.

Для получения более устойчивой к~аномальным наблюдениям $\tilde{Y}_i$ оценки, например, можно использовать метод наименьших модулей [12]. При наличии базы данных по значениям работы выхода анализируемого образца [13] для построения $\hat{\bm{\upvartheta}}$ имеет смысл опираться на эту априорную информацию. Поиск минимума нового функционала в~таких случаях может осложниться ввиду потери гладкости по параметрам.

Цель данной работы --- анализ особенностей применения метода случайного поиска для оценки параметров сигнала ПЭЭ.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{2. Математическая модель сигнала.} Рассмотрим задачи, необходимые для достижения поставленной цели, в~рамках математического моделирования. Это позволит сравнить полученные результаты с~данными, закладываемыми в~модель.

Пусть наблюдения $\tilde{I}_i$ получены при известных значениях параметров $(q_1^*, q_2^*)$ с~использованием закона \eqref{eq_I_V}. Погрешности $\varepsilon$ будем считать случайной величиной, разыгрываемой по правилу
\begin{equation}\label{eq_eps}
	\varepsilon_i = \delta \frac{I_i}{I_0} \varepsilon'_i,
\end{equation}
где безразмерная величина $\delta^2$ отвечает за дисперсию наблюдений, $\varepsilon'_i$ являются независимыми реализациями стандартной нормальной случайной величины~[10]. В~данном подходе интенсивность шума получается пропорциональной сигналу. Переход к~координатам ФН дает линеаризованные наблюдения $\tilde{Y}_i$:
\begin{equation}\label{eq_Y_X_noise}
	\tilde{Y}_i = \lg\left[ \frac{\tilde{I}_i}{V^2} \frac{V_0^2}{I_0} \right] =
	\vartheta_1 + \vartheta_2 X_i + \frac{\varepsilon'_i \delta}{\ln 10} + o(\varepsilon'_i \delta).
\end{equation}


Обратим внимание, что в~модель заложены независимость и~нормальность. Го\-мо\-ске\-да\-стич\-ность остатков \eqref{eq_ehat} для линеаризованной регрессионной модели должна выполняться в~пределе при $\delta \to 0$. Однако эти особенности шума \eqref{eq_eps} не гарантируют того, что отдельно взятая выборка пройдет тесты на принадлежность нормальному распределению, отсутствие автокорреляции, равенство дисперсий при различных значениях~$X_i$. Иногда в~статистическом эксперименте даже значимость регрессионной модели может оказаться под сомнением~[5].

На рис.~\ref{fig_IVplot_FN_fV} приведены ВАХ с~разным количеством наблюдений и~различным уровнем шума. Значения напряжения рассматривались равноотстоящими. Для наглядности при~каждой величине $V_i$ смоделировано 50 повторяющихся измерений.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%рис. 1


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{01/fig1}
\vskip 0mm \caption{Моделируемые ВАХ}\label{fig_IVplot_FN_fV}
\end{figure}




\textbf{3. Метод случайного поиска с~обучением.} Для минимизации~\eqref{eq_J} сначала выделим некоторую конечную подобласть множества $Q$. В~описываемом случае это был прямоугольник $\Pi = [a_1,b_1) \times [a_2,b_2) = [6,8) \times [6,8)$, не содержащий точку достижения экстремума и~точку $(q_1^*, q_2^*)$ (см. рис.~\ref{fig_random_walk_FN}, где начальная область поиска выделена сплошным серым цветом). Таким образом, при процедуре оптимизации имеем дело с~функционалом, наследуемым от \eqref{eq_J}:
\begin{equation}\label{eq_J_xi}
	J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) =
	\sum\limits_{i=1}^N \left( \tilde{Y}_i - \lg\xi_1 + \frac{\xi_2}{\ln 10} X_i \right)^2, \tag{\ref{eq_J}$'$}
\end{equation}
где $\bm{\upxi} = (\xi_1, \xi_2)^T$ --- случайные испытания или пробы.



%%%%%%%%%%%%%%%%%%%%%%%%%%%рис. 2


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{01/fig2}
\vskip 0mm \caption{Результаты поиска с~обучением для $J(\bm{\upvartheta}; \mathbf{X}, \tilde{\mathbf{Y}})$ }\label{fig_random_walk_FN}
\end{figure}






Далее идеология метода заключается в~том, что экстремум следует искать интенсивнее в~той части области $Q$, где уже достигнуты <<хорошие>> результаты методом проб. С математической точки зрения это означает поиск решения с~помощью плотности распределения, которая формируется на основе предыдущих опытов. В~чем-то такой подход напоминает метод существенной выборки при монте-карловском вычислении интеграла [14]. Для построения необходимой плотности используют оптимизируемую характеристику \eqref{eq_J_xi}. Поскольку
\begin{equation*}
	J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) \xrightarrow[||\bm{\upxi}|| \to +\infty]{} +\infty, \quad
	J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) \xrightarrow[\delta \to 0]{} 0,
\end{equation*}
было решено отказаться от построения вспомогательного функционала с~помощью традиционных рекомендаций: $L(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) = -J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}})$ или $L(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) = 1/J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}})$. В~данном случае производился поиск максимума выражения
\begin{equation}\label{eq_L_xi}
	L(\bm{\upxi}) = L(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}}) = \frac{1}{1+J(\bm{\upxi}; \mathbf{X}, \tilde{\mathbf{Y}})}, \tag{\ref{eq_J}$''$}
\end{equation}
область возможных значений которого представляет собой интервал $(0,1]$.

Проведем равномерный поиск в~области $\Pi$: $\bm{\upxi} = (\xi_1,\xi_2)$, где $\xi_j^{(k)} = a_j + (b_j - a_j) \gamma_j^{(k)}$, $j=\overline{1,p}$, $k=\overline{1,N_{\text{try}}}$, $\gamma_j^{(k)}$ являются реализациями равномерно распределенной случайной (псевдослучайной) величины в~интервале $[0,1)$. Решение формируется последовательно:
\begin{equation}\label{eq_bar_x}
	\begin{aligned}
		L^{(1)} &= L\bigl( \bm{\upxi}^{(1)} \bigr), &\quad \mathbf{q}^{(1)} &= \bm{\upxi}^{(1)},\\
		L^{(k)} &=
		\begin{cases}
			L(\bm{\upxi}^{(k)}), & L(\bm{\upxi}^{(k)}) > L^{(k-1)}, \\
			L^{(k-1)}, & L(\bm{\upxi}^{(k)}) \leqslant L^{(k-1)},
		\end{cases}
		&\quad
		\mathbf{q}^{(k)} &=
		\begin{cases}
			\bm{\upxi}^{(k)}, & L\bigl( \bm{\upxi}^{(k)} \bigr) > L^{(k-1)}, \\
			\mathbf{q}^{(k-1)}, & L\bigl( \bm{\upxi}^{(k)} \bigr) \leqslant L^{(k-1)},
		\end{cases}\\
		%k &= \overline{2,N_{\text{try}}}; &\quad
		& \hspace*{3.2cm} k = \overline{2,N_{\text{try}}}, &\quad
		\doublehat{\mathbf{q}} &= \mathbf{q}^{(N_{\text{try}})}.
	\end{aligned}
\end{equation}
На основе $N_{\text{try}}$ попыток строится ковариационная матрица $\mathbf{C}$ с~компонентами
\begin{equation}\label{eq_covar}
	c_{jl} = \dfrac{\sum\limits_{k=1}^{N_{\text{try}}} \xi^{(k)}_j \xi^{(k)}_l L\bigl( \bm{\upxi}^{(k)} \bigr)}{\sum\limits_{k=1}^{N_{\text{try}}} L\bigl( \bm{\upxi}^{(k)} \bigr) \vphantom{\left(\sum\limits_{k=1}^{N_{\text{try}}} L\bigl( \bm{\upxi}^{(k)} \bigr)\right)^2}} -
	\dfrac{\sum\limits_{k=1}^{N_{\text{try}}} \xi^{(k)}_j L\bigl( \bm{\upxi}^{(k)} \bigr) \sum\limits_{k=1}^{N_{\text{try}}} \xi^{(k)}_l L\bigl( \bm{\upxi}^{(k)} \bigr)}{\left(\sum\limits_{k=1}^{N_{\text{try}}} L\bigl( \bm{\upxi}^{(k)} \bigr)\right)^2},
	\quad j,l = \overline{1,p}.
\end{equation}

Для $\doublehat{\mathbf{q}}$ и~$\mathbf{C}$ существует двумерное гауссовское распределение нового вектора $\bm{\upxi}$ такое, что его плотность
\begin{equation*}
	p_{\bm{\upxi}}(\mathbf{q}) = \frac{1}{\sqrt{(2\pi)^p \det\mathbf{C}}} \exp\left[ -\frac{1}{2} (\mathbf{q} - \doublehat{\mathbf{q}})^T \mathbf{C}^{-1} (\mathbf{q} - \doublehat{\mathbf{q}}) \right].
\end{equation*}
Таким образом, далее поиск проводится во всей области $Q$ с~помощью $p_{\bm{\upxi}}(\mathbf{q})$, а~точки~$\bm{\upxi}$, не попавшие в~нее, отбрасываются --- происходит так называемое усечение распределения~[14]. Это обстоятельство позволяет рассматривать многоэкстремальные задачи, поскольку всегда существует отличная от нуля вероятность оказаться в~окрестности точки глобального максимума или минимума. Ввиду того, что матрица $\mathbf{C}$ симметрична, существует нижняя треугольная матрица $\mathbf{T}$ такая, что \mbox{$\mathbf{C} = \mathbf{T} \mathbf{T}^T$}. Это позволяет моделировать $\bm{\upxi}$ по формуле \mbox{$\bm{\upxi} = \mathbf{T} \bm{\upzeta} + \doublehat{\mathbf{q}}$}, где компоненты $\bm{\upzeta}$ являются независимыми стандартными нормальными случайными величинами~[15]. Элементы матрицы $\mathbf{T}$ при этом находятся последовательно из системы уравнений
\begin{equation*}
	\sum\limits_{k=1}^l t_{jk} t_{lk} = c_{jl}, \quad
	1 \leqslant l \leqslant j \leqslant p.
\end{equation*}

Теперь можно последовательно получать обновляемую оценку $\doublehat{\mathbf{q}}$, согласно \eqref{eq_bar_x}, и~построить уточняемую ковариационную матрицу $\mathbf{C}$ в~соответствии с~\eqref{eq_covar}. Выбор количества таких итераций $N_{\text{iter}} \geqslant 2$, равно как и~объем статистических испытаний $N_{\text{try}}$ на каждой стадии, остается за исследователем. В~рассматриваемом случае $N_{\text{iter}} = 10$, $N_{\text{try}} = 100$, т.\,е. на поиск одной окончательной оценки $\doublehat{\mathbf{q}}$ тратилось $N_{\text{search}} = 1000$~испытаний, что очень немного для методов статистического моделирования. Весь процесс отображен на рис.~\ref{fig_random_walk_FN} для наиболее зашумленного сигнала, где точками указаны пробные испытания, интенсивность цвета которых соот\-вет\-ст\-вует значениям функ\-ционала \eqref{eq_J_xi}. Серой толстой линией соединены все промежуточные экстремумы, черной~--- центры поэтапных распределений ($\doublehat{\mathbf{q}}$), начиная с~центра начальной области поиска~--- прямоугольника $\Pi$, серыми пунктирными --- промежуточные минимумы~\eqref{eq_J_xi} (максимумы \eqref{eq_L_xi}) для двух оставшихся сигналов, крестиками отмечены заложенные в~модель сигнала точные значения параметров. Показатели минимизируемого функционала показаны на рис.~\ref{J_search_FN}.


%%%%%%%%%%%%%%%%%%%%%%%%рис. 3


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{01/fig3}
\vskip 0mm \caption{Значения функционала $J(\bm{\upvartheta}; \mathbf{X}, \tilde{\mathbf{Y}})$ }\label{J_search_FN}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{4. Результаты и~статистические выводы.} В~рамках математического моделирования удобно сравнить результаты, полученные двумя разными способами: МНК-оценки $\hat{q}$ ($\hat{\bm{\upvartheta}}$) и~оценки случайного поиска $\doublehat{q}$ ($\doublehat{\bm{\upvartheta}}$). Был проведен статистический эксперимент с~$N_{\text{stat}} = 1000$ сигналами при каждом рассматриваемом уровне шума. Для~демонстрации распределения оценок исходных значений параметров удобно использовать величины $\bm{\upvartheta}$, поскольку в~этом случае область рассеяния имеет эллиптическую форму. Данный~тезис подтверждается тем, что совместная доверительная область для $\bm{\upvartheta}$ при выполнении предположений относительно остатков регрессионной модели является внутренностью эллипса:
\begin{equation*}
	\bigl( \bm{\upvartheta} - \hat{\bm{\upvartheta}} \bigr)^T \mathbf{M} \bigl( \bm{\upvartheta} - \hat{\bm{\upvartheta}} \bigr) \leqslant
	p s^2 F_{1-\alpha}(k_1,k_2), \quad
	s^2 = \frac{1}{k_2} \sum\limits_{i=1}^N \hat{e}_i^2, \quad
	k_1 = p-1, \quad
	k_2 = N - p;
\end{equation*}
$F_{1-\alpha}(k_1,k_2)$ --- $(1-\alpha)$-квантиль $F$-распределения Фишера\,---\,Снедекора [10]. Для построе\-ния единого семейства эллипсов его центр был заменен на $\bm{\upvartheta}^*$, а~$s^2$ --- на главный член дисперсии погрешности после линеаризации, согласно \eqref{eq_Y_X_noise}:
\begin{equation*}
	\bigl( \bm{\upvartheta} - \bm{\upvartheta}^* \bigr)^T \mathbf{M} \bigl( \bm{\upvartheta} - \bm{\upvartheta}^* \bigr) \leqslant
	p \frac{N}{k_2} \left( \frac{\delta}{\ln 10} \right)^2 F_{1-\alpha}(k_1,k_2).
\end{equation*}



%%%%%%%%%%%%%%%%%%%%%%%%рис. 4


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{01/fig4}
\vskip 0mm \caption{Разбиение области $\Theta$ и~рассеяние оценок }\label{fig_ellipses2010}
\end{figure}




На рис. \ref{fig_ellipses2010} представлены эллипсы со значениями $\alpha$ от 5 до 95\,\% с~шагом 5\,\%. Таким образом, область $\Theta$ была разбита на $r=20$ частей, которые были перенумерованы. Здесь же приведены оценки $\hat{\bm{\upvartheta}}$ и~$\doublehat{\bm{\upvartheta}}$ для $\delta = 10\,\%$. Предварительный визуальный анализ рассеяния параметров (имеется 1000 оценок каждого вида) позволяет выдвинуть гипотезу $H_0$, согласно которой случайные величины $\hat{\bm{\upvartheta}}$ и~$\doublehat{\bm{\upvartheta}}$ подчиняются одному закону распределения. Можно записать, что



\begin{equation}\label{eq_est_errors}
	\hat{\bm{\upvartheta}} = \bm{\upvartheta}^* + \Delta_{\varepsilon}\bm{\upvartheta}, \quad
	\doublehat{\bm{\upvartheta}} = \bm{\upvartheta}^* + \Delta_{\varepsilon}\bm{\upvartheta} + \Delta_{N_{\text{search}}}\bm{\upvartheta}.
\end{equation}
Тогда $H_0$ будет выглядеть как $|| \Delta_{N_{\text{search}}}\bm{\upvartheta} || \ll || \Delta_{\varepsilon}\bm{\upvartheta} ||$. Это не вполне четкая запись с~ точки зрения математической статистики. По сути, перед нами гипотеза об однородности многомерных выборок. В~описываемом случае компоненты векторов $\hat{\bm{\upvartheta}}$ и~$\doublehat{\bm{\upvartheta}}$ не являются независимыми. Построим вспомогательные одномерные случайные величины $\hat{\theta}$ и~$\doublehat{\theta}$. Пусть величина $\hat{\theta}$ принимает значение, равное номеру подобласти~$\Theta$, в~ которую попала оценка~$\hat{\bm{\upvartheta}}$. Для $\doublehat{\theta}$ аналогично. Частоты ($\hat{\nu}_k$, $\doublehat{\nu}_k$) попаданий преобразованных случайных величин в~конкретную область и~кумулятивные суммы частот ($\hat{F}_k$, $\doublehat{F}_k$)  для случая $\delta = 10\,\%$ иллюстрирует рис.~\ref{fig_sums_histo_2010}. Значения $\hat{F}_k$ и~$\doublehat{F}_k$ описывают выборочные функции распределения.



%%%%%%%%%%%%%%%%%%%%%%%%рис. 5


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{01/fig5}
\vskip 0mm \caption{Индивидуальные и~накопленные частоты }\label{fig_sums_histo_2010}
\end{figure}




Выдвинем вспомогательную гипотезу $H'_0$, согласно которой выборки $\hat{\theta}$ и~$\doublehat{\theta}$ извле\-каются из одной генеральной совокупности:
\begin{equation*}
	\Prob\bigl\{ \hat{\theta} \leqslant a \bigr\} = \Prob\bigl\{ \doublehat{\theta} \leqslant a \bigr\} \quad
	\forall a.
\end{equation*}
Для ее проверки осуществим свободный от распределения тест Колмогорова\,---\,Смир\-но\-ва~[16]. Итак, имеются наблюдения \mbox{$\hat{\theta}_1,\ldots,\hat{\theta}_m$} и~\mbox{$\doublehat{\theta}_1,\ldots,\doublehat{\theta}_m$}; \mbox{$m = 1000$}. Обе выборки построены на основе независимых случайных векторов, извлеченных из непрерывных совокупностей. Далее выборки объединяются и~упорядочиваются по возрастанию. Таким образом, строится вариационный ряд \mbox{$Z_{(1)} \leqslant Z_{(2)} \leqslant \ldots \leqslant Z_{(2m)}$}. Это позволяет упростить процедуру построения гистограмм и~выборочных функций распределения (рис.~\ref{fig_sums_histo_2010}). Исследуется статистика
\begin{equation*}
	K_m = \sqrt{\frac{m}{2}} \max\limits_{k=\overline{1,r}} \bigl\{ | \hat{F}_k - \doublehat{F}_k | \bigr\}.
\end{equation*}
При $m \to \infty$ величина $K_m$ подчиняется распределению с~функцией Колмогорова. Если \mbox{$K_m < K(\alpha)$}, то основания отвергать $H'_0$ отсутствуют. Для 5\%-го уровня значимости \mbox{$K(\alpha) = 1.358$} (соответствующую величину можно найти в~таблицах [16]). Значения статистики для показателей шума 5, 10 и~20\,\% оказались равными $1.006$, $0.8721$ и~$0.6037$ соответственно. В~рамках представления~\eqref{eq_est_errors} поведение наблюдаемых (оцениваемых по выборочным данным) значений $K_m$ означает, что при рассматриваемых величинах~$\delta$ вкладом $\Delta_{N_{\text{search}}}\bm{\upvartheta}$ можно пренебречь. При понижении уровня шума, оставляя $N_{\text{search}}$ постоянным, рано или поздно будем вынуждены отклонить гипотезу~$H'_0$.

Предположение~$H'_0$ можно проверить, используя метрику критерия $\omega^2$ (Крамера\,---\,фон~Мизеса\,---\,Смирнова). Это было предложено в~работе Леманна~[17] и~проанализировано Розенблаттом~[18]. Практически пригодная статистика приведена Андерсоном~[19]:
\begin{equation*}
	T_m = \frac{1}{2 m^2} \left[ \sum\limits_{i=1}^{m} \left( \hat{r}_i - i \right)^2 +
	\sum\limits_{i=1}^{m} \left( \doublehat{r}_i - i \right)^2 \right] - \frac{4 m^2 - 1}{12 m},
\end{equation*}
где $\hat{r}_i$ и~$\doublehat{r}_i$ --- ранги представителей выборок $\hat{\theta}$ и~$\doublehat{\theta}$ в~общем вариационном ряду $\bigl\{ Z_{(i)} \bigr\}$. При наличии совпадающих наблюдений следует использовать средние ранги.

При \mbox{$m \to \infty$} величина $T_m$ обладает функцией распределения $a_1(x)$ (см., например, [16]). Критическая область для  5\%-го уровня значимости  определяется величиной \mbox{$T(0.05) = 0.4614$}, оказавшейся больше, чем наблюдаемые значения $0.2428$, $0.1798$ и~$0.1145$ статистики $T_m$. Они приведены по-прежнему в~порядке возрастания уровня шума. Оснований отвергать вспомогательные гипотезы однородности нет. Здесь наблюдается та же тенденция в~динамике значения $T_m$, что и~при использовании теста Колмогорова\,---\,Смирнова.



Также гипотеза~$H'_0$ была проверена при помощи статистики Пирсона
\begin{equation*}
	\chi^2_m = m \sum\limits_{k=1}^{r} \frac{\left( \hat{\nu}_k - \doublehat{\nu}_k \right)^2}{\hat{\nu}_k + \doublehat{\nu}_k}
\end{equation*}
с количеством степеней свободы, равным $(r-1)$, которая при $m \to \infty$ имеет соот\-вет\-ст\-вую\-щее распределение~[20]. Критическая точка при той же строгости к~уровню доверия $\chi^2(0.05;19) = 30.14$. Это значение больше, чем приведенные в~той же последовательности, что и~ранее, наблюдаемые величины $14.79$, $11.54$ и~$20.84$. Оснований отвергать гипотезы $H'_0$ опять не нашлось. Монотонная зависимость  $\chi^2_m$ от $\delta$ уже отсутствует. Это можно объяснить тем, что объектом анализа здесь являются отдельные, а~не накопленные частоты. Можно отметить, что данный критерий не связан ограничениями на одномерность. Однако проведeнное разбиение области $\Theta$ на ячейки с~ помощью эллипсов, по нашему мнению, наиболее логичное в~таком случае.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{5. Заключение.} Была описана тестовая задача идентификации параметров сигнала ПЭЭ с~помощью регрессионной модели, основанной на законе Фаулера\,---\,Норд\-гейма. Исследование проведено в~рамках компьютерного статистического эксперимента. Методом, альтернативным МНК-оценке параметров, послужил случайный поиск с~обучением. Установлено, что при рассматриваемых соотношениях уровня шума к~мощности сигнала погрешностью случайного поиска можно до~некоторой степени пренебречь при количестве статистических испытаний, равном \mbox{$N_{\text{search}} = 1000$}. Речь идет о~рассеянии оцениваемых параметров относительно их точных значений, которое всегда имеет место. Такое заключение позволяет расширить класс используемых для~идентификации отклика функционалов, не меняя при этом метода. Данный статистический подход может применяться и~в~натурном эксперименте с~автоматизированными системами сбора информации~[3]. Ничтожное для методов Монте-Карло значение $N_{\text{search}}$ позволяет получать оценки достаточно быстро. Стоит указать и~на традиционные положительные особенности случайного поиска: сравнительно простое распараллеливание программного кода и~работоспособность при наличии локальных экстремумов. Метод также может применяться в~режиме реального времени, когда вычисления требуется прервать и~выдать в~качестве результата лучшую из имеющихся проб. При этом совместные доверительные области распределения параметров сигнала являются одними из важнейших показателей качества проведенного регрессионного анализа~[5]. В~рассматриваемой тестовой задаче эти множества определяются семейством эллипсов. Однако в~общем случае их форма зависит от используемого функционала~[21]. И поскольку есть основания считать, что метод случайного поиска практически не оказывает влияния на рассеяние параметров, благодаря ему можно построить доверительные области любой сложности с~помощью, например, независящей от распределения процедуры~[22].


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\input{01/lit-ra}

%\newpage
\input{01/ref-s}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%{\footnotesize

%\thispagestyle{empty}
%
\vskip 3mm
%
\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~17.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~17.~Вып.~\issuenum}}}%
% для оформления нижнего колонтитула
\cfoot{} %


%}
