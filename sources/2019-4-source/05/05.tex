
\noindent{\small УДК 519.87  \hfill {\footnotesize Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}\\
MSC 90B50, 15A80, 90C47

}

\vskip2mm

\noindent{\bf Методы тропической оптимизации в~многокритериальных
задачах\\ оценки альтернатив на основе парных
сравнений$^{*}$%
 }

\vskip2.5mm

\noindent{\it Н.~К.~Кривулин%$\,^1$%
, В.~А.~Агеев%$\,^1$%
%, И.~О. Фамилия%$\,^2$%
}

\efootnote{
%%
\vspace{-3mm}\parindent=7mm
%%
\vskip 0.1mm $^{*}$ Работа выполнена при финансовой поддержке
Российского фонда фундаментальных исследований (грант
№~18-010-00723).\par
%%
%%\vskip 2.0mm
%%
\indent{\copyright} Санкт-Петербургский государственный
университет, \issueyear%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum05 } }\hfill\thepage}%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\rm{\doivyp/spbu10.\issueyear.\issuenum05}}}%
% для оформления нижнего колонтитула
\cfoot{} %

\vskip2mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

\noindent%
%$^1$~%
Санкт-Петербургский государственный университет, Российская
Федерация,

\noindent%
%\hskip2.45mm%
199034, Санкт-Петербург, Университетская~наб., 7--9


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vskip3mm

{\small \noindent \textbf{Для цитирования:}
\textit{Кривулин~Н.~К., Агеев~В.~А.} Методы тропической
оптимизации в~многокритериальных задачах оценки альтернатив на
основе парных сравнений~// Вестник Санкт-Петербургского
университета. Прикладная математика. Информатика. Процессы
управления. \issueyear. Т.~15. Вып.~\issuenum.
С.~\pageref{p5}--\pageref{p5e}. %\\
\doivyp/\enskip%
\!\!\!spbu10.\issueyear.\issuenum05

\vskip3mm

{\leftskip=7mm\noindentСтатья посвящена применению методов
и~результатов тропической математики, которая изучает теорию
и~приложения алгебраических систем с~идемпотентными
опера\-ция\-ми, для разработки многокритериальной процедуры
принятия решений. Рассматри\-вает\-ся задача оценки рейтингов
альтернатив по данным парных сравнений альтернатив в~соответствии
с~несколькими критериями, а~также парных сравнений критериев. Для
решения задачи предлагается процедура принятия решений на основе
чебышевской аппроксимации в~логарифмической шкале матриц парных
сравнений обратно симметрическими матрицами единичного ранга
(согласованными матрицами), с~помощью которых определяют элементы
векторов весов критериев и~рейтингов альтернатив. Сначала решается
задача аппроксимации матрицы парных сравнений критериев для
нахождения вектора весов критериев. Затем взвешенные матрицы
парных сравнений альтернатив аппроксимируются общей согласованной
матрицей, определяющей искомый вектор рейтингов альтернатив. Если
результатом является не единственный (с точностью до
положительного множителя) вектор весов (рейтингов), решается
дополнительная задача анализа решений для нахождения векторов,
которые могут рассматриваться в~некотором смысле как наихудшее
и~наилучшее решения. Задачи аппроксимации и~анализа решений
в~рамках предложенной процедуры формулируются как задачи
тропической оптимизации, которые имеют прямые аналитические
решения в~компактной векторной форме. Приводится пример применения
процедуры
для решения известной задачи Т.~Саати о~выборе школы.\\[1mm]
\textit{Ключевые слова}: идемпотентное полуполе, тропическая
оптимизация, матрица парных сравнений, аппроксимация матриц,
log-чебышевская метрика, многокритериальная задача принятия
решений.

}

}

\vskip 4mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bfseries 1.~Введение.} Многокритериальные задачи принятия
решений возникают в~случаях, когда необходимо найти решение,
которое будет в~определенном смысле оптимальным по нескольким
критериям одновременно [1, 2]. Такие задачи встречаются, например,
при анализе предпочтений респондентов с~использованием различных
критериев оценки в~таких областях как маркетинг (исследование
потребительского спроса), социология (анализ социологических
опросов) и~политология (прогноз результатов выборов).

Распространенный способ изучения предпочтений основан на методе
парных сравнений [3, 4], при котором на каждом шаге сравниваются
только две альтернативы (два объекта, две характеристики
объектов), что обычно является более простой задачей, чем
одновременная оценка нескольких альтернатив. Результат применения
метода~--- матрица парных сравнений, анализ которой позволяет
получить вектор, составленный из рейтингов альтернатив и~сделать
вывод об их ранжировании.

В матрицах парных сравнений, как правило, нарушена согласованность
оценок, которую, однако, можно восстановить путем решения задачи
аппроксимации таких матриц согласованными матрицами, элементы
которых обладают свойствами обратной симметричности
и~транзитивности. Эту задачу формулируют как задачу оптимизации,
которую обычно решают различными алгоритмическими методами.

Наиболее распространен метод главного собственного вектора [4],
при котором решение строится при помощи главного собственного
вектора матрицы парных сравнений. Кроме того, применяются другие
методы, опирающиеся на разные способы определения метрики на
множестве матриц, при помощи которой измеряется ошибка
аппроксимации. В~частности, при использовании евклидовой метрики
приходят к~методам наименьших квадратов, логарифмических
наименьших квадратов (метод геометрического среднего), а~в~случае
чебышевской метрики получают задачу линейного программирования.
Примеры различных подходов к~задаче аппроксимации матрицы парных
сравнений можно найти в~работах [5--9]. При условии, что ошибка
аппроксимации измеряется в~метрике Чебышева в~логарифмической
шкале, решение задачи можно получить аналитически с~помощью
методов тропической математики.

Тропическая (идемпотентная) математика изучает теорию и~приложения
алгебраических систем с~идемпотентными операциями [10--14]. Задачи
оптимизации, сформулированные в~терминах тропической математики
(задачи тропической оптимизации), находят приложения в~разных
областях, включая задачи оценки альтернатив на основе парных
сравнений [15--18]. В~ряде случаев методы тропической оптимизации
позволяют найти решение задач в~явном виде в~компактной векторной
форме, удобной для формального анализа решений и~непосредственных
вычислений.

Если в~задаче имеются несколько критериев оценки, результатом
исследования будут несколько матриц парных сравнений,
соответствующих сравнению как альтернатив по каждому критерию, так
и самих критериев. Для решения полученной многокритериальной
задачи обычно применяют метод анализа иерархий, разработанный
Т.~Саати~[4], а~также его модификации [19--23]. Еще один подход
к~решению задачи, предложенный в~[17, 24--26], состоит
в~использовании тропической оптимизации [27].

Настоящая работа посвящена развитию и~практическому применению
методов тропической оптимизации [15--18, 24--26] для решения
многокритериальных задач оценки альтернатив на основе парных
сравнений. Основными целями являются разработка и~иллюстрация
использования процедуры принятия решений, которая может
рассматриваться как некоторый тропический аналог метода анализа
иерархий.


{\bfseries 2.~Задача аппроксимации матрицы парных сравнений.}
Пусть имеется $n$ альтернатив (вариантов) принятия решения, из
которых необходимо выбрать наиболее предпочтительную. Альтернативы
сравниваются попарно в~соответствии с~некоторым критерием,
в~результате чего образуется матрица парных сравнений
$\mathbf{A}=(a_{ij})$, в~которой элемент $a_{ij}>0$ показывает, во
сколько раз альтернатива $i$ предпочтительнее альтернативы $j$
(относительный рейтинг, приоритет $i$ по отношению к~$j$) для всех
$i,j=1,\ldots,n$. Цель анализа и~оценки предпочтений~---
вычисление на основе матрицы~$\mathbf{A}$ абсолютных предпочтений
(рейтингов, приоритетов) альтернатив.

Матрица парных сравнений является обратно симметрической, т.~е. ее
элементы удовлетворяют равенству $a_{ij}=1/a_{ji}$. Это условие
требует, чтобы в~случае, когда альтернатива $i$ оказывается
в~$a_{ij}$ раз предпочтительнее альтернативы $j$, которая, в~свою
очередь, должна быть в~$a_{ij}$ раз менее предпочтительной, чем
$i$. Матрица парных сравнений является транзитивной, если
$a_{ik}=a_{ij}a_{jk}$ для всех $i,j,k=1,\ldots,n$. Это условие
означает, что если альтернатива $i$ предпочтительнее альтернативы
$j$ в~$a_{ij}$~раз, а~альтернатива $j$ предпочтительнее $k$
в~$a_{jk}$~раз, то альтернатива $i$ должна быть более
предпочтительной, чем альтернатива $k$, в~$a_{ij}a_{jk}$ раз.

Матрица парных сравнений, которая обладает свойствами обратной
симметричности и~транзитивности, называется согласованной.
Несложно показать, что если матрица $\mathbf{A}$ согласована, то
найдется положительный вектор $\mathbf{a}=(a_{i})$, который
однозначно определяет элементы матрицы следующим образом:
$a_{ij}=a_{i}/a_{j}$, а~его элементы $a_{i}$ показывают абсолютную
степень предпочтения альтернатив $i=1,\ldots,n$.

В практических задачах матрица парных сравнений $\mathbf{A}$
обычно не является согласованной по причине того, что свойства
транзитивности, а~иногда и~обратной симметричности оказываются
нарушенными. Отсюда возникает задача аппроксимации матрицы
$\mathbf{A}$ некоторой согласованной матрицей $\mathbf{X}$,
которая заключается в~минимизации подходящей функции расстояния
между матрицами (ошибки аппроксимации). В~силу того, что элементы
согласованной матрицы $\mathbf{X}=(x_{ij})$ определяются вектором
$\mathbf{x}=(x_{i})$ по формуле $x_{ij}=x_{i}/x_{j}$, задачу
аппроксимации можно представить в~виде задачи нахождения вектора
рейтингов $\mathbf{x}$, на котором достигается
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \varphi(\mathbf{A},\mathbf{x}),
\end{aligned}
\label{P-minxvarphiAx}
\end{equation}
где $\varphi$~--- ошибка аппроксимации матрицы $\mathbf{A}$
матрицей, заданной вектором $\mathbf{x}$.

Для определения вектора $\mathbf{x}$ рейтингов альтернатив часто
используют метод главного собственного вектора [4], в~котором
в~качестве $\mathbf{x}$ берется собственный вектор матрицы парных
сравнений, соответствующий ее максимальному собственному числу.
В~настоящей работе используется подход на основе аппроксимации
матриц парных сравнений в~метрике Чебышева в~логарифмической
шкале, который будет описан в~п.~4.


{\bfseries 3.~Метод анализа иерархий.} Рассмотрим
многокритериальную задачу, в~которой $n$ альтернатив сравниваются
попарно согласно $m$ критериям. Заданы матрицы
$\mathbf{A}_{k}=(a_{ij}^{(k)})$ парных сравнений альтернатив по
критериям $k=1,\ldots,m$. Результаты сравнения критериев
составляют матрицу парных сравнений критериев
$\mathbf{C}=(c_{rs})$, где элемент $c_{rs}$ показывает, во сколько
раз критерий $r$ важнее (более значим) для принятия решения, чем
критерий $s$. Необходимо на основе матриц парных сравнений
$\mathbf{A}_{1},\ldots,\mathbf{A}_{m}$ и~$\mathbf{C}$ определить
абсолютную степень предпочтения каждой альтер\-нативы.

Распространенный подход к~решению такой многокритериальной задачи
состоит в~использовании метода анализа иерархий [4], который
включает два основных шага. Сначала для матриц $\mathbf{A}_{k}$
парных сравнений альтернатив по каждому критерию $k$, а~также
матрицы $\mathbf{C}$ парных сравнений критериев находят главные
собственные векторы. Затем все векторы нормируются и~вычисляется
вектор индивидуальных рейтингов альтернатив в~виде взвешенной
суммы главных собственных векторов матриц парных сравнений
альтернатив с~элементами главного собственного вектора матрицы
парных сравнений критериев в~роли соответствующих весов.

Рассмотрим известный пример оценки рейтингов средних школ из
работы [4]. Предположим, что проведен сравнительный анализ трех
средних школ $A$, $B$ и~$C$ по шести неравнозначным критериям:
качество обучения основным предметам, друзья (количество
знакомых), школьная жизнь (мероприятия для школьников), качество
профессионального обучения, уровень подготовки к~колледжу
и~возможность обучения музыке. Требуется оценить индивидуальный
рейтинг каждой школы для обоснования и~поддержки принятия решения
о наиболее предпочтительном выборе школы.

Результаты парных сравнений школ по каждому критерию заданы
матрицами
\begin{equation}
\begin{aligned}
\mathbf{A}_{1} &=
\begin{pmatrix}
1 & 1/3 & 1/2
\\
3 & 1 & 3
\\
2 & 1/3 & 1
\end{pmatrix},
& \mathbf{A}_{2} &=
\begin{pmatrix}
1 & 1 & 1
\\
1 & 1 & 1
\\
1 & 1 & 1
\end{pmatrix},
& \mathbf{A}_{3} &=
\begin{pmatrix}
1 & 5 & 1
\\
1/5 & 1 & 1/5
\\
1 & 5 & 1
\end{pmatrix},
\\
\mathbf{A}_{4} &=
\begin{pmatrix}
1 & 9 & 7
\\
1/9 & 1 & 1/5
\\
1/7 & 5 & 1
\end{pmatrix},
& \mathbf{A}_{5} &=
\begin{pmatrix}
1 & 1/2 & 1
\\
2 & 1 & 2
\\
1 & 1/2 & 1
\end{pmatrix},
& \mathbf{A}_{6} &=
\begin{pmatrix}
1 & 6 & 4
\\
1/6 & 1 & 1/3
\\
1/4 & 3 & 1
\end{pmatrix}.
\end{aligned}
\label{E-A1A2A3A4A5A6}
\end{equation}

Сравнение значимости критериев дает матрицу парных сравнений
критериев в~виде
\begin{equation}
\mathbf{C} =
\begin{pmatrix}
1 & 5 & 7 & 5 & 3 & 1
\\
1/5 & 1 & 3 & 1/5 & 1/6 & 1/6
\\
1/7 & 1/3 & 1 & 1/4 & 1/5 & 1/5
\\
1/5 & 5 & 4 & 1 & 1/5 & 1/6
\\
1/3 & 6 & 5 & 5 & 1 & 1
\\
1 & 6 & 5 & 6 & 1 & 1
\end{pmatrix}.
\label{E-C}
\end{equation}

В результате применения метода анализа иерархий получают вектор
инди\-ви\-дуаль\-ных рейтингов школ [4]
\begin{equation}
\mathbf{x} \approx
\begin{pmatrix}
0.40 & 0.36 & 0.25
\end{pmatrix}^{\mathrm{T}},
\label{E-x}
\end{equation}
который ранжирует школы в~порядке $A\succ B\succ C$.

В п.~4 описывается подход к~решению рассматриваемой
многокритериальной задачи с~помощью $\log$-чебышевской
аппроксимации матриц парных сравнений согласованной матрицей.
В~п.~6 представлены формулировка задачи в~терминах тропической
математики и~ее решение на основе методов и~результатов
тропической оптимизации.


%\section{Минимаксная аппроксимация в~логарифмической шкале}
{\bfseries 4.~Минимаксная аппроксимация в~логарифмической шкале.}
Опишем подход к~решению многокритериальной задачи оценки
альтернатив с~использованием минимаксной взвешенной аппроксимации
матриц парных сравнений в~чебышевской метрике в~логарифмической
шкале, предложенный и~изученный в~работах [15--18, 24,~25].

Рассмотрим матрицу парных сравнений $\mathbf{A}=(a_{ij})$
с~положительными элементами. Будем решать задачу
\eqref{P-minxvarphiAx}   аппроксимации этой матрицы согласованной
матрицей $\mathbf{X}=(x_{ij})$. Учитывая, что элементы матриц
$\mathbf{A}$ и~$\mathbf{X}$ положительны, а~логарифм с~основанием
большим единицы монотонно возрастает, в~качестве меры ошибки
аппроксимации можно взять величину $\max_{i,j}|\log a_{ij}-\log
x_{ij}|=\log\max_{i,j}\max\{a_{ij}/x_{ij},x_{ij}/a_{ij}\}$.

В силу того, что элементы согласованной матрицы $\mathbf{X}$
определяются соот\-но\-ше\-нием $x_{ij}=x_i/x_j$, где $x_i$~---
компоненты некоторого вектора $\mathbf{x}$, выражение под знаком
логарифма принимает вид
$\max_{i,j}\max\{a_{ij}/x_{ij},x_{ij}/a_{ij}\}=\max_{i,j}\max\{a_{ij}x_j/x_i,x_i/a_{ij}x_j\}$.

Свойство монотонности позволяет свести минимизацию логарифма
к~минимизации его аргумента, что приводит к~задаче нахождения
вектора $\mathbf{x}$, который обеспечивает
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \max_{1\leq i,j\leq
n}\max\{a_{ij}x_{j}/x_{i},x_{i}/a_{ij}x_{j}\}.
\label{P-minxmaxmaxaijxjxixiaijxj}
\end{aligned}
\end{equation}

Если $\mathbf{A}$~--- обратно симметрическая матрица с~элементами
$a_{ij}=1/a_{ji}$, то, в~силу равенства
$x_{j}/a_{ji}x_{i}=a_{ij}x_j/x_i$ задачу
\eqref{P-minxmaxmaxaijxjxixiaijxj} можно записать так:\pagebreak

\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \max_{1\leq i,j\leq n}a_{ij}x_{j}/x_{i}.
\label{P-minxmaxaijxjxi}
\end{aligned}
\end{equation}

Рассмотрим задачу оценки рейтингов $n$ альтернатив на основе
парных сравнений по $m$ критериям с~неотрицательными весами
$w_{1},\ldots,w_{m}$. Пусть в~результате сравнений получают
матрицу $\mathbf{A}_{k}=(a_{ij}^{(k)})$ для каждого критерия
$k=1,\ldots,m$. Чтобы найти вектор $\mathbf{x}=(x_{i})$, который
одновременно аппроксимирует все матрицы с~учетом весов,
минимизируем по $\mathbf{x}$ максимальную по всем критериям $k$
взвешенную ошибку в~виде
$w_{k}\max_{i,j}\max\{a_{ij}^{(k)}x_{j}/x_{i},x_{i}/a_{ij}^{(k)}x_{j}\}=\max_{i,j}(w_{k}\max\{a_{ij}^{(k)}x_{j}/x_{i},x_{i}/a_{ij}^{(k)}x_{j}\})$.

Получим следующую минимаксную задачу $\log$-чебышевской
аппроксимации:
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \max_{1\leq k\leq m}\max_{1\leq i,j\leq
n}(w_{k}\max\{a_{ij}^{(k)}x_{j}/x_{i},x_{i}/a_{ij}^{(k)}x_{j}\}),
\label{P-minxmaxmaxmaxwkaijkxjxiwkxiaijkxj}
\end{aligned}
\end{equation}
которая в~случае, когда все матрицы $\mathbf{A}_{k}$ обратно
симметрические, принимает форму
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \max_{1\leq k\leq m}\max_{1\leq i,j\leq
n}(w_{k}a_{ij}^{(k)})x_{j}/x_{i}. \label{P-minxmaxmaxwkaijkxjxi}
\end{aligned}
\end{equation}
Заметим, что задачи \eqref{P-minxmaxmaxmaxwkaijkxjxiwkxiaijkxj}
и~\eqref{P-minxmaxmaxwkaijkxjxi} могут быть сведены соответственно
к~задачам \eqref{P-minxmaxmaxaijxjxixiaijxj}
и~\eqref{P-minxmaxaijxjxi}. Например, с~помощью матрицы
$\mathbf{D}=(d_{ij})$ с~элементами
$d_{ij}=\max_{k}w_{k}a_{ij}^{(k)}$ задача
\eqref{P-minxmaxmaxwkaijkxjxi} принимает вид задачи
\eqref{P-minxmaxaijxjxi}, где матрица $\mathbf{A}$ заменяется на
$\mathbf{D}$.

Описанный подход можно рассматривать как аналог метода анализа
иерархий, в~котором вместо метода главного собственного вектора
используется $\log$-чебышевская аппроксимация, а~вектор рейтингов
альтернатив находится путем решения задачи минимаксной
аппроксимации взвешенных матриц парных сравнений по всем
критериям.

Предположим, что в~результате решения задач
\eqref{P-minxmaxmaxaijxjxixiaijxj} и~\eqref{P-minxmaxaijxjxi} (или
\eqref{P-minxmaxmaxmaxwkaijkxjxiwkxiaijkxj}
и~\eqref{P-minxmaxmaxwkaijkxjxi}) получен не единственный (с
точностью до положительного множителя) вектор рейтингов,
а~некоторое множество $\mathcal{S}$ векторов. Чтобы
охарактеризовать множество $\mathcal{S}$, определим векторы,
которые являются в~определенном смысле наихудшим и~наилучшим
решениями. В~качестве наихудшего решения возьмем вектор, который
минимально различает (дифференцирует) альтернативы с~высшим
и~низшим рейтингами, а~в~качестве наилучшего~--- вектор, который
максимально различает эти альтернативы (см.~[18,~24,~25]).

Наихудший и~наилучший дифференцирующие векторы рейтингов находятся
путем минимизации и~максимизации максимального отношения между
компонентами вектора $\mathbf{x}=(x_{i})$, которое имеет следующий
вид:
$\max_{i}x_{i}/\min_{j}x_{j}=\max_{i}x_{i}\times\max_{j}(1/x_{j})$.
Тогда задачи нахождения наихудшего и~наилучшего решений
записы\-ваются в~форме
\begin{gather}
\begin{aligned}
& \min_{\mathbf{x}\in\mathcal{S}} && \max_{1\leq i\leq
n}x_{i}\times\max_{1\leq j\leq n}(1/x_{j}),
\end{aligned}
\qquad
\begin{aligned}
& \max_{\mathbf{x}\in\mathcal{S}} && \max_{1\leq i\leq
n}x_{i}\times\max_{1\leq j\leq n}(1/x_{j}).
\end{aligned}
\label{P-minmaxxSmaxximax1xj}
\end{gather}

Рассмотренные задачи оптимизации будут представлены ниже как
задачи тропической оптимизации, для которых находятся прямые
решения в~явном виде.


{\bfseries 5.~Элементы тропической математики.} Тропическая
математика изучает алгебраические структуры с~идемпотентными
операциями [10--14]. Для формулировки и~решения задач оптимизации
будем использовать вещественное идемпотентное полуполе
$\mathbb{R}_{\max}=(\mathbb{R}_{+},\max,\times,0,1)$, где
$\mathbb{R}_{+}=\{x\in\mathbb{R}\mid x\geq0\}$, которое
назы\-вают $\max$-алгеброй. В~полуполе $\mathbb{R}_{\max}$
операция сложения определена как $\max$ и~ниже обозначается знаком
$\oplus$, а~операция умножения определена и~обозначается, как
обычно.

Операции сложения и~умножения являются ассоциативными
и~коммутативными с~нейтральными элементами $0$ и~$1$. Сложение
обладает свойством идемпотентности: $x\oplus x=x$ для любого
$x\in\mathbb{R}_{+}$. Умножение дистрибутивно относительно
сложения и~обратимо, т.~е. для любого $x\neq0$ существует обратный
элемент $x^{-1}$ такой, что $xx^{-1}=1$.

Матрицы и~векторы над $\mathbb{R}_{+}$ вводятся обычным путем.
Множество матриц, состоящих из $m$ строк и~$n$ столбцов,
обозначается через $\mathbb{R}_{+}^{m\times n}$. Операции сложения
и умножения матриц подходящего размера выполняются по стандартным
правилам с~заменой арифметического сложения на операцию $\oplus$.
Операция умножения матрицы на скаляр выполняется как обычно.
Нулевая и~единичная матрицы имеют стандартную форму и~обозначаются
$\mathbf{0}$ и~$\mathbf{I}$. Матрица без нулевых элементов
является положительной.

Матрица, состоящая из одного столбца или строки, образует вектор.
Множество векторов-столбцов размера $n$ обозначается через
$\mathbb{R}_{+}^{n}$. Векторы-столбцы, все элементы которых равны
$0$ или $1$, обозначаются соответственно $\mathbf{0}$ или
$\mathbf{1}$.

Рассмотрим квадратные матрицы из множества $\mathbb{R}_{+}^{n
\times n}$. Целая неотрицательная степень любой матрицы
$\mathbf{A}\in\mathbb{R}_{+}^{n\times n}$ определяется обычным
путем: $\mathbf{A}^{0}=\mathbf{I}$,
$\mathbf{A}^{m}=\mathbf{A}\mathbf{A}^{m-1}$, где $m$~---
натуральное число. След матрицы $\mathbf{A}$ вычисляется по
формуле
\begin{equation*}
\mathop\mathrm{tr}\mathbf{A} = a_{11}\oplus\cdots\oplus a_{nn}.
%=
%\bigoplus_{m=1}^{n} a_{mm}.
\end{equation*}

Спектральным радиусом матрицы $\mathbf{A}$ называется скаляр
\begin{equation*}
\lambda = \mathop\mathrm{tr}\mathbf{A} \oplus\cdots\oplus
\mathop\mathrm{tr}\nolimits^{1/n}(\mathbf{A}^{n}).
%\label{E-lambda}
\end{equation*}
Если для $\mathbf{A}$ выполняется условие $\lambda\leq1$, можно
построить матрицу (матрицу Клини)
\begin{equation*}
\mathbf{A}^{\ast} =
\mathbf{I}\oplus\mathbf{A}\oplus\cdots\oplus\mathbf{A}^{n-1}.
\end{equation*}

Для любой ненулевой матрицы
$\mathbf{A}=(a_{ij})\in\mathbb{R}_{+}^{m \times n}$ существует
мультипликативно сопряженная матрица
$\mathbf{A}^{-}=(a^{-}_{ij})\in \mathbb{R}_{+}^{n \times m},$ где
$a^{-}_{ij}=a^{-1}_{ji}$, если $a_{ji} \neq 0$, иначе
$a^{-}_{ij}=0$.

Квадратная матрица $\mathbf{A}\in\mathbb{R}_{+}^{n \times n}$
является обратно симметрической, если $\mathbf{A}^{-}=\mathbf{A}$.

Любому ненулевому вектору-столбцу
$\mathbf{x}=(x_i)\in\mathbb{R}_{+}^{n}$ сопоставляется
мультипликативно сопряженный вектор-строка
$\mathbf{x}^{-}=(x^{-}_i)$, где $x^{-}_i=x^{-1}_i$, если $x_i \neq
0$, иначе $x^{-}_i={0}$.

Согласованная матрица $\mathbf{X}$ имеет вид
$\mathbf{X}=\mathbf{x}\mathbf{x}^{-}$, где $\mathbf{x}$~---
положительный вектор.

Вектор $\mathbf{b}\in\mathbb{R}_{+}^{n}$ линейно зависит от
векторов
$\mathbf{a}_{1},\ldots,\mathbf{a}_{m}\in\mathbb{R}_{+}^{n}$, если
его можно представить как линейную комбинацию $\mathbf{b}=x_{1}
\mathbf{a}_{1}\oplus\cdots\oplus x_{m}\mathbf{a}_{m}$
с~коэффициентами $x_{1},\ldots,x_{m}\in\mathbb{R}_{+}$. Вектор
$\mathbf{b}$ коллинеарен $\mathbf{a}$, если существует такой
скаляр $x$, что $\mathbf{b}=x\mathbf{a}$.


{\bfseries 6.~Применение методов тропической оптимизации.}
Представим многокритериальную задачу оценки альтернатив на основе
минимаксной $\log$-чебышевской аппроксимации матриц парных
сравнений в~виде ряда задач оптимизации в~терминах тропической
математики и~опишем их решение.

{\bfseries\itshape 6.1.~Оценка рейтингов альтернатив на основе
парных сравнений.} Рассмотрим однокритериальную задачу оценки
рейтингов $n$ альтернатив по матрице парных сравнений
$\mathbf{A}\in\mathbb{R}_{+}^{n\times n}$. Будем решать задачу
аппроксимации \eqref{P-minxvarphiAx} с~измерением ошибки
аппроксимации в~метрике Чебышева в~логарифмической шкале.

Если обратная симметричность матрицы $\mathbf{A}$ не
предполагается, то задача \eqref{P-minxvarphiAx}   принимает вид
\eqref{P-minxmaxmaxaijxjxixiaijxj}, которая в~терминах полуполя
$\mathbb{R}_{\max}$ записывается так:
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} &&
\mathbf{x}^{-}(\mathbf{A}\oplus\mathbf{A}^{-})\mathbf{x}.
\label{P-minxxAAx}
\end{aligned}
\end{equation}

Полное решение задачи, которое определяет вектор рейтингов
альтернатив $\mathbf{x}$, дает следующий результат [15, 17].
%\begin{theorem}
%\label{T-minxxAAx}

{\bfseries Теорема~1.} {\itshape Пусть $\mathbf{A}$~--- ненулевая
матрица и~$\mu$~--- спектральный радиус матрицы
$\mathbf{D}=\mathbf{A}\oplus\mathbf{A}^{-}$. Тогда минимум
в~задаче \eqref{P-minxxAAx} равен $\mu$, а~все положительные
решения имеют вид
$\mathbf{x}=(\mu^{-1}\mathbf{D})^{\ast}\mathbf{u}$, где
$\mathbf{u}>\bm{0}$.
%\end{theorem}
\par}

Если матрица $\mathbf{A}$ обратно симметрическая, то имеем задачу
\eqref{P-minxmaxaijxjxi}. Записывая ее в~терминах
$\mathbb{R}_{\max}$, получим
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} && \mathbf{x}^{-}\mathbf{A}\mathbf{x}.
\label{P-minxxAx}
\end{aligned}
\end{equation}

Решение задачи обеспечивает следствие теоремы~1 (см. также [15,
16]).
%\begin{corollary}
%\label{C-minxxAx}

{\bfseries Следствие~1.} {\itshape Пусть $\mathbf{A}$~{\rm
---} обратно
симметрическая матрица со спектральным радиусом $\lambda$. Тогда
минимум в~задаче \eqref{P-minxxAx} равен $\lambda$, а~все
положительные решения имеют вид
$\mathbf{x}=(\lambda^{-1}\mathbf{A})^{\ast}\mathbf{u}$, где
$\mathbf{u}>\bm{0}$.
%\end{corollary}
\par}

Предположим, что имеется $m$ критериев с~весами
$w_{1},\ldots,w_{m}\in\mathbb{R}_{+}$, а~также $m$ матриц
$\mathbf{A}_{1},\ldots,\mathbf{A}_{m}\in\mathbb{R}_{+}^{n\times
n}$, полученных в~результате парных сравнений альтернатив по
указанным критериям. Применение минимаксной $\log$-чебышевской
аппроксимации приводит к~задаче
\eqref{P-minxmaxmaxmaxwkaijkxjxiwkxiaijkxj} или к~эквивалентной
задаче тропической оптимизации
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} &&
\mathbf{x}^{-}(w_{1}(\mathbf{A}_{1}\oplus\mathbf{A}_{1}^{-})\oplus\cdots\oplus
w_{m}(\mathbf{A}_{m}\oplus\mathbf{A}_{m}^{-}))\mathbf{x}.
\label{P-minxw1A1A1wmAmAmx}
\end{aligned}
\end{equation}

Приведем теорему из [17], которая дает решение такой задачи.
%\begin{theorem}
%\label{T-minxw1A1A1wmAmAmx}

{\bfseries Теорема~2.} {\itshape Пусть $\mathbf{A}_{i}$~{\rm
---}
ненулевая матрица для всех $i=1,\ldots,m$ и ~$\mu$~{\rm
---}
спектральный радиус матрицы
$\mathbf{D}=w_{1}(\mathbf{A}_{1}\oplus\mathbf{A}^{-}_{1})\oplus\cdots\oplus
w_{m}(\mathbf{A}_{m}\oplus\mathbf{A}_{m}^{-})$. Тогда минимум
в~\eqref{P-minxw1A1A1wmAmAmx} равен $\mu$, а~все положительные
решения имеют вид
$\mathbf{x}=(\mu^{-1}\mathbf{D})^{\ast}\mathbf{u}$, где
$\mathbf{u}>\bm{0}$.
%\end{theorem}
\par}

Когда все матрицы $\mathbf{A}_{i}$ обратно симметрические, получим
задачу
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}} &&
\mathbf{x}^{-}(w_{1}\mathbf{A}_{1}\oplus\cdots\oplus
w_{m}\mathbf{A}_{m})\mathbf{x}. \label{P-minxw1A1wmAmx}
\end{aligned}
\end{equation}
%\begin{corollary}
%\label{C-minxw1A1wmAmx}

{\bfseries Следствие~2.} {\itshape Пусть $\mathbf{A}_{i}$~{\rm
---} обратно симметрические матрицы для всех $i=1,\ldots, m$ и~
$\mu$~{\rm
---} спектральный радиус матрицы
$\mathbf{D}=w_{1}\mathbf{A}_{1}\oplus\cdots\oplus
w_{m}\mathbf{A}_{m}$. Тогда минимум в~\eqref{P-minxw1A1wmAmx}
равен $\mu$, а~все положительные решения имеют вид
$\mathbf{x}=(\mu^{-1}\mathbf{D})^{\ast}\mathbf{u}$, где
$\mathbf{u}>\mathbf{0}$.
%\end{corollary}
\par}

{\bfseries\itshape 6.2.~Наихудшее и~наилучшее дифференцирующие
решения.} При оценке рейтингов альтернатив с~помощью выше
приведенных результатов решение записывается как
$\mathbf{x}=(\mu^{-1}\mathbf{D})^{\ast}\mathbf{u}$, здесь
$\mathbf{D}$~--- матрица, полученная из матрицы парных сравнений
в~однокритериальных задачах, или взвешенная сумма таких матриц
в~многокритериальных задачах, $\mu$~--- спектральный радиус
матрицы $\mathbf{D}$, а~$\mathbf{u}$~--- вектор параметров.
В~общем случае множество решений, которое представляет собой
тропическую линейную оболочку столбцов матрицы
$(\mu^{-1}\mathbf{D})^{\ast}$, может включать различные решения.

Чтобы охарактеризовать все множество решений при помощи векторов,
которые минимально и~максимально дифференцируют альтернативы
с~наибольшим и~наименьшим рейтингами, требуется решить задачи
\eqref{P-minmaxxSmaxximax1xj} минимизации и~максимизации
максимального отношения между компонентами вектора решений
$\mathbf{x}=(x_{i})$. Используя операции полуполя
$\mathbb{R}_{\max}$, запишем это отношение в~виде
\begin{equation*}
\bigoplus_{1\leq i\leq n}x_{i}\bigoplus_{1\leq j\leq
n}x_{j}^{-1}=\mathbf{1}^{\mathrm{T}}\mathbf{xx}^{-}\mathbf{1}.
\end{equation*}

С учетом множества решений $\mathcal{S}=\{\mathbf{x}|\
\mathbf{x}=(\mu^{-1}\mathbf{D})^{\ast}\mathbf{u},\
\mathbf{u}>\mathbf{0}\}$ задачи \eqref{P-minmaxxSmaxximax1xj}
нахождения наихудшего и~наилучшего дифференцирующих решений
представим как
\begin{equation}
\begin{aligned}
& \min_{\mathbf{x}\in\mathcal{S}} &&
\mathbf{1}^{\mathrm{T}}\mathbf{xx}^{-}\mathbf{1},
\end{aligned}
\qquad
\begin{aligned}
& \max_{\mathbf{x}\in\mathcal{S}} &&
\mathbf{1}^{\mathrm{T}}\mathbf{xx}^{-}\mathbf{1}.
\end{aligned}
\label{P-minmaxx1muDu1Du1}
\end{equation}

Полное решение задач \eqref{P-minmaxx1muDu1Du1} дают следующие
результаты (см. также [18, 25, 26]).
%\begin{lemma}
%\label{L-minx1muDu1Du1}

{\bfseries Лемма~1.} {\itshape Пусть $\mathbf{D}$~{\rm
---} матрица со
спектральным радиусом $\mu$
и~$\delta=\mathbf{1}^{\mathrm{T}}(\mu^{-1}\mathbf{D})^{\ast}
\mathbf{1}$. Тогда минимум в~задаче минимизации
\eqref{P-minmaxx1muDu1Du1} равен $\delta$, а~наихудший
дифференцирующий вектор имеет вид
$\mathbf{x}_{1}=(\delta^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}}\oplus\mu^{-1}\mathbf{D})^{\ast}\mathbf{u}_{1}$,
где $\mathbf{u}_{1}\geq\bm{0}$.
%\end{lemma}
\par}

%\begin{lemma}
%\label{L-maxx1muDu1Du1}

{\bfseries Лемма~2.} {\itshape Пусть
$\mathbf{B}=(\mathbf{b}_j)$~{\rm
---} матрица, полученная из
$(\mu^{-1}\mathbf{D})^{\ast}$ вычеркива\-нием столбцов, линейно
зависимых от остальных, а~$\mathbf{B}_{sk}$~{\rm
---} матрица, полученная
 из $\mathbf{B}=(b_{ij})$ обращением в~нуль всех
элементов, кроме $b_{sk}$. Тогда максимум в~задаче максимизации
\eqref{P-minmaxx1muDu1Du1} равен
$\Delta=\mathbf{1}^{\mathrm{T}}\mathbf{B}\mathbf{B}^{-}\mathbf{1}$,
а наилучший дифференцирующий вектор имеет вид
$\mathbf{x}_{2}=\mathbf{B}(\mathbf{I}\oplus\mathbf{B}_{sk}^{-}\mathbf{B})\mathbf{u}_{2}$,
где $\mathbf{u}_{2}>\mathbf{0}$, а~индексы $k$ и~$s$ находятся из
условий
\begin{equation*}
k =
\arg\max_{j}\mathbf{1}^{\mathrm{T}}\mathbf{b}_{j}\mathbf{b}_{j}^{-}\mathbf{1},
\qquad s = \arg\max_{i}b_{ik}^{-1}.
\end{equation*}
%\end{lemma}
\par}


%\section{Решение многокритериальной задачи принятия решений}\label{sec:procedure}
{\bfseries 7.~Процедура решения многокритериальной задачи принятия
решений.} Представленные выше результаты используются для
построения многокритериальной процедуры оценки рейтингов
альтернатив на основе парных сравнений.

Пусть $\mathbf{A}_{1},\ldots,\mathbf{A}_{m}$~--- матрицы парных
сравнений альтернатив относительно $m$ заданных критериев,
$\mathbf{C}$~--- матрица парных сравнений этих критериев.
Предлагаемая процедура оценки рейтингов альтернатив, которая может
рассматриваться как тропический аналог метода анализа иерархий,
состоит из следующих шагов (см. также [24--26]).

1. По матрице $\mathbf{C}$ определяется вектор весов критериев
\begin{equation*}
\mathbf{w} = (\mu^{-1}\mathbf{C})^{\ast}\mathbf{u}, \qquad
\mathbf{u}>\mathbf{0}, \qquad \mu =
%\bigoplus_{k=1}^{m}\mathop\mathrm{tr}\nolimits^{1/k}(\mathbf{C}^{k})
\mathop\mathrm{tr}\mathbf{C} \oplus\cdots\oplus
\mathop\mathrm{tr}\nolimits^{1/m}(\mathbf{C}^{m}).
\end{equation*}

2. Если полученный вектор не единственный (с точностью до
положительного множителя), то находятся наихудший дифференцирующий
вектор весов
\begin{equation*}
\mathbf{w}_{1}=(\delta^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}}\oplus\mu^{-1}\mathbf{C})^{\ast}\mathbf{v}_{1},
\qquad \mathbf{v}_{1}>\mathbf{0}, \qquad
\delta=\mathbf{1}^{\mathrm{T}}(\mu^{-1}\mathbf{C})^{\ast}\mathbf{1},
\end{equation*}
и наилучший дифференцирующий вектор весов
\begin{equation*}
\mathbf{w}_{2} =
\mathbf{P}(\mathbf{I}\oplus\mathbf{P}_{sk}^{-}\mathbf{P})\mathbf{v}_{2},
\qquad \mathbf{v}_{2}>\mathbf{0},
\end{equation*}
для которого матрица $\mathbf{P}=(\mathbf{p}_{j})$ получена из
матрицы $(\mu^{-1}\mathbf{C})^{\ast}$ вычеркиванием столбцов,
линейно зависимых от остальных, матрица $\mathbf{P}_{sk}$~--- из
матрицы $\mathbf{P}=(p_{ij})$ обращением в~нуль всех элементов,
кроме $p_{sk}$, а~индексы $k$ и~$s$ определяются, исходя из
условий
\begin{equation*}
k =
\arg\max_{j}\mathbf{1}^{\mathrm{T}}\mathbf{p}_{j}\mathbf{p}_{j}^{-}\mathbf{1},
\qquad s = \arg\max_{i}p_{ik}^{-1}.
\end{equation*}

3. С~помощью векторов $\mathbf{w}_{1}=(w^{(1)}_{i})$
и~$\mathbf{w}_{2}=(w^{(2)}_{i})$ составляются взвешенные суммы
матриц парных сравнений (или только одна сумма, когда векторы
весов совпадают)
\begin{equation*}
\mathbf{D}_{1} =
%\bigoplus_{k=1}^{m}w^{(1)}_{k}\mathbf{A}_{k},
w^{(1)}_{1}\mathbf{A}_{1} \oplus\cdots\oplus
w^{(1)}_{m}\mathbf{A}_{m}, \qquad \mathbf{D}_{2} =
%\bigoplus_{k=1}^{m} w^{(2)}_{k} \mathbf{A}_{k}.
w^{(2)}_{1}\mathbf{A}_{1} \oplus\cdots\oplus
w^{(2)}_{m}\mathbf{A}_{m}.
\end{equation*}

4. Вычисляется наихудший дифференцирующий вектор рейтингов
альтернатив
\begin{equation*}
\mathbf{x}_{1} =
(\nu_{1}^{-1}\mathbf{D}_{1})^{\ast}\mathbf{u}_{1}, \qquad
\mathbf{u}_{1}>\mathbf{0}, \qquad \nu_{1} =
%\bigoplus^{n}_{i=1} \mathop\mathrm{tr}\nolimits^{1/i}(\mathbf{D}_{1}^{i}).
\mathop\mathrm{tr}\mathbf{D}_{1} \oplus\cdots\oplus
\mathop\mathrm{tr}\nolimits^{1/n}(\mathbf{D}_{1}^{n}).
\end{equation*}

5. Если полученный вектор не единственный, то вместо него берется
вектор
\begin{equation*}
\mathbf{x}_{1} =
(\delta_{1}^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}}\oplus\nu_{1}^{-1}\mathbf{D}_{1})^{\ast}\mathbf{u}_{1},
\qquad \mathbf{u}_{1}>\mathbf{0}, \qquad \delta_{1} =
\mathbf{1}^{\mathrm{T}}(\nu^{-1}\mathbf{D}_{1})^{\ast} \mathbf{1}.
\end{equation*}

6. Вычисляется наилучший дифференцирующий вектор рейтингов
альтернатив
\begin{equation*}
\mathbf{x}_{2} =
(\nu_{2}^{-1}\mathbf{D}_{2})^{\ast}\mathbf{u}_{2}, \qquad
\mathbf{u}_{2} > 0, \qquad \nu_{2} =
%\bigoplus^{n}_{i=1} \mathop\mathrm{tr}\nolimits^{1/i}(\mathbf{D}_{2}^{i}).
\mathop\mathrm{tr}\mathbf{D}_{2} \oplus\cdots\oplus
\mathop\mathrm{tr}\nolimits^{1/n}(\mathbf{D}_{2}^{n}).
\end{equation*}

7. Если этот вектор не единственный, то вместо него берется вектор
\begin{equation*}
\mathbf{x}_{2} =
\mathbf{Q}(\mathbf{I}\oplus\mathbf{Q}_{sk}^{-}\mathbf{Q})\mathbf{u}_{2},
\qquad \mathbf{u}_{2} > \mathbf{0},
\end{equation*}
где матрица $\mathbf{Q}=(\mathbf{q}_{j})$ получена из матрицы
$(\nu_{2}^{-1}\mathbf{D}_{2})^{\ast}$ вычеркиванием столбцов,
линейно зависимых от остальных, матрица $\mathbf{Q}_{sk}$~--- из
матрицы $\mathbf{Q}=(q_{ij})$ обращением в~нуль всех элементов,
кроме $q_{sk}$, а~индексы $k$ и~$s$ определяются, исходя из
условий
\begin{equation*}
k =
\arg\max_{j}\mathbf{1}^{\mathrm{T}}\mathbf{q}_{j}\mathbf{q}_{j}^{-}\mathbf{1},
\qquad s = \arg\max_{i}q_{ik}^{-1}.
\end{equation*}


%\section{Решение задачи выбора школы}
{\bfseries 8.~Решение задачи выбора школы.} Применим предложенную
процедуру к~решению рассмотренной выше задачи выбора школы из
работы~[4].

%\subsection{Вычисление вектора весов критериев}\label{sec:weightVector}
{\bfseries\itshape 8.1.~Вычисление вектора весов критериев.} По
матрице парных сравнений критериев $\mathbf{C}$ в~виде \eqref{E-C}
найдем вектор весов критериев с~помощью следствия~1. После
вычисления спектрального радиуса $\mu$ матрицы $\mathbf{C}$
и~матрицы $\mu^{-1}\mathbf{C}$ будем иметь
\begin{equation*}
\mu
%=
%18^{1/4}
= 2^{1/4}3^{1/2} \approx 2.06, \qquad \mu^{-1}\mathbf{C} =
\mu^{-1}
\begin{pmatrix}
1 & 5 & 7 & 5 & 3 & 1
\\
1/5 & 1 & 3 & 1/5 & 1/6 & 1/6
\\
1/7 & 1/3 & 1 & 1/4 & 1/5 & 1/5
\\
1/5 & 5 & 4 & 1 & 1/5 & 1/6
\\
1/3 & 6 & 5 & 5 & 1 & 1
\\
1 & 6 & 5 & 6 & 1 & 1
\end{pmatrix}.
\end{equation*}

Затем построим матрицу Клини
\begin{equation}
(\mu^{-1}\mathbf{C})^{\ast} =
\begin{pmatrix}
1 & 25\mu/6 & 25/2 & 15/\mu^{2} & 3/\mu & 5/2\mu
\\
3/7 \mu^{2} & 1 & 3/\mu & \mu/5 & \mu/14 & 3/5\mu^{2}
\\
1/7\mu & \mu/3 & 1 & 6/5\mu^{2} & 3/7\mu^{2} & 1/5\mu
\\
5\mu/42 & 5/\mu & 5\mu^{2}/6 & 1 & 5/14 & \mu/6
\\
25/42 & 25/\mu^{2} & 25\mu/6 & 5/\mu & 1 & 5/6
\\
5/7 & 5\mu^{2}/3 & 5\mu & 6/\mu & 15/7\mu & 1
\end{pmatrix}.
\label{E-mu1Cast}
\end{equation}

Для определения наихудшего дифференцирующего вектора весов по
лемме~1 необходимо найти
\begin{equation*}
\delta = 25/2, \qquad
\delta^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}}\oplus\mu^{-1}\mathbf{C}
= \mu^{-1}
\begin{pmatrix}
1 & 5 & 7 & 5 & 3 & 1
\\
1/5 & 1 & 3 & 1/5 & 1/6 & 1/6
\\
2\mu/25 & 1/3 & 1 & 1/4 & 1/5 & 1/5
\\
1/5 & 5 & 4 & 1 & 1/5 & 1/6
\\
1/3 & 6 & 5 & 5 & 1 & 1
\\
1 & 6 & 5 & 6 & 1 & 1
\end{pmatrix}.
\end{equation*}

Составим матрицу Клини, порождающую наихудший дифференцирующий
вектор:
\begin{equation*}
(\delta^{-1}\mathbf{1}\mathbf{1}^{-}\oplus\mu^{-1}\mathbf{C})^{\ast}
=
\begin{pmatrix}
1 & 25\mu/6 & 25/2 & 5\mu^{2}/6 & 3/\mu & 5/2\mu
\\
6/25\mu & 1 & 3/\mu & \mu/5 & \mu^{2}/25 & 3/5\mu^{2}
\\
2/25 & \mu/3 & 1 & 6/5\mu^{2} & 6/25\mu & 1/5\mu
\\
6/5\mu^{2} & 5/\mu & 5\mu^{2}/6 & 1 & \mu/5 & \mu/6
\\
\mu/3 & 25/\mu^{2} & 25\mu/6 & 5/\mu & 1 & 5/6
\\
2\mu/5 & 5\mu^{2}/3 & 5\mu & 6/\mu & 6/5 & 1
\end{pmatrix}.
\end{equation*}

Нетрудно проверить, что все столбцы полученной матрицы
коллинеарны. Например, умножение на $25\mu/6$ первого столбца дает
второй столбец. Тогда в~качестве вектора весов, который наихудшим
образом различает критерии с~наибольшим и~наименьшим весами, можно
взять любой столбец матрицы. Выбор второго столбца дает вектор
весов
\begin{equation}
\mathbf{w}_{1} =
\begin{pmatrix}
25\mu/6 & 1 & \mu/3 & 5/\mu & 25/\mu^{2} & 5\mu^{2}/3
\end{pmatrix}^{\mathrm{T}}
v, \qquad v
>
0. \label{E-w1}
\end{equation}

С помощью леммы~2 определим вектор весов, который максимально
различает критерии с~наибольшим и~наименьшим весами. Рассмотрим
матрицу \eqref{E-mu1Cast} и~удалим столбцы, которые линейно
зависят от остальных. Получим матрицу
\begin{equation*}
\mathbf{P} =
\begin{pmatrix}
1 & 25\mu/6 & 3/\mu
\\
3/7 \mu^{2} & 1 & \mu/14
\\
1/7\mu & \mu/3 & 3/7\mu^{2}
\\
5\mu/42 & 5/\mu & 5/14
\\
25/42  & 25/\mu^{2} & 1
\\
5/7 & 5\mu^{2}/3 & 15/7\mu
\end{pmatrix}.
\end{equation*}

Теперь найдем индекс $k$, при котором достигается максимум
$\mathbf{1}^{\mathrm{T}}\mathbf{p}_{k}\mathbf{p}_{k}^{-}\mathbf{1}$,
а также индекс $s$, обеспечивающий максимум величины
$p_{sk}^{-1}$. Сравнивая результаты вычислений
\begin{equation*}
\mathbf{1}^{\mathrm{T}}\mathbf{p}_{1}\mathbf{p}_{1}^{-}\mathbf{1}
= 7\mu\approx 14.42, \qquad
\mathbf{1}^{\mathrm{T}}\mathbf{p}_{2}\mathbf{p}_{2}^{-}\mathbf{1}
= 25/2\approx 12.5, \qquad
\mathbf{1}^{\mathrm{T}}\mathbf{p}_{3}\mathbf{p}_{3}^{-}\mathbf{1}
= 7\mu\approx 14.42,
\end{equation*}
заключаем, что следует положить $k=1$ или $k=3$.

Пусть сначала $k=1$. Определим максимальную из величин
\begin{align*}
p_{11}^{-1} &= 1,
&%\qquad
p_{21}^{-1} &= 7\mu^{2}/3 \approx 9.90,
&%\qquad
p_{31}^{-1} &= 7\mu \approx 14.42,
\\
p_{41}^{-1} &= 42/5\mu \approx 4.08,
&%\qquad
p_{51}^{-1} &= 42/25 \approx 1.68,
&%\qquad
p_{61}^{-1} &= 7/5 \approx 1.40.
\end{align*}
Учитывая, что максимум равен $p_{31}^{-1}$, положим $s=3$ и~найдем
матрицы
\begin{equation*}
\mathbf{P}_{31} =
\begin{pmatrix}
0 & 0 & 0
\\
0 & 0 & 0
\\
1/7\mu & 0 & 0
\\
0 & 0 & 0
\\
0 & 0 & 0
\\
0 & 0 & 0
\end{pmatrix},
\qquad \mathbf{P}(\mathbf{I}\oplus\mathbf{P}_{31}^{-}\mathbf{P}) =
\begin{pmatrix}
1 & 7\mu^{2}/3 & 3/\mu
\\
3/7\mu^{2} & 1 & \mu/14
\\
1/7\mu & \mu/3 & 3/7\mu^{2}
\\
5\mu/42 & 15/\mu  & 5/14
\\
25/42 & 25 \mu^{2}/6 & 1
\\
5/7 & 5\mu^{2}/3 & 15/7\mu
\end{pmatrix}.
\end{equation*}
Первый и~второй столбцы последней матрицы коллинеарны. Отбрасывая
один из них, например второй, запишем наилучший дифференцирующий
вектор весов в~виде
\begin{equation}
\mathbf{w}_{2} =
\begin{pmatrix}
1 & 3/7\mu^{2} & 1/7\mu & 5\mu/42 & 25/42 & 5/7
\\
3/\mu & \mu/14 & 3/7\mu^{2} & 5/14 & 1 & 15/7\mu
\end{pmatrix}^{\mathrm{T}}
\mathbf{v}, \qquad \mathbf{v}>\mathbf{0}. \label{E-w2}
\end{equation}

Рассуждая аналогично, нетрудно показать, что при $k=3$ вектор
весов колли\-неа\-рен последнему столбцу матрицы
$\mathbf{P}(\mathbf{I}\oplus\mathbf{P}_{31}^{-}\mathbf{P})$,
а~потому новых решений не дает.


%\subsection{Наихудший дифференцирующий вектор}
{\bfseries\itshape 8.2.~Наихудший дифференцирующий вектор.} Найдем
наихудший дифференцирующий вектор, соответствующий вектору весов
\eqref{E-w1}. При $v=1/5\mu$ имеем вектор
\begin{equation*}
\mathbf{w}_{1} =
\begin{pmatrix}
5/6 & 1/5\mu & 1/15 & 1/\mu^{2} & 5\mu/18 & \mu/3
\end{pmatrix}^{\mathrm{T}}.
\end{equation*}

Составим взвешенную сумму матриц \eqref{E-A1A2A3A4A5A6}
\begin{equation*}
\mathbf{D}_{1} =
%(5/6)\mathbf{A}_{1}\oplus(1/5\mu)\mathbf{A}_{2}\oplus(1/15)\mathbf{A}_{3}\oplus(1/\mu^{2})\mathbf{A}_{4}\oplus(5\mu/18)\mathbf{A}_{5}\oplus(\mu/3)\mathbf{A}_{6}
\frac{5}{6}\mathbf{A}_{1}\oplus\frac{1}{5\mu}\mathbf{A}_{2}\oplus\frac{1}{15}\mathbf{A}_{3}\oplus\frac{1}{\mu^{2}}\mathbf{A}_{4}\oplus\frac{5\mu}{18}\mathbf{A}_{5}\oplus\frac{\mu}{3}\mathbf{A}_{6}
=
\begin{pmatrix}
5/6 & 2\mu & 4\mu/3
\\
5/2 & 5/6 & 5/2
\\
5/3 & \mu & 5/6
\end{pmatrix}.
\end{equation*}

Обозначим спектральный радиус матрицы $\mathbf{D}_{1}$ через
$\nu_{1}$. Последовательно найдем
\begin{equation*}
\nu_{1} = (5\mu)^{1/2} \approx 3.21, \qquad
\nu_{1}^{-1}\mathbf{D}_{1} =
\begin{pmatrix}
5/6\nu_{1} & 2\nu_{1}/5 & 4\nu_{1}/15
\\
5/2\nu_{1} & 5/6\nu_{1} & 5/2\nu_{1}
\\
5/3\nu_{1} & \nu_{1}/5 & 5/6\nu_{1}
\end{pmatrix}.
\end{equation*}

Вычислим матрицу Клини, столбцы которой порождают решение:
\begin{equation*}
(\nu_{1}^{-1}\mathbf{D}_{1})^{\ast} =
\begin{pmatrix}
1 & 2\nu_{1}/5 & 1
\\
5/2\nu_{1} & 1 & 5/2\nu_{1}
\\
5/3\nu_{1} & 2/3 & 1
\end{pmatrix}.
\end{equation*}
Нетрудно проверить, что первые два столбца полученной матрицы
коллинеарны. Сохраняя один из них, например первый, запишем
множество решений в~виде
\begin{equation*}
\mathbf{x} =
\begin{pmatrix}
1 & 1
\\
5/2\nu_{1} & 5/2\nu_{1}
\\
5/3\nu_{1} & 1
\end{pmatrix}
\mathbf{u}, \qquad \mathbf{u}>\mathbf{0}.
\end{equation*}

Теперь воспользуемся леммой~1, чтобы построить наихудшие решения,
которые соответствуют матрице $\nu_{1}^{-1}\mathbf{D}_{1}$. Для
этого вычислим
\begin{equation*}
\delta_{1} = 2\nu_{1}/5 \approx 1.28, \qquad
\delta_{1}^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}} \oplus
\nu_{1}^{-1}\mathbf{D}_{1} =
\begin{pmatrix}
5/2\nu_{1}  & 2\nu_{1}/5 & 4\nu_{1}/15
\\
5/2\nu_{1} & 5/2\nu_{1} & 5/2\nu_{1}
\\
5/2\nu_{1} & 5/2\nu_{1} & 5/2\nu_{1}
\end{pmatrix}
\end{equation*}
и найдем матрицу Клини
\begin{equation*}
(\delta_{1}^{-1}\mathbf{1}\mathbf{1}^{\mathrm{T}}\oplus
\nu_{1}^{-1}\mathbf{D}_{1})^{\ast} =
\begin{pmatrix}
1  & 2\nu_{1}/5 & 1
\\
5/2\nu_{1} & 1 & 5/2\nu_{1}
\\
5/2\nu_{1} & 1 & 1
\end{pmatrix}.
\end{equation*}
Первые два столбца матрицы коллинеарны. Отбрасывая второй столбец,
запишем
\begin{equation*}
\mathbf{x}_{1} =
\begin{pmatrix}
1 & 1
\\
5/2\nu_{1} & 5/2\nu_{1}
\\
5/2\nu_{1} & 1
\end{pmatrix}
\mathbf{u}, \qquad \mathbf{u}\geq0.
\end{equation*}

После умножения первого столбца на $1/(1+5/\nu_{1})$, а~второго на
$1/(2+5/2\nu_{1})$, получим два наихудших решения, которые
нормированы в~обычном смысле:
\begin{equation*}
\mathbf{x}_{1}^{\prime} \approx
\begin{pmatrix}
0.40 & 0.30 & 0.30
\end{pmatrix}^{\mathrm{T}},
\qquad \mathbf{x}_{1}^{\prime\prime} \approx
\begin{pmatrix}
0.36 & 0.28 & 0.36
\end{pmatrix}^{\mathrm{T}}.
\end{equation*}
Первое решение дает порядок предпочтений $A\succ B\equiv C$, а~второе~--- $A\equiv C\succ B$.% Заметим, что рейтинг школы $A$ всегда не ниже рейтингов остальных школ.


%\subsection{Наилучший дифференцирующий вектор}
{\bfseries\itshape 8.3.~Наилучший дифференцирующий вектор.} Для
определения наилучшего дифференцирующего вектора рейтингов
альтернатив будем использовать найденный вектор весов
\eqref{E-w2}, который максимально дифференцирует критерии.

Сначала выберем первый столбец матрицы \eqref{E-w2} в~качестве
вектора весов
\begin{equation*}
\mathbf{w}_{2} =
\begin{pmatrix}
1 & 3/7\mu^{2} & 1/7\mu & 5\mu/42 & 25/42 & 5/7
\end{pmatrix}^{\mathrm{T}}.
\end{equation*}
Составим взвешенную сумму матриц
\begin{equation*}
\mathbf{D}_{2} =
%\mathbf{A}_{1}\oplus(3/7\mu^{2})\mathbf{A}_{2}\oplus(1/7\mu)\mathbf{A}_{3}\oplus(5\mu/42)\mathbf{A}_{4}\oplus(25/42)\mathbf{A}_{5}\oplus(5/7)\mathbf{A}_{6}
\mathbf{A}_{1}\oplus\frac{3}{7\mu^{2}}\mathbf{A}_{2}\oplus\frac{1}{7\mu}\mathbf{A}_{3}\oplus\frac{5\mu}{42}\mathbf{A}_{4}\oplus\frac{25}{42}\mathbf{A}_{5}\oplus\frac{5}{7}\mathbf{A}_{6}
=
\begin{pmatrix}
1 & 30/7 & 20/7
\\
3 & 1 & 3
\\
2 & 15/7 & 1
\end{pmatrix}.
\end{equation*}
Вычислим спектральный радиус этой суммы
\begin{equation*}
\nu_{2}
%=
%1\oplus(90/7)^{1/2}\oplus(180/7)^{1/3}
= (90/7)^{1/2} \approx 3.59
\end{equation*}
и найдем матрицы
\begin{equation*}
\nu_{2}^{-1}\mathbf{D}_{2} =
\begin{pmatrix}
1/\nu_{2} & 30/7\nu_{2} & 20/7\nu_{2}
\\
3/\nu_{2} & 1/\nu_{2} & 3/\nu_{2}
\\
2/\nu_{2} & 15/7\nu_{2} & 1/\nu_{2}
\end{pmatrix},
\qquad (\nu_{2}^{-1}\mathbf{D}_{2})^{\ast} =
\begin{pmatrix}
1  & \nu_{2}/3 & 1
\\
3/\nu_{2} & 1 & 3/\nu_{2}
\\
2/\nu_{2} & 2/3 & 1
\end{pmatrix}.
\end{equation*}
Учитывая коллинеарность первого и~второго столбцов полученной
матрицы Клини, достаточно рассмотреть решение вида
\begin{equation*}
\mathbf{x} = \mathbf{Q}\mathbf{u}, \qquad \mathbf{Q} =
\begin{pmatrix}
1 & 1
\\
3/\nu_{2} & 3/\nu_{2}
\\
2/\nu_{2} & 1
\end{pmatrix},
\qquad \mathbf{u}
>
\mathbf{0}.
\end{equation*}

Обозначим через $\mathbf{q}_{j}$ столбцы матрицы
$\mathbf{Q}=(q_{ij})$ и~найдем наилучший вектор рейтингов,
используя лемму~2. Чтобы определить индексы $k$ и~$s$, сначала
получим
\begin{equation*}
\mathbf{1}^{\mathrm{T}}\mathbf{q}_{1}\mathbf{q}_{1}^{-}\mathbf{1}
= \nu_{2}/2, \qquad
\mathbf{1}^{\mathrm{T}}\mathbf{q}_{2}\mathbf{q}_{2}^{-}\mathbf{1}
= \nu_{2}/3,
\end{equation*}
из чего вытекает, что $k=1$. Сравнение величин
\begin{equation*}
q_{11}^{-1} = 1, \qquad q_{21}^{-1} = \nu_{2}/3 \approx 1.20,
\qquad q_{31}^{-1} = \nu_{2}/2 \approx 1.78
\end{equation*}
показывает, что $s=3$. Осталось вычислить матрицы
\begin{equation*}
\mathbf{Q}_{31} =
\begin{pmatrix}
0 & 0
\\
0 & 0
\\
2/\nu_{2} & 0
\end{pmatrix},
\qquad \mathbf{Q}(\mathbf{I}\oplus\mathbf{Q}_{31}^{-}\mathbf{Q}) =
\begin{pmatrix}
1 & \nu_{2}/2
\\
3/\nu_{2} & 3/2
\\
2/\nu_{2} & 1
\end{pmatrix}.
\end{equation*}

Столбцы последней матрицы коллинеарны, что приводит к~такому
решению:
\begin{equation*}
\mathbf{x}_{2} =
\begin{pmatrix}
1
\\
3/\nu_{2}
\\
2/\nu_{2}
\end{pmatrix}
u, \qquad u>0.
\end{equation*}

При $u=1/(1+5/\nu_{2})$ имеем наилучший дифференцирующий вектор
рейтингов
\begin{equation*}
\mathbf{x}_{2} \approx
\begin{pmatrix}
0.42 & 0.35 & 0.23
\end{pmatrix}^{\mathrm{T}}.
\end{equation*}

Согласно этому решению, школы располагаются в~порядке $A\succ
B\succ C$.

Аналогичным образом проверяется, что выбор второго столбца матрицы
в \eqref{E-w2} в~качестве вектора весов приводит к~такому же
результату.


%\subsection{Сравнение методов}
%{\bfseries\itshape 8.4.~Сравнение методов.}
В заключение сравним полученные результаты с~решением по методу
анализа иерархий \eqref{E-x}, который устанавливает порядок школ
$A \succ B \succ C$.

Рассмотрим найденные выше решения. После нормирования наихудшие
и~наилучший дифференцирующие векторы рейтингов альтернатив
записываются в~виде
\begin{equation*}
\mathbf{x}_{1}^{\prime} \approx
\begin{pmatrix}
0.40 & 0.30 & 0.30
\end{pmatrix}^{\mathrm{T}},
\quad \mathbf{x}_{1}^{\prime\prime} \approx
\begin{pmatrix}
0.36 & 0.28 & 0.36
\end{pmatrix}^{\mathrm{T}},
\quad \mathbf{x}_{2} \approx
\begin{pmatrix}
0.42 & 0.35 & 0.23
\end{pmatrix}^{\mathrm{T}}\!.
\end{equation*}
Вектор $\mathbf{x}_{2}$ упорядочивает школы так же, как
и~известное решение в~[4], вектор $\mathbf{x}_{1}^{\prime}$ задает
порядок $A\succ B\equiv C$, а~вектор
$\mathbf{x}_{1}^{\prime\prime}$~--- порядок $A \equiv C \succ B$.

В результате применения описанного подхода окончательное решение,
как и~при использовании традиционного метода анализа иерархий,
принимается в~пользу школы $A$, а~наилучшее решение дает рейтинги,
близкие к~полученным обычным методом.

{\bfseries 9.~Заключение.} В~работе представлен минимаксный подход
к решению многокритериальных задач оценки рейтингов альтернатив на
основе их парных сравнений по нескольким критериям. Наиболее
распространенным инструментом решения таких задач является метод
анализа иерархий, который сначала находит рейтинги альтернатив
относительно каждого критерия с~помощью метода главного
собственного вектора, а~затем определяет абсолютный рейтинг
альтернатив путем прямого вычисления взвешенной суммы
нормированных главных собственных векторов. В~отличие от этого
метода используемый подход опирается на аппроксимацию матриц
в~смысле метрики Чебышева в~логарифмической шкале и~находит
абсолютные рейтинги альтернатив одновременно с~аппроксимацией
матриц за счет минимизации взвешенного максимума функций
log-чебышевской ошибки аппроксимации по всем матрицам.

Учитывая, что логарифмическая шкала удобна для манипуляции
с~данными, которые могут принимать значения из широкого диапазона,
ее применение при аппроксимации матриц парных сравнений, элементы
которых взаимно обратны, представ\-ляется вполне оправданным.
Решение задачи путем перехода от многокритериальной целевой
функции к~взвешенному максимуму функций критериев, который обычно
называют чебышевской скаляризацией задачи, является достаточно
обоснованным.

Задача аппроксимации формулируется в~терминах тропической
математики, что позволяет решить исходную задачу оценки рейтингов
альтернатив как задачу тропической оптимизации, используя новые
методы и~результаты в~этой области. Представлено аналитическое
решение задачи в~явном виде в~замкнутой форме, которая удобна как
для дальнейшего анализа, так и~для непосредственных вычислений.

Решением задачи оптимизации может быть единственный набор (вектор)
рейтингов альтернатив или множество различных наборов.
Неединственное решение в~виде нескольких оптимальных наборов
рейтингов альтернатив расширяет возможности принятия решений,
однако может вызвать трудности при выборе подходящих решений на
практике. Для анализа неединственного решения использован метод
с~применением тропической оптимизации для определения таких
векторов рейтингов альтернатив, которые наилучшим и~наихудшим
образом различают альтернативы с~наибольшим и~наименьшим
рейтингами, а~потому хорошо представляют весь диапазон решений.

Полученные результаты расширяют область приложений тропической
математики и~предлагают полезные практические инструменты,
способные дополнить существующие средства решения рассматриваемых
многокритериальных задач.

Дальнейшие исследования могут включать сопоставление и~сравнение
результатов, полученных с~помощью рассмотренного подхода,
с~результатами применения других известных методов, а~также
изучение свойств векторов решений, включая влия\-ние на решение
степени несогласованности матриц. Вызывает интерес разработка
вариантов подхода, при которых сначала решаются задачи минимаксной
аппроксимации матрицы по каждому критерию, а~затем вычисляется
взвешенная (обычная или тропическая) сумма определенных на первом
этапе векторов.\\

Авторы благодарят рецензентов за весьма полезные замечания
и~предложения, которые были учтены при работе над текстом статьи.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\input{05/lit-ra}

%\newpage
\input{05/ref-s}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

%\thispagestyle{empty}
%
\vskip 3mm
%
\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\rm{Вестник~СПбГУ.~Прикладная~математика.~Информатика...~\issueyear.~Т.~15.~Вып.~\issuenum}}}%
% для оформления нижнего колонтитула
\cfoot{} %
%
}
