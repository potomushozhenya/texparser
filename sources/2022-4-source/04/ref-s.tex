
{\normalsize

\vskip 4.5%6
mm
%\newpage

\noindent{\bf The method of successive approximations for constructing a model\\ of dynamic polynomial regression$^{*}$
 }

}

\vskip 3mm

{\small

\noindent{\it А.~G. Golovkina, V.~А. Kozynchenko, I.~S. Klimenko%
%, I.~О. Famylia%$\,^2$%

 }

\vskip 3mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\efootnote{
%%
\vspace{-3mm}\parindent=7mm
%%
\vskip 0.1mm \indent~$^{*}$ This work was financially supported by Saint Petersburg State University (project ID~93024916).\par%
%%
%%\vskip 2.0mm
%%
%%\indent{\copyright} Санкт-Петербургский государственный
%%университет, \issueyear%
%%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize


\noindent%
%$^2$~%
St~Petersburg State University, 7--9, Universitetskaya nab., St~Petersburg,

\noindent%
%\hskip2.45mm%
199034, Russian Federation

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vskip 3%
mm


\noindent \textbf{For citation:}  Golovkina А.~G., Kozynchenko V.~А., Klimenko I.~S. The method of successive approximations for constructing a model of dynamic polynomial regression. {\it Vest\-nik of Saint Pe\-ters\-burg Uni\-ver\-si\-ty. Ap\-plied Mathe\-ma\-tics. Com\-pu\-ter
Scien\-ce. Cont\-rol Pro\-cesses}, %\,
\issueyear, vol.~18, iss.~\issuenum, pp.~\pageref{p4}--\pageref{p4e}. %\\
\doivyp/\enskip%
\!\!\!spbu10.\issueyear.\issuenum04 (In Russian)

\vskip2.2mm

\begin{hyphenrules}{english}

%\pagebreak

{\leftskip=7mm\noindent Predicting the behavior of a certain process in time is an important task that arises in many applied areas, and information about the system that generated this process can either be completely absent or be partially limited. The only available knowledge is the accumulated data on past states and process parameters. Such a task can be successfully solved using machine learning methods, but when it comes to modeling physical experiments or areas where the ability of a model to generalize and interpretability of predictions are important, then the most machine learning methods do not fully satisfy these requirements. The forecas\-ting problem is solved by building a dynamic polynomial regression model, and a method for finding its coefficients is proposed, based on the connection with dynamic systems. Thus, the constructed model corresponds to a deterministic process, potentially described by differential equations, and the relationship between its parameters can be expressed in an analytical form. As an illustration of the applicability of the proposed approach to solving forecasting problems, we consider a synthetic data set generated as a numerical solution of a system of differential equations that describes the Van der Pol oscillator.
\\[1mm]
\textit{Keywords}: polynomial regression, dynamic  systems, Taylor map.\par}

\vskip6mm

\end{hyphenrules}
%\pagebreak

\noindent \textbf{References} }

\vskip 2.0mm

{\footnotesize

1. Jansson~M., Wahlberg~B. A linear regression approach to state-space subspace system identification. \textit{Signal Processing}, 1996, vol.~2, pp.~103--129. https://doi.org/10.1016/0165-1684(96)00048-5
	
	2. Herceg~S., Ujevic~Z., Bolf~A.\:N. Development of soft sensors for isomerization process based on support vector machine regression and dynamic polynomial models.  \textit{Chemical Engineering Research and Design}, 2019, vol.~149, pp.~95--103. 	 https://doi.org/10.1016/j.cherd.2019.06.034
	
	
	3. Dette~H. Optimal designs for identifying the degree of a polynomial regression. \textit{Annals of Statistics}, 1995, vol.~23, no.~4, pp.~1248--1266. https://doi.org/10.1214/aos/1176324708
	
	4. Kim~B., Ko~Ch.-Y., Wong~N. Tensor network subspace identification of polynomial state space models. \textit{Automatica}, 2018, vol.~95, pp.~187--196.
	 https://doi.org/10.1016/j.automatica.2018.05.015
	
	5.	Blondel~M., Ishihata~M., Fujino~A., Ueda~N. Polynomial networks and factorization machines: New insights and efficient training algorithms. \textit{Proceedings of ICML 2016}. New York City, 2016, pp.~850--858.
	
	6. Blondel~M., Niculae~V., Otsuka~T., Ueda~N.  Multi-output polynomial networks and factorization machines. \textit{Proceedings of the 31$^{st}$~International Conference on Neural Information Processing Systems (NIPS'17)}. Long Beach, 2017, pp.~3351--3361.
	
	7. Chen~T., Guestrin~C. XGBoost: A Scalable tree boosting system.  \textit{Proceedings of the 22$^{nd}$~ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'16)}. San Francisco, 2016, pp.~785--794. https://doi.org/10.1145/2939672.2939785
	
	8.	{Hornik~K., Stinchcombe~M., White~H.} Multilayer feedforward networks are universal ap\-pro\-xi\-mators. \textit{Neural Networks}, 1989, vol.~2, pp.~359--366.
	
	9.	{Rao~S., Sethuraman~S., Ramamurthi~V.} A recurrent neural network for nonlinear time series prediction: a comparative study. \textit{IEEE 1992 Workshop on Neural Networks for Signal Processing (NNSP'92)}. Helsingoer, 1992, pp.~531--539.
	
	10.	{Kaheman~K., Kutz~J.\:N., Brunton~S.\:L.} SINDy-PI: a robust algorithm for parallel implicit sparse identification of nonlinear dynamics.  \textit{Proceedings of the Royal Society A.}, 2020, vol.~476, no.~2242, Art. no.~20200279.
	
	11.	{Brunton~S.\:L., Joshua~L.\:P., Kutz~N.} Discovering governing equations from data by sparse identification of nonlinear dynamical systems. \textit{Proceedings of the National Academy of Sciences}, 2016, vol.~113, no.~15, pp.~3932--3937.
	
	12. {Andrianov~S.\:N.} {\it Dynamical modeling of control systems for particle beams}. St~Petersburg, Publishing House of Saint Petersburg State University, 2004, 368 p.
	
	13. {Dragt~A.} Lie methods for nonlinear dynamics with applications to accelerator physics. 2011. Available at: inspirehep.net/record/955313/files/TOC28Nov2011.pdf (accessed: August~10, 2022).
	
	14. {Andrianov~S.} Symbolic computation of approximate symmetries for ordinary differential equa\-tions. \textit{Mathematics and Computers in Simulation}, 2001, vol.~57, no.~3--5, pp.~147--154.
	
	15. {Andrianov~S.} A matrix representation of the Lie transformation. \textit{Proceedings of the Abstracts of the International Congress on Computer Systems and Applied Mathematics}. St Petersburg, 1993, vol.~14, pp.~19--23.
	
	16. {Ivanov~A., Golovkina~A., Iben~U.} Polynomial neural networks and taylor maps for dy\-na\-mi\-cal systems simulation and learning. \textit{ 24$^{th}$~European Conference on Artificial Intelligence, in\-clu\-ding 10$^{th}$~Con\-ference on Prestigious Applications of Artificial Intelligence, PAIS 2020. Proceedings}. IOS Press, 2020, pp.~1230--1237. (Frontiers in Artificial Intelligence and Applications). \\ https://doi.org/10.3233/FAIA200223
	
	17. {Golovkina~A., Kozynchenko~V., Kulabukhova~N.} Reconstruction and identification of dynamical systems based on taylor maps. \textit{Computational Science and its Applications --- 21$^{st}$~International Conference. Proceedings}. Pt VIII. Switzerland, Springer Nature Publ. 2021, pp.~360--369. (Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)). https://doi.org/10.1007/978-3-030-87010-2\_26
	
	18. Golovkina~A.\:G., Kozynchenko~V.\:A., Kulabukhova~N.\:V. Reconstruction of ordinary differential equations from irregularly distributed time-series data.  \textit{Proceedings of the 9$^{th}$~International Conference ``Distributed Computing and Grid Technologies in Science and Education'' (GRID'2021)}. Dubna, Russia, July~5--9, 2021, vol.~3041, pp.~342--347.
	
	19. Golovkina А. G., Ganaeva D. D. Metod reconstructsii nelineinykh dinamicheskih sistem po vremennym ryadam [Method of nonlinear dynamical systems reconstruction based on time series data]. \textit{Control Processes and Stability}, 2022, vol.~9, no.~1, pp.~197--201. (In Russian)
	
	20. Klimenko~I.\:S. Realizatsia metoda matrichnykh otobrajenii dlya reshenia sistemy differentsialnyh uravnenii [Implementation of matrix map method for solving a system of ordinary equations]. \textit{Control Processes and Stability}, 2022, vol.~9, no.~1, pp.~53--57. (In Russian)
	
	21. Cartwright~M.\:L. Van der Pol’s equation for relaxation oscillations.
\textit{	Contributions to the Theory of Nonlinear Oscillations. II. Princeton Ann. Math. Stud.} Princeton, Princeton University Press,  1952, pp.~3--18.
	
	22. Abrevaya~G., Rish I., Aravkin A. Y., Cecchi G.,  Kozloski J., Polosecki P., Zheng P., Daw\-son~S.~P., Rhee J., Cox D. Learning nonlinear brain dynamics: Van der Pol Meets LSTM.	\textit{bioRxiv 330548}. https://doi.org/10.1101/330548
	
	23. LSODA. {\it Ordinary differential equation solver for stiff or non-stiff system (September 2005)}. Available at: http://www.nea.fr/abs/html/uscd1227.html (accessed: August~10, 2022).


\vskip1.5mm Received:  August 11, 2022.

Accepted: September 01, 2022.

\vskip6mm
A\,u\,t\,h\,o\,r\,s' \, i\,n\,f\,o\,r\,m\,a\,t\,i\,o\,n:%
%
\vskip2mm \textit{Anna G. Golovkina} --- PhD in Physics and Mathematics, Associate Professor; a.golovkina@spbu.ru

\vskip2mm \textit{Vladimir A. Kozynchenko} ---  PhD in Physics and Mathematics, Associate Professor; \\ v.kozynchenko@spbu.ru

\vskip2mm \textit{Ilia S. Klimenko} --- Master Student; st062546@student.spbu.ru \par
%
%

}
