

{\footnotesize


\vskip4mm \noindent {\small\textbf{Литература} }

\vskip4mm


1. \textit{Raina R., Battle A., Lee H., Packer B.,  Ng A. Y.}
Selftaught learning: Transfer learning from unlabeled data //
Proc. of the 24th Intern. conference on machine learning. 2007.
June~20--24. P.~759--766.

2. \textit{Hinton G. E., Salakhutdinov R. R.} Reducing the
dimensionality of data with Neural Networks // Science. 2006.
28~July. Vol.~313, N~5786. P.~504--507.

3. \textit{Vincent P., Larochelle H., Lajoie I., Bengio Y.,
Manzagol P.-A.} Stacked denoising autoencoders: Learning useful
representations in a deep network with a local denoising criterion
// The Journal of Machine Learning Research archive. 2010. Vol.~11. P.~3371--3408.
% http://dl.acm.org/citation.cfm?id=1953039

4. \textit{Masci J., Meier U., Ciresan D., Schmidhuber J.} Stacked
convolutional auto-encoders for hierarchical feature extraction //
21st Intern. conference on Artificial Neural Networks. Espoo,
Finland, 2011. June~14--17. Pt~I. P.~52--59.
% http://link.springer.com/chapter/10.1007/978-3-642-21735-7_7

5. \textit{Gehring J., Miao Y., Metze F., Waibel A.} Extracting
deep bottleneck features using stacked auto-encoders // Acoustics,
speech and signal processing (ICASSP). IEEE Intern. conference.
2013.  P.~3377--3381.
% http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6638284&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6638284

6. \textit{Baldi P., Hornik K.} Neural Networks and principal
component analysis: learning from examples without local minima //
Neural Networks. 1989. Vol.~2. P.~53--58.

7. \textit{Caruana R.} Multitask learning // Machine learning.
1997. Vol.~28. P.~41--75.

8. \textit{UFDL}. URL:
http://ufldl.stanford.edu/wiki/index.php/UFLDL\_Tutorial (дата
обращения: 19.04.2016).

9. \textit{Ciresan D. C, Meier U., Schmidhuber J.} Transfer
learning for Latin and Chinese characters with deep Neural
Networks // The 2012 Intern. joint conference on Neural Networks
(IJCNN). 2012. P.~1--6.

10. \textit{CIFAR}. URL:
http://www.cs.toronto.edu/\~{}kriz/cifar.html (дата обращения:
19.04.2016).

11. \textit{Rolfe J. T., LeCun Y.} Discriminative recurrent sparse
auto-encoders // The Intern. conference on learning
representations: Proceedings. 2013.

12. \textit{Masci J., Meier U., Cires D. Вёan, Schmidhuber J.}
Stacked convolutional auto-encoders for hierarchical feature
extraction // Intern. conference artificial Neural Networks and
machine learning. 2011. P.~52--59.
% http://ieeexplore.ieee.org/xpl/abstractAuthors.jsp?tp=&arnumber=6252544&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F6241467%2F6252360%2F06252544.pdf%3Farnumber%3D6252544
% \bibitem{MNIST} \textit{MNIST}. Available at \url{http://yann.lecun.com/exdb/mnist/} (assesed:19.04.2016)
% \bibitem{ED} Simard P. Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis. \textit{IC-DAR. Edinburgh, Scotland}, 2003, Aug, pp. 958-962.

13. \textit{Glorot X., Bengio Y.} Understanding the difficulty of
training deep feedforward neural networks // Intern. conference on
artificial intelligence and statistics. 2010. P.~249--256.

14. \textit{Pascanu R., Mikolov T., Bengio Y.} Understanding the
exploding gradient problem: Tech. Rep. Montreal: Universite de
Montreal, 2012. 11~p.

%\\


\vskip 2mm

{\bf Для цитирования:} Дрокин И.~С. Об одном алгоритме
последовательной инициализации весов глубоких нейронных сетей
и~обучении ансамбля нейронных сетей // Вестник
Санкт-Петербургского университета. Сер.~10. Прикладная математика.
Информатика. Процессы управления. \issueyear. Вып.~\issuenum.
С.~\pageref{p6}--\pageref{p6e}.
\doivyp/spbu10.\issueyear.\issuenum06





}
