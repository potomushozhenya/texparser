


\zagol{517.977.8}{О.~Л.~Петросян}{РЕШЕНИЕ С~ИНФОРМАЦИОННОЙ ДИСКРИМИНАЦИЕЙ \\
В КООПЕРАТИВНЫХ ДИФФЕРЕНЦИАЛЬНЫХ ИГРАХ \\
С БЕСКОНЕЧНОЙ ПРОДОЛЖИТЕЛЬНОСТЬЮ$^*$}{



\vspace{-3mm}\parindent=7mm



%{\copyright} А.~В.~Буре, 2014

\textit{Петросян Ованес Леонович}  --- аспирант;
petrosian.ovanes@yandex.ru





\vskip 3mm

\emph{Petrosian Ovanes Leonovich}  --- postgraduate student;
petrosian.ovanes@yandex.ru



$^*$ Работа выполнена при финансовой поддержке
Санкт-Петербургского государственного университета (НИР
№~9.38.205.2014).

{\copyright} Санкт-Петербургский государственный университет, 2016

}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
%\fancyfoot[LO]{{\footnotesize\emph{\doivyp02 } }\hfill\thepage}%
\fancyfoot[LO]{{\footnotesize\emph{\doivyp/spbu10.\issueyear.\issuenum02}}\hfill\thepage}%
%\fancyfoot[RE]{\thepage\hfill{\footnotesize\emph{\doivyp02 } } }%
\fancyfoot[RE]{\thepage\hfill{\footnotesize\emph{\doivyp/spbu10.\issueyear.\issuenum02}}}%
%\fancyfoot[LO]{\hfill{\fontsize{10.5}{10.5}\selectfont \thepage}}%
%\fancyfoot[RE]{{\fontsize{10.5}{10.5}\selectfont \thepage}\hfill}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\footnotesize

\noindentСанкт-Петербургский государственный университет,
Российская Федерация, \\ 199034, Санкт-Петербург, Университетская
наб., 7--9


\vskip3.5mm


\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}


\item Предложен новый подход к~определению решения дифференциальных игр
с бесконеч-\linebreakной продолжительностью для случая, когда
игроки не~имеют точную информацию об игре (уравнения движения,
функция выигрыша) на временном интервале, на~котором задана игра.
В~любой момент времени игроки принимают решение, используя
инфор\-мацию на~временном интервале с~конечной продолжительностью.
Информация об игре обновляется в~определенные моменты времени
и~неизвестна заранее. Согласно описанно\-му подходу решение в~игре
определяется как комбинация решений в~усеченных играх. Рассмотрен
пример игры управления природными ресурсами, в~котором приведено
срав\-нение кооперативной траектории, дележей и~процедуры
распределения дележа в~исходной игре с~бесконечной
продолжительностью и~в~игре с~представленным подходом. Библиогр.
15 назв. Ил. 3.

{\it Ключевые слова}: дифференциальные игры, решение
с~информационной дискриминацией, процедура распределения дележа,
динамическая устойчивость, сильная динамическая устойчивость.

\end{list}

}

\vskip4mm

\begin{list}{}{\leftmargin=7mm \rightmargin=7mm \listparindent=5mm}

\noindent{\it O. L. Petrosian}

\vskip3mm \noindent{\bf LOOKING FORWARD APPROACH IN COOPERATIVE\\
DIFFERENTIAL GAMES WITH INFINITE-HORIZON}

\vskip3mm


{\footnotesize


\noindent St.~Petersburg State University, 7--9, Universitetskaya
nab.,\\ St.~Petersburg, 199034, Russian Federation

\vskip3mm


\item A novel approach to definition and computation of a solution of a differential with an infinite-horizon game is presented for the case when players do not have certain information about the game structure on the infinite time interval. At any instant of time players have certain information about motion equations and payoff functions on a subinterval with fixed duration. The information about the game structure updates at fixed instants of time and is completely unknown in advance. A new solution is defined as a recursive combination of sets of imputations in the truncated subgames that are analyzed by the Looking Forward Approach. An example of a resource extraction game illustrates a comparison of cooperative trajectory, imputation, imputation distribution procedure in the original game with infinite-horizon and in the corresponding game with Looking Forward Approach. Refs. 15. Figs 3.

\textit{Keywords}: differential game, looking forward approach,
imputation distribution procedure, time-consistency, strong
time-consistency.

}

\end{list}


\vskip3mm

{\bf 1. Введение.} Теория кооперативных дифференциальных игр
изучает вопросы построения оптимальных решений в~процессах
со~многими участниками. Оптимальное решение включает в~себя
кооперативную траекторию, стратегии, ее порождающие, выигрыш вдоль
кооперативной траектории, распределение выигрыша между игроками
и~анализ динамической устойчивости выбранного решения. Проблема
динамической неустойчивости вектора Шeпли для переговоров была
озвучена в~работе~[1]. Л.~А.~Петросян впервые математически
сформулировал понятие динамической устойчивости [2] и~сильной
динамической устойчивости [3] решения в~кооперативных
дифференциальных играх. С~целью предотвращения нарушения
устойчивости позднее в~[4] была предложена схема выплат,
получившая название процедуры распределения дележа (ПРД), которая
обеспечивает реализацию решения.

В данной работе внимание уделяется специальному классу
дифференциальных игр с~бесконечной продолжительностью, когда
игроки не~имеют полной информации об игре на~всем временном
интервале, на~котором определена игра. В~каждый момент времени
игрокам доступна информация только на~фиксированном временном
интервале. В~определенные моменты времени информация обновляется.
Для того чтобы смоделировать поведение игроков в~такой игре,
предлагается использовать специальный подход, который будем
называть подходом решения с~информационной дискриминацией. Одна
из~вариаций подхода описана в~[5,~6].

Рассмотрим кооперативную дифференциальную игру, заданную
на~временном интервале $[t_0, +\infty)$. Предположим, что
информация об игре обновляется в~моменты времени $t=t_0 + j\Delta
t$,~ $j=0, \ldots, +\infty$, здесь $0 < \Delta t < +\infty$ задает
время между моментами обновления информации. В~эти моменты игроки
получают точную информацию об уравнениях движений и~функции
выигрыша на~временном интервале $[t_0 + j\Delta t, t_0 + j\Delta t
+ \overline{T}]$, где $\Delta t < \overline{T} < +\infty$ задает
временной горизонт, на~котором игрокам известна информация об
игре. На~интервалах $[t_0 + j\Delta t, t_0 + j\Delta t +
\overline{T}]$, $j = 0, \ldots, +\infty$, строится игра. С~помощью
уравнений Гамильтона---Якоби---Беллмана~[7] можно установить
кооперативное поведение (кооперативные стратегии, траекторию)
в~каждой\linebreak подобной игре. Вопрос определения оптимального
в~некотором смысле информа\-ционного горизонта $\overline{T}$ для
подхода с~информационной дискриминацией рассматривался в~работе
[8].

Характеристическую функцию будем считать также наилучшим ответом
коалиции на~стратегии, входящие в~ситуацию равновесия по~Нэшу
остальных игроков [9]. Такой подход к~получению характеристической
функции требует определения ситуации равновесия по~Нэшу
в~дифференциальных играх, вопрос построения равновесия по~Нэшу
детально описан в~[9]. Множество дележей или решение в~игре
находится для каждого момента времени $t=t_0 + j\Delta t$. Для
каждого дележа из~выбранного решения определяется ПРД, введенная
Л.~А.~Петросяном в~[4]. Некоторые последние публикации на~эту тему
[9--11]. Для того чтобы определить решение для всей игры,
необходимо скомбинировать решения и~соответствующие ПРД
на~временных интервалах $[t_0 + j\Delta t , t_0 + j\Delta t +
\overline{T}]$. Также в~работе проведено исследование свойств
динамической устойчивости и~сильной динамической устойчивости,
впервые рассмотренных Л.~А.~Петросяном в~[2,~12].

Для того чтобы продемонстрировать предлагаемый подход, была
изучена игра добычи ограниченных ресурсов с~бесконечной
продолжительностью. Исходная игра описана в~[13]. В~настоящей
работе представлено аналитическое и~численное решение игры,
которое сравнивается с~решением в~исходной игре. В~качестве дележа
в игре используется пропорциональное решение.

Статья имеет следующую структуру. В~п. 2 описывается исходная
игра, в~п. 3 --- усеченная игра, с~помощью которой можно
моделировать поведение игроков с~предложенным подходом. В~п. 4
дается решение усеченных игр. В~п. 5 характеризуется предлагаемый
подход для определения решения во~всей игре. В~п. 6 подход
применяется к~дифференциальной игре добычи ограниченного ресурса
с~бесконечной продолжительностью. В~п. 7 приведены выводы.

{\bf 2. Модель исходной игры.} Рассмотрим дифференциальную игру
$n$-лиц с~бесконечной продолжительностью $\Gamma(x_{0}, t_{0})$,
начинающуюся в~позиции $x_{0} \in R^{m}$ в~момент времени $t_0$.
Уравнения движения для этой игры имеют следующий вид:
\begin{equation}\label{1}
\dot{x}=g(t, x, u), \qquad x(t_0) = x_0,
\end{equation}
где $x \in R^{m}$; $u = (u_{1}, \ldots, u_{n})$. Множество игроков
обозначим через $N=\{1,2,\ldots,n\}$. Игрок $i=1, \ldots, n$
выбирает стратегии $u_{i}$, как функции текущего состояния
и~времени со~значениями в~множестве $U_{i} \subset CompR^{k}$
(подробней см.~в~[14]).

Функция выигрыша игрока $i$
\begin{equation*}\label{2}
K_{i}(x_0, t_0; u) = \int\limits_{t_{0}}^{+ \infty}h_{i}(x(\tau),
u(\tau)) e^{-r (\tau - t_{0})} d\tau,
\end{equation*}
здесь $x(\tau)$ --- траектория (решение) при заданных уравнениях
движения (\ref{1}) и~стратегиях $u$ на~бесконечном временном
интервале.

Предлагаемый подход предполагает использование игроками усеченной
информации об игре. В~моменты времени $t \in [t_0 + j \Delta t,
t_0 + (j+1) \Delta t]$ игроки обладают информацией об уравнениях
движения и~функции выигрыша на~временном интервале $[t_0 + j
\Delta t, t_0 + j \Delta t + \overline{T}]$. В~моменты времени $t
= t_0 + j\Delta t$ информация об игре обновляется и~игроки
переопределяют свое поведение. Подобные задачи часто появляются
в~реальной жизни, так как информация о~конфликтном процессе
на~длительном временном интервале не~всегда определена
и~необходимо принимать решения в~реальном времени, подстраиваясь
под изменения.


{\bf 3. Понятие усеченной подыгры.} В~течение первого временного
интервала $[t_0, t_0 + \Delta t]$ игроки владеют информацией об
игре на~временном интервале $[t_0, t_0 + \overline{T}]$. В~момент
времени $t = t_0 + \Delta t$ информация обновляется, и~в~течение
второго временного интервала $[t_0 + \Delta t, t_0 + 2\Delta t]$
игроки имеют информацию об игре на~$[t_0 + \Delta t, t_0 + \Delta
t + \overline{T}]$. Для того чтобы учесть это в~модели, введем
определение усеченной игры. Примем следующее обозначение:
$x_{j,0}=x(t_0 + j\Delta t)$.

{\bf Определение 1.} {\it Пусть $j = 0, \ldots, +\infty$.
Усеченная игра $\bar{\Gamma}_j(x_{j,0}, t_0 + j \Delta t, t_0 + j
\Delta t~+~\overline{T})$ определена на~временном интервале $[t_0
+ j \Delta t, t_0 + j \Delta t + \overline{T}]$ следую-\linebreak
щим образом. На временном интервале $[t_0 + j \Delta t, t_0 + j
\Delta t + \overline{T}]$ уравнения движения и~функция выигрыша
в~усеченной игре и~исходной игре $\Gamma(x_{0}, t_0)$ совпадают$:$
\begin{equation*}\label{5}
\dot{x}=g(t, x, u), \qquad x(t_0 + j\Delta t) = x_{j,0},
\end{equation*}
\begin{equation}\label{6}
K^{j}_{i}(x_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}; u) = \int\limits_{t_0 + j \Delta t}^{t_0 + j \Delta
t + \overline{T}}h_{i}(x(\tau), u(\tau)) e^{-r(\tau - t_0)} d\tau,
\end{equation}
где $e^{-r(\tau - t_0)}$ --- функция, дисконтирующая выигрыш
начиная с момента времени $t_0$ в~игре $\Gamma(x_{0}, t_0)$.}

Предполагается, что выигрыш в~игре (в любой усеченной подыгре)
рассчиты\-вается от момента времени $t_0$; в~формуле (2)
дисконтирование выигрыша начи\-нает\-ся с~момента времени $t_0$.


%\begin{figure}[h!]
%\center
%\includegraphics[width=0.8\linewidth]{2.eps}
%\caption{}
%\end{figure}
%
%%\pagebreak


{\bf 4. Решение кооперативной усеченной подыгры.} Рассмотрим
усеченную кооперативную подыгру $\bar{\Gamma}^{c}_j(x_{j,0}, t_0 +
j \Delta t, t_0 + j \Delta t + \overline{T})$ на~временном
интервале $[t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}]$
с~начальным условием $x(t_0 + j\Delta t)=x_{j,0}$. В~кооперативной
постановке игрокам необходимо максимизировать суммарный выигрыш
\begin{equation}\label{10}
\sum\limits_{i \in N}^{} K^{j}_{i}(x_{j,0}, t_0 + j\Delta t, t_0 +
j\Delta t + \overline{T}; u^{j}) = \sum\limits_{i \in N}^{}
\int\limits_{t_0 + j \Delta t}^{t_0 + j \Delta t +
\overline{T}}h_{i}(x(\tau), u(\tau)) e^{-r(\tau - t_0)} d\tau
\end{equation}
при условии
\begin{equation}\label{11}
\dot{x}=g(t, x, u), \qquad x(t_0 + j\Delta t) = x_{j,0}.
\end{equation}

Для решения подобной задачи может быть использована система
уравнений Гамильтона---Якоби---Беллмана [15, теорема A.1]:



{\bf Теорема 1.} {\it Пусть существует непрерывно дифференцируемая
функция $W^{(j \Delta t)}(t, x): [t_0 + j \Delta t, t_0 + j \Delta
t + \overline{T}] \times R^{m} \rightarrow R$, удовлетворяющая
системе уравнений в~частных производных
\begin{equation}\label{12}
-W_{t}^{(j \Delta t)}(t, x)= \max\limits_{u}^{} \left\{
\sum\limits_{i = 1}^{n} h_{i}(t, x, u) e^{-r(t - t_0)} + W_{x}^{(j
\Delta t)}(t, x) g(t, x, u) \right\}
\end{equation}
при условии
$$
W^{(j \Delta t)}(t_0 + j \Delta t + \overline{T}, x)=0.
$$

Предположим, что максимум в~$(5)$ достигается при $u=u^{* j}(t)$.
Тогда $u=u^{* j}(t)$ является оптимальным в~задаче управления,
определяемой $(3)$, $(4)$.}

Траекторию, соответствующую $u=u^{* j}(t)$, будем называть
кооперативной и~обозначать через $x^{*}_{j}(t)$.

В соответствии с~рассматриваемым подходом в~каждый момент времени
игрокам доступна ограниченная информация об игре $\Gamma(x_0,
t_0)$. Этой информации недостаточно, чтобы определить
кооперативное поведение для игроков во~всей игре $\Gamma(x_0,
t_0)$. Вместо кооперативной траектории в~игре $\Gamma(x_0, t_0)$
будем строить условно кооперативную траекторию $\{ \hat{x}^{*}(t)
\}^{+\infty}_{t = t_0}$
\begin{equation*}\label{16}
\{ \hat{x}^{*}(t) \}^{+\infty}_{t = t_0} =
\begin{cases}
   x^{*}_{0}(t), \quad t \in [t_0, t_0 + \Delta t], \\
   x^{*}_{1}(t), \quad t \in (t_0 + \Delta t, t_0 + 2\Delta t], \\
   \cdots \\
   x^{*}_{j}(t), \quad t \in (t_0 + j\Delta t, t_0 + (j+1)\Delta t], \\
   \cdots
 \end{cases}
\end{equation*}
На временном интервале $[t_0 , t_0 + \Delta t]$ траектория
$x^{*}_{0}(t)$ является кооперативной в~усеченной подыгре
$\bar{\Gamma}^{c}_0(x_{0}, t_0, t_0 + \overline{T})$. В~момент
времени $t = t_0 + \Delta t$ в~позиции $x^{*}_{0}(t_0 + \Delta t)$
информация об игре обновляется. На~временном интервале $[t_0 +
\Delta t, t_0 + 2\Delta t]$ игроки двигаются вдоль кооперативной
траектории $x^{*}_{1}(t)$ в~усеченной подыгре
$\bar{\Gamma}^c_1(x^{*}_{0}(t_0 + \Delta t), t_0 + \Delta t, t_0 +
\Delta t + \overline{T})$. В~момент времени $t = t_0 + j \Delta t$
в позиции $x^{*}_{j-1}(t_0 + j \Delta t)$ информация об игре
обновляется. Условно кооперативная траектория $\hat{x}^*(t)$
на~временном интервале $[t_0 + j \Delta t, t_0 + (j+1)\Delta t]$
определена как комбинация частей кооперативных траекторий
$x^{*}_{j}(t)$ в~усеченных подыграх
$\bar{\Gamma}^c_j(x^{*}_{j-1}(t_0 + j \Delta t), t_0 + j \Delta t,
t_0 + j \Delta t + T)$. Введем следующие обозначения:
$x^*_{j,0}=x^*_{j-1}(t_0 + j\Delta t)=x^*_{j}(t_0 + j\Delta t)$.
Тогда усеченная подыгра может быть записана в~таком виде:
$\bar{\Gamma}^c_j(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t
+ \overline{T})$.

%%\pagebreak
%
%\begin{figure}[h!]
%\center
%\includegraphics[width=0.8\linewidth]{3.eps}
%\caption{}
%\end{figure}

Для каждой коалиции $S \subset N$ и~усеченной подыгры с~номером $j=0,\ldots,+\infty$ найдем значения характеристической функции так, как это сделано в~[14]: \\
\begin{equation*}\label{}
V_j(S, x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T})=
\end{equation*}
\begin{equation}\label{17}
=\left\{
\begin{array}{ll}
   0, & S=\{\emptyset\},\\[5pt]
   \max\limits_{\begin{array}{c}\scriptstyle u_i,\; i \in S \\\scriptstyle u_j =u_j^{NE},\; \scriptstyle j \in N\setminus S\end{array}}  \sum\limits_{i \in S} K^{j}_{i}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}; u^{*}_{j,S}, u^{NE}_{j,N \setminus S}),&S \subset N,\\
   \max\limits_{u} \sum\limits_{i=1}^n K^{j}_{i}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}; u^{*}_j),&S=N.
\end{array}\right.
\end{equation}
В этом подходе предполагается, что фиксируется некоторая ситуация
равновесия по~Нэшу $u^{NE}_{j} = (u^{NE}_{1,j}, \ldots,
u^{NE}_{n,j})$, игроки $k$, не~входящие в~коалицию $k \notin S$,
используют равновесные по~Нэшу стратегии $\{u^{NE}_{k,j}\}$, тогда
как игроки из~коалиции $S$ мак\-си\-ми\-зи\-руют свой суммарный
выигрыш.

Любой дележ $\xi^{j}(x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t
+ \overline{T})$ в~кооперативной усеченной подыгре
$\bar{\Gamma}^{c}_j(x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t
+ \overline{T})$ должен удовлетворять следующей системе
неравенств:
\begin{eqnarray*}\label{18}
\xi^{j}_{i}(x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}) \geq V_j(\{i\}, x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}), \quad i\in N, \nonumber \\
\sum\limits_{i\in N} \xi^{j}_{i}(x^*_{j,0}, t_0 + j \Delta t, t_0
+ j \Delta t + \overline{T}) = V_j(N, x^*_{j,0}, t_0 + j \Delta t,
t_0 + j \Delta t + \overline{T}).
\end{eqnarray*}

Обозначим множество всевозможных дележей для усеченной подыгры
%\linebreak
$\bar{\Gamma}^{c}_j(x^{*}_{j,0}, t_0 + j \Delta t, t_0
+ j \Delta t + \overline{T})$ через $E_{j}(x^*_{j,0}, t_0 + j
\Delta t, t_0 + j \Delta t + \overline{T})$.

Предположим, что для каждой усеченной подыгры выбрано непустое
решение
\begin{equation*}\label{}
W_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}) \subset E_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j
\Delta t + \overline{T}).
\end{equation*}
Это может быть C-ядро, НМ-решение, N-ядро или вектор Шепли.

Логично предположить, что распределение суммарного выигрыша между
игроками в~игре $\Gamma(x_{0}, t_0)$ вдоль условно кооперативной
траектории $\{ \hat{x}^{*}(t) \}^{+\infty}_{t = t_0}$ найдено как
комбинация дележей на~временных интервалах $[t_0 + j\Delta t, t_0
+ (j+1)\Delta t]$,\linebreak $j=0, \ldots, +\infty$. Эту
конструкцию будем называть новой концепцией решения.

Комбинация множеств $W_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j
\Delta t + \overline{T})$ не~позволяет получить решение в~игре
$\Gamma(x_{0}, t_0)$ напрямую. Для каждого $j=0, \ldots, +\infty$
решение в~усеченной подыгре $\bar{\Gamma}^{c}_j(x^{*}_{j,0}, t_0 +
j \Delta t, t_0 + j \Delta t + \overline{T})$ построено для
временного интервала $[t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}]$. Использование такого решения на~временном
интервале $[t_0 + j\Delta t, t_0 + (j+1)\Delta t]$ не~имеет
смысла, так как информация об игре обновляется каждый $\Delta t$
временной интервал. Необходимая часть решения может быть получена
с помощью процедуры распределения дележа для каждой усеченной
подыгры. ПРД также обеспечивает свойство динамической устойчивости
новой концепции решения и~возможность определять решения внутри
временного интервала $[t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}]$.


{\bf 5. Концепция решения.} Для того чтобы построить предложенное
решение в~игре $\Gamma(x_{0}, t_0)$, необходимо установить ПРД для
всех усеченных подыгр $\bar{\Gamma}^{c}_j(x^{*}_{j,0}, t_0 + j
\Delta t, t_0 + j \Delta t + \overline{T})$,~ $j=0,
\ldots,+\infty$.

Обозначим семейство подыгр для $\bar{\Gamma}^{c}_j(x^{*}_{j,0},
t_0 + j \Delta t, t_0 + j \Delta t + \overline{T})$ вдоль
коопе-\linebreak ративной траектории $x^{*}_{j}(t)$ через
$\bar{\Gamma}^{c}_j(x^{*}_{j}(t), t, t_0~+~j \Delta t~+ \
\overline{T})$, где $t \in (t_0~+~j \Delta t, t_0~+~j \Delta t~+
\overline{T}]$~--- начальный момент времени подыгры.

Характеристическая функция вдоль $x^{*}_{j}(t)$ в~семействе подыгр
$\bar{\Gamma}^{c}_j(x^{*}_{j}(t), t, t_0  +  j \Delta
t~+~\overline{T})$~определена так же, как и~в~(6). Обозначим через
$E_{j}(x^{*}_{j}(t), t, t_0 + j \Delta t + \overline{T})$
множество дележей в~подыгре $\bar{\Gamma}^{c}_j(x^{*}_{j}(t), t,
t_0 + j \Delta t + \overline{T})$ вдоль $x^{*}_{j}(t)$.

Предположим, что в~каждой усеченной подыгре
$\bar{\Gamma}^{c}_j(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta
t + \overline{T})$ решение $W_{j}(x^{*}_{j,0}, t_0 + j \Delta t,
t_0 + j \Delta t + \overline{T}) \neq \emptyset$ вдоль
кооперативной траектории $x^{*}_{j}(t)$ выбрано.

Примем, что для любой усеченной подыгры
$\bar{\Gamma}^{c}_j(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta
t + \overline{T})$ в~начальной позиции $x^{*}_{j,0}$ игроки
договорились о~выборе дележа:
\begin{equation*}\label{21}
\xi^{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}) \in W_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j
\Delta t + \overline{T})
\end{equation*}
и соответствующего ПРД
\begin{equation*}\label{22}
B_{j}(t, x^{*}_{j})=[B^{j}_{1}(t, x^{*}_{j}) \ldots B^{j}_{n}(t,
x^{*}_{j})], \quad t \in (t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}],
\end{equation*}
что гарантирует динамическую устойчивость выбранного дележа [2]:
\begin{equation*}\label{23}
\xi^{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}) = \int\limits_{t_0 + j \Delta t}^{t_0 + j \Delta t +
\overline{T}}B_{j}(t, x^{*}_{j}) e^{-r(t - t_0)} dt,
\end{equation*}
где $e^{-r(t - t_0)}$ --- функция, обеспечивающая дисконтирование
выигрыша начиная с~момента времени $t_0$ в~игре $\Gamma(x_{0},
t_0)$. ПРД $B_{j}(t, x^{*}_{j})$ может быть получена путем
дифференцирования дележа $\xi^{j}_{t}(x^{*}_{j}, t, t_0 + j \Delta
t + \overline{T})$ [15, лемма 4.1]:


{\bf Теорема 2.} {\it Если функция $\xi^{j}(x^{*}_{j}, t, t_0 + j
\Delta t + \overline{T})$ является непрерывно дифференцируемой
по~$t$ и~$x^{*}_{j}$, тогда}
\begin{equation*}\label{24}
B_{j}(t, x^{*}_{j})= - \left[\xi^{j}_{t}(x^{*}_{j}, t, t_0 + j
\Delta t + \overline{T}) \right] -
\left[\xi^{j}_{x^{*}_{j}}(x^{*}_{j}, t, T)\right] g_{j}\left[t,
x^{*}_{j}, \psi_{1}^{*j}(\tau,x) \ldots \psi_{n}^{*
j}(\tau,x)\right].
\end{equation*}

Новая концепция решения в~игре $\Gamma(x_{0}, t_0)$ состоит
из~комбинации решений \linebreak
 $W_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T})$ (соответствующих ПРД) в~усеченных подыграх $\bar{\Gamma}_{c}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T})$, $j=0, \ldots, +\infty$. Пусть для каждого дележа $\xi_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}) \in W_{j}(x^{*}_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t + \overline{T})$ существует ПРД $B_{j}(t, x^{*}_{j})$. Определим условное ПРД для всей игры $\Gamma(x_{0}, t_0)$ следующим образом:
\begin{equation}\label{28}
\hat{B}(t,\hat{x}^*) = B_{j}(t, x^{*}_{j}), \qquad t \in [t_0 +
j\Delta t, t_0 + (j+1)\Delta t], \quad j=0,\ldots,+\infty.
\end{equation}

%%\pagebreak
%
%\begin{figure}[h!]
%\center
%\includegraphics[width=0.8\linewidth]{4.eps}
%\caption{}
%\end{figure}

С помощью условного ПРД $\hat{B}(t, \hat{x}^*)$ определим вектор
\begin{equation*}\label{}
\hat{\xi}^j(x_{j,0}, t_0 + j \Delta t) = \int\limits_{t_0 + j
\Delta t}^{+\infty} \hat{B}(\tau, \hat{x}^*(\tau)) e^{-r(\tau -
t_0)} d\tau=
\end{equation*}
\begin{equation}\label{29}
= \sum\limits_{m=j}^{+\infty} \left[ \int\limits_{m\Delta
t}^{(m+1)\Delta t} B_{m}(\tau, x^{*}_{m}(\tau)) e^{-r(\tau - t_0)}
d\tau \right],
\end{equation}
в котором $j=0, \ldots, +\infty$. Через $\hat{W}_j(x^*_{j,0}, t_0
+ j \Delta t)$ обозначим множество векторов \linebreak
 $\hat{\xi}^j(x^*_{j,0}, t_0 + j \Delta t)$, построенных с~помощью (7), (8).
В соответствии с~новой концепцией решение в~игре $\Gamma(x_{0},
t_0)$ определено, как $\hat{W}=(\hat{W}_j(x^*_{j,0}, t_0 + j
\Delta t))_{j=0}^{+\infty}$. Решение $\hat{W}$ является
динамически устойчивым. Оказывается, что $\hat{W}$ обладает
и~другим свойством.

{\bf Определение 2.} {\it Решение $W=(W_j(x^*_{j,0}, t_0 + j
\Delta t))_{j=0}^{+\infty}$ называется сильно\linebreak $\Delta
t$-ди\-на\-ми\-чес\-ки устойчивым, если для каждого $j=0, \ldots,
+\infty$ и каждого $\xi \in W$ соответствующее ПРД $B(t, x^*)$
удовлетворяет условию
\begin{equation*}\label{30}
\int\limits_{t_0}^{t_0 + j \Delta t}B(\tau, x^*(\tau)) e^{-r(\tau
- t_0)}d\tau \oplus W_j(x^{*}_{j,0},t_0 + j \Delta t) \subset
W_0(x_0, t_0),
\end{equation*}
в котором $a \oplus A = \{ a + a': a' \in A\}$.}

{\bf Теорема 3.} {\it Решение $\hat{W}$ является сильно $\Delta
t$-динамически устойчивым в~игре $\Gamma(x_{0}, t_0)$. }

{Д о~к~а з а~т е л ь с~т в~о.} Пусть $0\le j\le +\infty$ и~дележ
$\hat{\xi}^0(x_{0}, t_0)\in \hat{W}_0(x_0,t_0)$ порождает ПРД
$\hat{B}(t, \hat{x}^*)$. Тогда для любого $0\le k < j$ существует
$\xi^k(x_{k,0}^*, t_0 + k\Delta t)\in W_k(x_{k,0}^*, t_0 + k\Delta
t)$ с~ПРД $B_k(t, x_k^*)$ таким, что
$$
\hat{B}(t, \hat{x}^*) = B_k(t, x^*_k), ~~ t\in [k\Delta t,
(k+1)\Delta t), ~~ 0\le k \le j-1.
$$
Следовательно,
$$
\int\limits_{t_0}^{t_0 + j \Delta t}\hat{B}(\tau, \hat{x}^*(\tau))
e^{-r(\tau - t_0)}d\tau = \sum_{k=0}^{j-1} \int_{t_0 + k\Delta
t}^{t_0 + (k+1)\Delta t} B_k(t, x^*_k(t)) e^{-r(\tau - t_0)}dt.
$$

Предположим, что $\xi'' \in W_j(x^{*}_{j,0}, t_0 + j \Delta t)$.
Тогда для любого $j\le k \le l-1$ су\-щест\-вует $\xi^k(x_{k,0}^*,
t_0 + k\Delta t)\in W_k(x_{k,0}^*, t_0 + k\Delta t)$ с~ПРД $B_k(t,
x_k^*)$ такое, что $\hat{B}(t, \hat{x}^*) = B_k(t, x^*_k)$ для
$t\in [t_0 + k\Delta t, t_0 + (k+1)\Delta t)$ и~$$ \xi'' =
\sum\limits_{m=j}^{l-1} \left[ \int\limits_{t_0 + m\Delta t}^{t_0
+ (m+1)\Delta t} B_{m}(\tau, x^{*}_{m}(\tau)) e^{-r(\tau - t_0)}
d\tau \right].
$$

Таким образом,
$$
\int\limits_{t_0}^{t_0 + j \Delta t}\hat{B}(\tau, \hat{x}^*(\tau))
e^{-r(\tau - t_0)} d\tau + \xi'' =$$
$$= \sum\limits_{m=0}^{l-1}
\left[ \int\limits_{t_0 + m\Delta t}^{t_0 + (m+1)\Delta t}
B_{m}(\tau, x^{*}_{m}(\tau)) e^{-r(\tau - t_0)} d\tau \right] \in
\hat{W}_0(x_0, t_0).
$$
Теорема доказана.



{\bf 6. Решения с~информационной дискриминацией в~кооперативной
игре добычи ограниченного ресурса с~бесконечной
продолжительностью.} Рассмотрим бесконечную игру добычи
ограниченного ресурса. Решение игры в~классическом виде
представлено в~[13]. Применим предлагаемый нами подход для этой
игры.\linebreak\newpage\noindent Пусть в~игре участвуют два
игрока. Уравнения движения, описывающие изменение запаса ресурса
$x(t) \in X \subset R$, имеют следующий вид:
\begin{equation*}\label{37}
\dot{x}=a\sqrt{x(t)}-bx(t)-u_{1}-u_{2}, \quad x(t_0)=x_{0},
\end{equation*}
где $u_{i}$ --- уровень добычи игрока, $i=1,2$.

Запишем функцию выигрыша игрока $i$:
\begin{equation*}\label{39}
K_{i}(x_0, t_0; u) = \int\limits_{t_0}^{+\infty}h_{i}(x(\tau),
u(\tau)) e^{-r(\tau - t_0)} d\tau, \qquad i=1, 2,
\end{equation*}
здесь
\begin{equation*}\label{40}
h_{i}(x(\tau), u(\tau)) =
\sqrt{u_{i}(\tau)}-\frac{c_{i}}{\sqrt{x(\tau)}}u_{i}(\tau), \qquad
i=1, 2,
\end{equation*}
где $r$ --- параметр дисконтирования (дисконтирование выигрыша
происходит начиная с~момента времени $t_0$); $c_1, c_2$ ---
константы $c_{1} \neq c_{2}$.

Исходная игра $\Gamma(x_0,t_0)$ определена на~временном интервале
$[t_0, +\infty]$. Предположим, что для любого $t \in [t_0 + j
\Delta t, t_0 + (j+1) \Delta t]$, $j=0 , \ldots, +\infty$, игроки
имеют усеченную информацию об игре. Она включает в~себя информацию
об уравнениях движения и~функциях выигрыша на~временном интервале
$[t_0 + j \Delta t, t_0 + j \Delta t + \overline{T}]$. Смоделируем
это с~помощью усеченной подыгры $\bar{\Gamma}_j(x_{j,0}, t_0 + j
\Delta t, t_0 + j \Delta t + \overline{T})$. Уравнения движения
и~начальные данные имеют такой вид:
\begin{equation}\label{41}
\dot{x}=a_{j}\sqrt{x(t)}-b_{j}x(t)-u_{1}-u_{2}, \quad x(t_0 +
j\Delta t) = x_{j,0},
\end{equation}
функция выигрыша игрока $i$:
\begin{equation*}\label{43}
K^{j}_{i}(x_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T}; u) = \int\limits_{t_0 + j \Delta t}^{t_0 + j \Delta
t + \overline{T}}h_{i}(x(\tau), u(\tau)) e^{-r(\tau - t_0)} d\tau.
\end{equation*}

Усеченная подыгра $\bar{\Gamma}_j(x_{j,0}, t_0 + j \Delta t, t_0 +
j \Delta t + \overline{T})$ является конечной
диф\-фе\-рен\-циаль\-ной игрой, подобная игра была детально
изучена в~[13, 15]. Стратегии, входящие в~ситуацию равновесия
по~Нэшу в~усеченной подыгре $\bar{\Gamma}_j(x_{j,0}, t_0 + j
\Delta t, t_0 + j \Delta t + \overline{T})$, могут быть вычислены
так:
\begin{equation*}\label{}
u_i^j(t,x) = \frac{x}{4[c_i + A_i^j(t)/2]^2}, \qquad i=1,2.
\end{equation*}
Здесь функции $A_i^j(t)$ определены с~помощью системы
дифференциальных уравнений
\begin{eqnarray*}
\dot{A}_i^j(t) & = & A_i^j(t) \left[r + \frac{b_j}{2} + \frac{1}{8(c_j + A_{3-i}^j(t)/2)^2}\right] - \frac{1}{4(c_i + A_i^j(t)/2)}, \\
\dot{C}_i^j(t) & = & r C_i^j(t)  - \frac{a_j}{2} A_i^j(t)
\end{eqnarray*}
для $i=1,2$ с~граничными условиями $A_i^j(t_0 + j \Delta t +
\overline{T})=0$ и~$C_i^j(t_0 + j \Delta t + \overline{T})=0$.

Выигрыш игрока $i=1,2$ в~ситуации равновесия по~Нэшу [13, 15]
\begin{equation*}\label{44}
V^j_i(t, x) = e^{-r(t - t_0)} \left[
A^{j}_{i}(t)\sqrt{x}+C^{j}_{i}(t) \right], \qquad i=1, 2.
\end{equation*}

Рассмотрим теперь случай, когда игроки договорились
кооперироваться в~усеченной подыгре $\bar{\Gamma}^c_j(x_{j,0}, t_0
+ j \Delta t, t_0 + j \Delta t + \overline{T})$. Вычислим
максимальный суммарный выигрыш в~игре $\bar{\Gamma}^c_j(x_{j,0},
t_0 + j \Delta t, t_0 + j \Delta t + \overline{T})$ [13, 15]:
\begin{equation*}\label{45}
W^j(t, x) = e^{-r(t - t_0)} \left[ A^{j}(t)\sqrt{x}+C^{j}(t)
\right],
\end{equation*}
где функции $A^{j}(t)$, $C^{j}(t)$ удовлетворяют следующей системе
дифференциальных уравнений:
\begin{equation*}\label{}
\dot{A}^{j}(t)= \left[r+\frac{b_{j}}{2}\right]A^{j}(t) -
\frac{1}{4\left[c_{1}+\frac{A^{j}(t)}{2}\right]} -
\frac{1}{4\left[c_{2}+\frac{A^{j}(t)}{2}\right]},
\end{equation*}
\begin{equation*}\label{}
\dot{C}^{j}(t)= r C^{j}(t) -\frac{a_{j}}{2}A^{j}(t), \quad
A^{j}(t_0 + j \Delta t + \overline{T})=0, \quad C^{j}(t_0 + j
\Delta t + \overline{T})=0.
\end{equation*}

Кооперативная траектория $x^*_j(t)$ в~усеченной подыгре
$\bar{\Gamma}^c_j(x_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T})$ определена на~временном интервале $[t_0 + j \Delta
t, t_0 + j \Delta t + \overline{T}]$ [13, 15]:
\begin{equation*}\label{46}
x_{j}^{*}(t)= \varpi_{j}^{2}(t_0 + j \Delta t, t)
\left[\sqrt{x^{*}_{j,0}} +  \frac{1}{2} a \int\limits_{t_0 + j
\Delta t}^{t}  \varpi_{j}(t_0 + j \Delta t, \tau)^{-1}
d\tau\right]^{2}\!\!, \end{equation*}
%\begin{multline*}
\begin{equation*}
t \in (t_0 + j \Delta t, t_0 + (j+1) \Delta t],
\end{equation*}
%\begin{multline*}
\begin{equation*}
\text{здесь} ~\varpi_{j}(t_0 + j \Delta t, t) =   \exp
\int\limits_{t_0 + j \Delta t}^{t} -\left[\frac{1}{2}b +
\frac{1}{8 \left[c_{1}+\frac{A^{j}(\tau
)}{2}\right]^{2}}+\frac{1}{8
\left[c_{2}+\frac{A^{j}(\tau)}{2}\right]^{2}}\right]d\tau.~~~~~~~~~~
%\end{multline*}
\end{equation*}

Начальное положение для кооперативной траектории в~каждой
усеченной подыгре устанавливается из~предыдущей усеченной подыгры:
$x^*_{0,0}=x_0$ и~$x^*_{j,0}=x^*_{j-1}(t_0 + j\Delta t)$ для $1\le
j\le +\infty$. Определим условно кооперативную траекторию
$\hat{x}^*(t)$ в~игре $\Gamma(x_0,t_0)$:
$$
\hat{x}^*_j(t) = x^*_j(t), \qquad t\in  [t_0 + j \Delta t, t_0 +
(j+1) \Delta t], \qquad 0\le j\le +\infty.
$$

Рассмотрим пример, в~котором информация об игре известна
на~временном интервале с~продолжительностью $\overline{T} = 2$
и~обновляется каждый $\Delta t=1$ временной интервал. Зафиксируем
следующие параметры для уравнений движений: $a=5$, $b=0.3$, для
функции выигрыша: $c_{1}=0.15$, $c_{2}=0.65$ и~для начальных
условий: $t_0=0$, $x_0=250$. Также положим дисконт-фактор
$r=0.01$.

Условно кооперативная траектория $\hat{x}^*(t)$ составлена
из~кооперативных траекторий в~усеченных подыграх
$\bar{\Gamma}^c_j(x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T})$ с~уравнениями движе-\linebreakния~(9). На~рис. 1
представлено сравнение условно кооперативной траектории
$\hat{x}^*(t)$ и~кооперативной траектории $x^*(t)$ в~исходной игре
с~бесконечной продолжительностью $\Gamma(x_0, t_0)$ [13]. Видно,
что в~случае ограниченной информации выработка ресурсов происходит
быстрее, ибо игроки ориентируются на~урезанный временной интервал.
Ось абсцисс на рис.~1 определяет время $t$, ось ординат~--- запас
ресурса $x$.



%\begin{figure}[h]
%\center
%\includegraphics[width=0.8\linewidth]{x.eps}
%\caption{Условно кооперативная траектория для запаса ресурсов
%$\hat{x}^*(t)$ (сплошная линия) и~кооперативная траектория
%$x^*(t)$ (пунктирная линия) в~исходной игре $\Gamma(x_0, t_0)$
%с~бесконечной продолжительностью.}
%\end{figure}

%\pagebreak
В~качестве дележа в~каждой кооперативной усеченной
подыгре %\linebreak
$\bar{\Gamma}^c_j(x^*_{j,0}, t_0 + j \Delta t, t_0 + j \Delta t +
\overline{T})$, $0\le j\le +\infty$, используется пропорциональное
решение
\begin{equation*}\label{}
\xi^{(j)i}(\hat{x}^*_j(t), t, t_0 + j \Delta t + \overline{T}) =
\frac{V^j_i (t, \hat{x}^*_j(t))}{\sum_{k = 1}^{2}V^j_k(t,
\hat{x}^*_j(t))} W^j(t, \hat{x}^*_j(t)) =
\end{equation*}
\begin{equation*}\label{}
=
\frac{\left[A^{j}_{i}(t)\sqrt{\hat{x}^*_j(t)}+C^{j}_{i}(t)\right]}{\sum\limits_{k
= 1}^{2}
\left[A^{j}_{k}(t)\sqrt{\hat{x}^*_j(t)}+C^{j}_{k}(t)\right]}\left[A^{j}(t)\sqrt{\hat{x}^*_j(t)}+C^{j}(t)\right].
\end{equation*}


\begin{figure}[h!]
\centering
\includegraphics[scale=1]{02/fig1}
\vskip 1mm \caption{Условно кооперативная траектория для запаса
ресурсов }%\label{метка}
\centering \vspace{0mm} \small{$\hat{x}^*(t)$ (сплошная линия)
и~кооперативная траектория
$x^*(t)$ (пунктирная линия) \\
\vskip .5mm в~исходной игре $\Gamma(x_0, t_0)$ с~бесконечной
продолжительностью}
\end{figure}




Соответствующее ПРД обозначим через %\vskip 2mm
\begin{equation*}\label{48} B_{j}(t, x^{*}_{j})=\left[B^{j}_{1}(t,
x^{*}_{j}), B^{j}_{2}(t, x^{*}_{j})\right].
\end{equation*}
%\vskip 2mm
\indentОбщая формула для ПРД $B^{j}_i(t, x^{*}_{j})$ в~игре добычи
ограниченных ресурсов была выведена Д. Янгом и~Л.
Петросяном [13]: %\vskip 2mm
\begin{equation*}\label{}
B_{i}^{j}(\tau, x^{*}_{j})= - \left[\xi^{(j)i}_{t}(x^{*}_{j}, t,
t_0 + j \Delta t + \overline{T}) |_{t=\tau}\right]-
\end{equation*}
\begin{equation*}\label{}
- \left[\xi^{(j)i}_{x^{*}_{j}}(x^{*}_{j}, t, t_0 + j \Delta t +
\overline{T}) |_{t=\tau}\right]\!\!
\left[a\sqrt{x^{*}_{j}}\!-\!bx^{*}_{j}-\frac{x^{*}_{j}}{4\left[c_{1}
+ A^{j}(t)\right]^{2}}\!-\!\frac{x^{*}_{j}}{4\left[c_{2} +
A^{j}(t)\right]^{2}}\right]\!\!, ~ i=1,2.
\end{equation*}

%\vskip 2mm
Условное ПРД $\hat{B}_i(t, \hat{x}^*)$ строится
с~помощью $B_{i}^{j}(\tau, x^{*}_{j})$, $i=1, 2$ (см.~формулу (7).
Условное ПРД, определенное с~помощью решений с~опережением в~игре
$\Gamma(x_0, t_0)$, и~соответствующее ПРД в исходной игре
с~бесконечной продолжительностью  изображены на~рис.~2. Условное
ПРД $\hat{B}_i(t, \hat{x}^*)$ имеет ломаный вид, что является
результатом обновления информации об игре и~пересчета ожидаемого
суммарного выигрыша. Ось абсцисс на~рис. 2 определяет время $t$,
ось ординат --- ПРД.

На рис.~3 видна разница между результирующим дележом
$\hat{\xi}(x_0, t_0)$ (8) и~дележом в~исходной игре $\Gamma(x_0,
t_0)$ с~бесконечной продолжительностью, а~также между
соответствующим суммарным выигрышем. Очевидно, что суммарный
выигрыш в~рассматриваемом подходе будет всегда меньше, чем
в~исходной игре. Но стоит заметить, что дележ для некоторого
игрока может быть больше. Это значит, что некоторым игрокам может
быть выгодно, чтобы все игроки имели ограниченную информацию об
игре. Ось абсцисс на~рис. 3 определяет время $t$, ось ординат ---
дележ.



\begin{figure}[h!]
\centering
\includegraphics[scale=1]{02/fig2}
\vskip 2mm \caption{Условное ПРД $\hat{B}_i(t, \hat{x}^*)$
(сплошные линии)
и~ПРД $B_i(t, x^*)$ (пунктирные линии) }%\label{метка}
\centering \vspace{0mm} \small{в~исходной игре
$\Gamma(x_0, t_0)$ с~бесконечной продолжительностью}\\%
\centering \vspace{1mm} \footnotesize{ПРД изображено для первого
и~второго игрока соответственно.}
\end{figure}
\begin{figure}[h!]
\centering
\includegraphics[scale=1]{02/fig3}
\vskip 2mm \caption{Дележ $\hat{\xi}(x_0, t_0)$ (сплошные линии),
дележ
$\xi(x_0, t_0)$ (пунктирные линии) }%\label{метка}
\centering \vspace{0mm} \small{в~исходной игре $\Gamma(x_0, t_0)$
с~бесконечной продолжительностью и~соответствующий \\ \vskip 0.5mm
суммарный
выигрыш игроков (жирные пунктирная и~сплошная линии)}\\%
\centering \vspace{1mm} \footnotesize{Дележи изображены для
первого и~второго игрока соответственно.}
\end{figure}



%\begin{figure}[h]
%\center
%\includegraphics[width=0.8\linewidth]{idp.eps}
%\caption{Условное ПРД $\hat{B}_i(t, \hat{x}^*)$ (сплошные линии)
%и~ПРД $B_i(t, x^*)$ (пунктирные линии) в~исходной игре
%$\Gamma(x_0, t_0)$ с~бесконечной продолжительностью. ПРД
%изображено для первого и~второго игрока соответственно.}
%\end{figure}

%\pagebreak



%\begin{figure}[h]
%\center
%\includegraphics[width=0.8\linewidth]{xi.eps}
%\caption{Дележ $\hat{\xi}(x_0, t_0)$ (сплошные линии), дележ
%$\xi(x_0, t_0)$ (пунктирные линии) в~исходной игре $\Gamma(x_0,
%t_0)$ с~бесконечной продолжительностью и~соответствующий суммарный
%выигрыш игроков (жирные пунктирная и~сплошная линии). Дележи
%изображены для первого и~второго игрока соответственно.}
%\end{figure}

%\pagebreak


{\bf 7. Заключение.} В работе представлен подход для построения
решения в~реальном времени в~кооперативных дифференциальных играх
с~бесконечной продолжительностью. Игра определена на~интервале
с~бесконечной продолжительностью, разбитом на~интервалы конечной
длины. Предполагается, что в~каждый момент времени игроки имеют
информацию об уравнениях движения, функциях выигрыша на~конечном
временном интервале. В~фиксированные моменты времени информация
обновляется, таким образом достигается эффект того, что игра
решается в~реальном времени. Для получения оптимального решения
в~игре вводится понятие усеченной игры. На~его основе определяются
условно кооперативная траектория, условная ПРД и~концепция
решения. Доказывается свойство сильной $\Delta t$ динамической
устойчивости предложенной концепции решения.

Подход проиллюстрирован на~бесконечной игре добычи ограниченного
ресурса. Проведено сравнение решения в~классической постановке
и~в~постановке с~использованием разработанного подхода. Показано,
что в~случае ограниченной информации выработка ресурсов происходит
быстрее, так как игроки ориентируются на~урезанный временной
интервал. Показан ломаный вид условного ПРД по~сравнению с~ПРД
в~исходной игре. Также приведено сравнение дележей в~исходной игре
и в~игре с~ис\-пользованием данного подхода. Замечено, что
суммарный выигрыш в~рассматри\-ваемом подходе будет всегда меньше,
чем в~исходной игре, но~дележ для некоторо\-го игрока может быть
больше. Это значит, что некоторым игрокам может быть выгодно,
чтобы все игроки имели ограниченную информацию об игре.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\input{02/lit-ra}

%%%%%N DOI в~ссылке!!!!!!!!!!

\input{02/ref-s}

%%%%%N DOI в~ссылке!!!!!!!!!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\footnotesize




\vskip 2mm

%\thispagestyle{empty}


\thispagestyle{empty} %очищаем стиль страницы
\thispagestyle{fancy} %включаем пользовательский стиль
\renewcommand{\headrulewidth}{0pt}%
\fancyhead[LO]{}%
\fancyhead[RE]{}%
\fancyfoot[LO]{\footnotesize{\it{Вестник~СПбГУ.~Сер.~10.~Прикладная~математика.~Информатика...~\issueyear.~Вып.~\issuenum}}
\hfill}%
\fancyfoot[RE]{\hfill\footnotesize{\it{Вестник~СПбГУ.~Сер.~10.~Прикладная~математика.~Информатика...~\issueyear.~Вып.~\issuenum}}}%
%\lhead{} %верхний колонтитул слева
%%\rhead{} % верхний колонтитул справа
% для оформления нижнего колонтитула
\cfoot{} %
%\lfoot{} %
%\rfoot{\thepage} %


\noindent Статья рекомендована к~печати проф. Л.~А.~Петросяном.

\vskip 1mm

\noindent Статья поступила в~редакцию 7 мая 2016~г.

\vskip 1mm

\noindent Статья принята к~печати 29 сентября 2016~г.

}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\vskip 5mm


%{\footnotesize

%\noindent К\,о\,н\,т\,а\,к\,т\,н\,а\,я\,
%и\,н\,ф\,о\,р\,м\,а\,ц\,и\,я\nopagebreak

%\vskip 3mm

%\emph{Басков Олег Владимирович}~--- аспирант, ассистент; e-mail:
%ov.japh@gmail.com

%\vskip 2mm

%\emph{Baskov Oleg Vladimirovich}~--- postgraduate student; e-mail:
%ov.japh@gmail.com

%}



%\thispagestyle{empty}
